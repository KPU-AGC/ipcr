===== BEGIN ./Makefile =====
# ./Makefile
BIN_DIR := bin
GO ?= go

# Embed a nice version at build-time; falls back to "dev".
VERSION := $(shell git describe --tags --dirty --always 2>/dev/null || echo dev)
LDFLAGS := -s -w -X ipcr/internal/version.Version=$(VERSION)
GOFLAGS ?= -trimpath

# ---- Race detector auto-detection -------------------------------------------
CGO_ENABLED ?= $(shell $(GO) env CGO_ENABLED)
GOOS := $(shell $(GO) env GOOS)
GOARCH := $(shell $(GO) env GOARCH)
CCBIN := $(shell $(GO) env CC)
HASCC := $(shell command -v $(CCBIN) >/dev/null 2>&1 && echo yes || echo no)

# Race detector is considered "supported" only if cgo is enabled AND a C compiler exists.
RACE_SUPPORTED := $(if $(and $(filter 1,$(CGO_ENABLED)),$(filter yes,$(HASCC))),yes,no)
RACEFLAG := $(if $(filter yes,$(RACE_SUPPORTED)),-race,)

define maybe_echo_skip_race
	@if [ "$(RACE_SUPPORTED)" != "yes" ]; then \
	  echo "NOTE: Race detector disabled (CGO_ENABLED=$(CGO_ENABLED), CC=$(CCBIN), GOOS=$(GOOS), GOARCH=$(GOARCH))."; \
	  echo "      To enable, install a C toolchain and run with CGO_ENABLED=1."; \
	fi
endef
# -----------------------------------------------------------------------------

.PHONY: all build build-race test test-race test-short bench cover fmt vet lint tidy clean

all: build

build:
	mkdir -p $(BIN_DIR)
	$(GO) build $(GOFLAGS) -ldflags "$(LDFLAGS)" -o $(BIN_DIR)/ipcr ./cmd/ipcr
	$(GO) build $(GOFLAGS) -ldflags "$(LDFLAGS)" -o $(BIN_DIR)/ipcr-probe ./cmd/ipcr-probe
	$(GO) build $(GOFLAGS) -ldflags "$(LDFLAGS)" -o $(BIN_DIR)/ipcr-multiplex ./cmd/ipcr-multiplex
	$(GO) build $(GOFLAGS) -ldflags "$(LDFLAGS)" -o $(BIN_DIR)/ipcr-nested ./cmd/ipcr-nested

# Force a race build; fails with a helpful message if unsupported.
build-race:
	@if [ "$(RACE_SUPPORTED)" != "yes" ]; then \
	  echo "ERROR: build-race requested but race detector not available."; \
	  echo "       Install a C toolchain and export CGO_ENABLED=1."; \
	  exit 1; \
	fi
	mkdir -p $(BIN_DIR)
	$(GO) build $(GOFLAGS) -race -ldflags "$(LDFLAGS)" -o $(BIN_DIR)/ipcr ./cmd/ipcr
	$(GO) build $(GOFLAGS) -race -ldflags "$(LDFLAGS)" -o $(BIN_DIR)/ipcr-probe ./cmd/ipcr-probe
	$(GO) build $(GOFLAGS) -race -ldflags "$(LDFLAGS)" -o $(BIN_DIR)/ipcr-multiplex ./cmd/ipcr-multiplex
	$(GO) build $(GOFLAGS) -race -ldflags "$(LDFLAGS)" -o $(BIN_DIR)/ipcr-nested ./cmd/ipcr-nested

# Auto: uses -race when supported; otherwise skips it with a note.
test:
	$(maybe_echo_skip_race)
	$(GO) test $(GOFLAGS) $(RACEFLAG) ./... -count=1

test-race:
	@if [ "$(RACE_SUPPORTED)" != "yes" ]; then \
	  echo "ERROR: test-race requested but race detector not available."; \
	  echo "       Install a C toolchain and export CGO_ENABLED=1."; \
	  exit 1; \
	fi
	$(GO) test $(GOFLAGS) -race ./... -count=1

test-short:
	$(maybe_echo_skip_race)
	$(GO) test $(GOFLAGS) $(RACEFLAG) ./... -short -count=1

bench:
	$(maybe_echo_skip_race)
	$(GO) test $(GOFLAGS) $(RACEFLAG) ./... -bench=. -run=^$$

cover:
	$(maybe_echo_skip_race)
	$(GO) test $(GOFLAGS) $(RACEFLAG) ./... -coverprofile=coverage.out
	$(GO) tool cover -func=coverage.out

fmt:
	@echo "Formatting..."
	@$(GO) fmt ./...

vet:
	$(GO) vet ./...

lint:
	@command -v golangci-lint >/dev/null 2>&1 || { \
	  echo "golangci-lint not found; install from https://golangci-lint.run/"; exit 0; }
	golangci-lint run

tidy:
	$(GO) mod tidy

clean:
	rm -rf $(BIN_DIR) coverage.out

===== END ./Makefile =====

===== BEGIN ./cmd/ipcr-multiplex/main.go =====
// ./cmd/ipcr-multiplex/main.go
package main

import (
	"context"
	"os"
	"os/signal"
	"syscall"

	"ipcr/internal/multiplexapp"
)

func main() {
	ctx, stop := signal.NotifyContext(context.Background(), os.Interrupt, syscall.SIGTERM)
	defer stop()
	code := multiplexapp.RunContext(ctx, os.Args[1:], os.Stdout, os.Stderr)
	os.Exit(code)
}

===== END ./cmd/ipcr-multiplex/main.go =====

===== BEGIN ./cmd/ipcr-probe/main.go =====
// cmd/ipcr-probe/main.go
package main

import (
	"context"
	"os"
	"os/signal"
	"syscall"

	"ipcr/internal/probeapp"
)

func main() {
	ctx, stop := signal.NotifyContext(context.Background(), os.Interrupt, syscall.SIGTERM)
	defer stop()
	code := probeapp.RunContext(ctx, os.Args[1:], os.Stdout, os.Stderr)
	os.Exit(code)
}

===== END ./cmd/ipcr-probe/main.go =====

===== BEGIN ./cmd/ipcr/main.go =====
// cmd/ipcr/main.go
package main

import (
	"context"
	"os"
	"os/signal"
	"syscall"

	"ipcr/internal/app"
)

func main() {
	// Derive cancellation from signals (Ctrl‑C / SIGTERM).
	ctx, stop := signal.NotifyContext(context.Background(), os.Interrupt, syscall.SIGTERM)
	defer stop()

	// Stream directly to the process writers.
	code := app.RunContext(ctx, os.Args[1:], os.Stdout, os.Stderr)
	os.Exit(code)
}

===== END ./cmd/ipcr/main.go =====

===== BEGIN ./docs/ARCHITECTURE.md =====
<!-- ./docs/ARCHITECTURE.md -->
# ipcr Architecture (layers & rules)

**Goal:** keep the engine fast/clean, keep presentation optional, and make adding new tools easy.

## Layers (top → bottom)
1. **cmd/** — tiny binaries (signal handling, exit code).
2. **internal/app, internal/probeapp, internal/multiplexapp, internal/nestedapp** — parse CLI and call the shared harness.
3. **internal/appcore** — one harness for all tools: chunking, engine, pipeline, visitor, writer.
4. **internal/writers, internal/visitors** — extension points for output and filtering.
5. **internal/pipeline** — FASTA chunking, dedupe, stream products.
6. **internal/engine, internal/primer, internal/probe, internal/oligo** — domain logic.
7. **internal/fasta** — IO for FASTA streams.
8. **internal/output, internal/probeoutput, internal/nestedoutput, internal/pretty** — concrete formats & ASCII rendering.
9. **internal/common, internal/runutil, internal/cli*, internal/version** — leaf utilities.

## Allowed imports (arrows)
- `cmd/*` → `internal/app*` only.
- `internal/app*` → `appcore`, `cli*/probecli/nestedcli`, `visitors`, `writers`, `runutil`, `version`, `primer`.
- `appcore` → `cmdutil`, `engine`, `pipeline`, `primer`, `visitors`, `writers`, `runutil`.
- `writers` → `output/probeoutput/nestedoutput`, `pretty`, `engine`, `common`.
- `pipeline` → `engine`, `fasta`, `primer`, `common`.
- `engine` → `primer` (and stdlib).
- `output/probeoutput/nestedoutput/pretty` → may import `engine` types, but **must not** import `app*`, `appcore`, `pipeline`, `cli*`.

## Key invariants
- **Only writers know about “pretty”.**
- **Engine never depends upward.** (no imports of app, pipeline, writers, cli, output)

## Future split
If you ever need external reuse: lift `engine`, `primer`, `probe`, `oligo`, `fasta` into a separate module (`ipcr-core`) and keep `app`, `appcore`, `writers`, `output`, `pretty` in this repo.

===== END ./docs/ARCHITECTURE.md =====

===== BEGIN ./internal/app/app.go =====
package app

import (
	"bufio"
	"context"
	"errors"
	"flag"
	"fmt"
	"io"

	"ipcr/internal/appcore"
	"ipcr/internal/cli"
	"ipcr/internal/engine"
	"ipcr/internal/primer"
	"ipcr/internal/runutil"
	"ipcr/internal/version"
	"ipcr/internal/visitors"
	"ipcr/internal/writers"
)

// RunContext is the ipcr app entrypoint used by cmd/ipcr.
func RunContext(parent context.Context, argv []string, stdout, stderr io.Writer) int {
	outw := bufio.NewWriter(stdout)
	defer outw.Flush() // harmless if re-flushed later

	// Build a throwaway FlagSet so we can render usage cleanly.
	fs := cli.NewFlagSet("ipcr")
	fs.SetOutput(io.Discard)

	// No args → show help and exit 0.
	if len(argv) == 0 {
		_, _ = cli.ParseArgs(fs, []string{"-h"})
		fs.SetOutput(outw)
		fs.Usage()
		if err := outw.Flush(); writers.IsBrokenPipe(err) {
			return 0
		} else if err != nil {
			fmt.Fprintln(stderr, err)
			return 3
		}
		return 0
	}

	opts, err := cli.ParseArgs(fs, argv)
	if err != nil {
		if errors.Is(err, flag.ErrHelp) {
			fs.SetOutput(outw)
			fs.Usage()
			if e := outw.Flush(); writers.IsBrokenPipe(e) {
				return 0
			} else if e != nil {
				fmt.Fprintln(stderr, e)
				return 3
			}
			return 0
		}
		fmt.Fprintln(stderr, err)
		fs.SetOutput(outw)
		fs.Usage()
		if e := outw.Flush(); writers.IsBrokenPipe(e) {
			return 0
		} else if e != nil {
			fmt.Fprintln(stderr, e)
			return 3
		}
		return 2
	}

	if opts.Version {
		fmt.Fprintf(outw, "ipcr version %s\n", version.Version)
		if e := outw.Flush(); writers.IsBrokenPipe(e) {
			return 0
		} else if e != nil {
			fmt.Fprintln(stderr, e)
			return 3
		}
		return 0
	}

	// Primer pairs
	var pairs []primer.Pair
	if opts.PrimerFile != "" {
		pairs, err = primer.LoadTSV(opts.PrimerFile)
		if err != nil {
			fmt.Fprintln(stderr, err)
			return 2
		}
	} else {
		pairs = []primer.Pair{{
			ID:         "manual",
			Forward:    opts.Fwd,
			Reverse:    opts.Rev,
			MinProduct: opts.MinLen,
			MaxProduct: opts.MaxLen,
		}}
	}

	// Normalize options for the core runner.
	termWin := runutil.ComputeTerminalWindow(opts.Mode, opts.TerminalWindow)
	coreOpts := appcore.Options{
		SeqFiles:        opts.SeqFiles,
		MaxMM:           opts.Mismatches,
		TerminalWindow:  termWin,
		MinLen:          opts.MinLen,
		MaxLen:          opts.MaxLen,
		HitCap:          opts.HitCap,
		SeedLength:      opts.SeedLength,
		Circular:        opts.Circular,
		Threads:         opts.Threads,
		ChunkSize:       opts.ChunkSize,
		Quiet:           opts.Quiet,
		NoMatchExitCode: opts.NoMatchExitCode,
	}

	writer := appcore.NewProductWriterFactory(opts.Output, opts.Sort, opts.Header, opts.Pretty, opts.Products)

	return appcore.Run[engine.Product](
		parent,
		stdout, stderr,
		coreOpts,
		pairs,
		visitors.PassThrough{}.Visit,
		writer,
	)
}

// Compatibility shim for older tests and callers.
// Signature matches previous app.Run(argv, stdout, stderr) style.
func Run(argv []string, stdout, stderr io.Writer) int {
	return RunContext(context.Background(), argv, stdout, stderr)
}

===== END ./internal/app/app.go =====

===== BEGIN ./internal/appcore/core.go =====
// internal/appcore/core.go
package appcore

import (
	"bufio"
	"context"
	"errors"
	"fmt"
	"io"
	"runtime"

	"ipcr/internal/cmdutil"
	"ipcr/internal/engine"
	"ipcr/internal/pipeline"
	"ipcr/internal/primer"
	"ipcr/internal/runutil"
	"ipcr/internal/writers"
)

type Options struct {
	SeqFiles []string

	MaxMM          int
	TerminalWindow int
	MinLen         int
	MaxLen         int
	HitCap         int
	SeedLength     int
	Circular       bool

	Threads   int
	ChunkSize int

	Quiet           bool
	NoMatchExitCode int
}

type VisitorFunc[T any] func(engine.Product) (keep bool, out T, err error)

type WriterFactory[T any] interface {
	NeedSites() bool
	NeedSeq() bool
	Start(out io.Writer, bufSize int) (chan<- T, <-chan error)
}

func Run[T any](
	parent context.Context,
	stdout, stderr io.Writer,
	o Options,
	pairs []primer.Pair,
	visit VisitorFunc[T],
	wf WriterFactory[T],
) int {
	outw := bufio.NewWriter(stdout)

	// longest primer
	maxPLen := 0
	for _, pr := range pairs {
		if l := len(pr.Forward); l > maxPLen {
			maxPLen = l
		}
		if l := len(pr.Reverse); l > maxPLen {
			maxPLen = l
		}
	}
	if o.MaxLen > 0 && o.MaxLen < maxPLen {
		fmt.Fprintf(stderr, "error: --max-length (%d) is smaller than the longest primer length (%d)\n", o.MaxLen, maxPLen)
		return 2
	}
	if o.MinLen > 0 && o.MaxLen > 0 && o.MinLen > o.MaxLen {
		fmt.Fprintf(stderr, "error: --min-length (%d) exceeds --max-length (%d)\n", o.MinLen, o.MaxLen)
		return 2
	}

	chunkSize, overlap, warns := runutil.ValidateChunking(o.Circular, o.ChunkSize, o.MaxLen, maxPLen)
	if !o.Quiet {
		for _, w := range warns {
			fmt.Fprintln(stderr, w)
		}
	}

	thr := o.Threads
	if thr <= 0 {
		thr = runtime.NumCPU()
	}

	sim := engine.New(engine.Config{
		MaxMM:          o.MaxMM,
		TerminalWindow: o.TerminalWindow,
		MinLen:         o.MinLen,
		MaxLen:         o.MaxLen,
		HitCap:         o.HitCap,
		NeedSites:      wf.NeedSites(),
		SeedLen:        o.SeedLength,
		Circular:       o.Circular,
	})

	inCh, writeErr := wf.Start(outw, thr*4)

	ctx, cancel := context.WithCancel(parent)
	defer cancel()

	total, perr := cmdutil.RunStream[T](
		ctx,
		pipeline.Config{
			Threads:   thr,
			ChunkSize: chunkSize,
			Overlap:   overlap,
			Circular:  o.Circular,
			NeedSeq:   wf.NeedSeq(),
		},
		o.SeqFiles,
		pairs,
		sim, // <— interface now
		visit,
		func(x T) error {
			select {
			case inCh <- x:
				return nil
			case <-ctx.Done():
				return ctx.Err()
			}
		},
	)

	close(inCh)

	if werr := <-writeErr; writers.IsBrokenPipe(werr) {
		return 0
	} else if werr != nil {
		fmt.Fprintln(stderr, werr)
		return 3
	}
	if e := outw.Flush(); writers.IsBrokenPipe(e) {
		return 0
	} else if e != nil {
		fmt.Fprintln(stderr, e)
		return 3
	}

	if perr != nil {
		if errors.Is(perr, context.Canceled) {
			return 130
		}
		fmt.Fprintln(stderr, perr)
		return 3
	}
	if total == 0 {
		return o.NoMatchExitCode
	}
	return 0
}

===== END ./internal/appcore/core.go =====

===== BEGIN ./internal/appcore/writer_factories.go =====
// ./internal/appcore/writer_factories.go
package appcore

import (
	"io"

	"ipcr/internal/engine"
	"ipcr/internal/probeoutput"
	"ipcr/internal/writers"
	"ipcr/internal/nestedoutput"
)

// ---------------- Product writer ----------------

type ProductWriterFactory struct {
	Format   string
	Sort     bool
	Header   bool
	Pretty   bool
	Products bool
}

func NewProductWriterFactory(format string, sort, header, pretty, products bool) ProductWriterFactory {
	return ProductWriterFactory{Format: format, Sort: sort, Header: header, Pretty: pretty, Products: products}
}

func (w ProductWriterFactory) NeedSites() bool {
	return w.Format == "text" && w.Pretty
}

func (w ProductWriterFactory) NeedSeq() bool {
	if w.Products { return true }
	if w.Format == "fasta" { return true }
	if w.Format == "text" && w.Pretty { return true }
	return false
}

func (w ProductWriterFactory) Start(out io.Writer, bufSize int) (chan<- engine.Product, <-chan error) {
	return writers.StartProductWriter(out, w.Format, w.Sort, w.Header, w.Pretty, bufSize)
}

// ---------------- Annotated writer (probe) ----------------

type AnnotatedWriterFactory struct {
	Format string
	Sort   bool
	Header bool
	Pretty bool
}

func NewAnnotatedWriterFactory(format string, sort, header, pretty bool) AnnotatedWriterFactory {
	return AnnotatedWriterFactory{Format: format, Sort: sort, Header: header, Pretty: pretty}
}

func (w AnnotatedWriterFactory) NeedSites() bool { return w.Pretty }
func (w AnnotatedWriterFactory) NeedSeq() bool  { return true }

func (w AnnotatedWriterFactory) Start(out io.Writer, bufSize int) (chan<- probeoutput.AnnotatedProduct, <-chan error) {
	return writers.StartAnnotatedWriter(out, w.Format, w.Sort, w.Header, w.Pretty, bufSize)
}

// ---------------- Nested writer ----------------

type NestedWriterFactory struct {
	Format string
	Sort   bool
	Header bool
}

func NewNestedWriterFactory(format string, sort, header bool) NestedWriterFactory {
	return NestedWriterFactory{Format: format, Sort: sort, Header: header}
}

// Pretty rendering for nested isn’t implemented (sites aren’t needed here).
func (w NestedWriterFactory) NeedSites() bool { return false }

// IMPORTANT: visitor needs Product.Seq to rescan inner primers.
func (w NestedWriterFactory) NeedSeq() bool { return true }

func (w NestedWriterFactory) Start(out io.Writer, bufSize int) (chan<- nestedoutput.NestedProduct, <-chan error) {
	return writers.StartNestedWriter(out, w.Format, w.Sort, w.Header, bufSize)
}

===== END ./internal/appcore/writer_factories.go =====

===== BEGIN ./internal/appcore/writer_factories_test.go =====
package appcore

import "testing"

func TestProductWriterFactory_NeedSitesAndSeq(t *testing.T) {
	w := NewProductWriterFactory("text", false, false, true, false)
	if !w.NeedSites() { t.Fatal("pretty text must NeedSites") }
	if !w.NeedSeq() { t.Fatal("pretty text must NeedSeq") }

	w = NewProductWriterFactory("json", false, false, false, false)
	if w.NeedSites() || w.NeedSeq() { t.Fatal("json without products/pretty should not need sites/seq") }

	w = NewProductWriterFactory("fasta", false, false, false, false)
	if !w.NeedSeq() { t.Fatal("fasta must NeedSeq") }

	w = NewProductWriterFactory("json", false, false, false, true)
	if !w.NeedSeq() { t.Fatal("json + --products must NeedSeq") }
}

func TestAnnotatedWriterFactory_AlwaysNeedsSeq(t *testing.T) {
	w := NewAnnotatedWriterFactory("text", false, false, false)
	if !w.NeedSeq() { t.Fatal("annotated writer always needs seq for probe") }
	if w.NeedSites() { t.Fatal("no-pretty should not NeedSites") }

	w = NewAnnotatedWriterFactory("text", false, false, true)
	if !w.NeedSites() { t.Fatal("pretty annotated writer needs sites") }
}

===== END ./internal/appcore/writer_factories_test.go =====

===== BEGIN ./internal/arch/arch_test.go =====
// ./internal/arch/arch_test.go
package arch

import (
	"bytes"
	"encoding/json"
	"io"
	"os/exec"
	"strings"
	"testing"
)

type pkg struct {
	ImportPath string
	Imports    []string
	Standard   bool
}

func TestImportBoundaries(t *testing.T) {
	cmd := exec.Command("go", "list", "-json", "./...")
	var out bytes.Buffer
	cmd.Stdout = &out
	if err := cmd.Run(); err != nil {
		t.Fatalf("go list: %v", err)
	}
	dec := json.NewDecoder(&out)

	bans := map[string][]string{
		"ipcr/internal/engine": {
			"ipcr/internal/pipeline", "ipcr/internal/writers",
			"ipcr/internal/output", "ipcr/internal/probeoutput", "ipcr/internal/nestedoutput",
			"ipcr/internal/cli", "ipcr/internal/probecli", "ipcr/internal/nestedcli",
			"ipcr/internal/appcore", "ipcr/internal/app", "ipcr/cmd/",
		},
		"ipcr/internal/pipeline": {
			"ipcr/internal/appcore", "ipcr/internal/app",
			"ipcr/internal/cli", "ipcr/internal/probecli", "ipcr/internal/nestedcli",
			"ipcr/cmd/",
		},
		"ipcr/internal/writers": {
			"ipcr/internal/appcore", "ipcr/internal/app",
			"ipcr/internal/cli", "ipcr/internal/probecli", "ipcr/internal/nestedcli",
			"ipcr/internal/pipeline", "ipcr/cmd/",
		},
		"ipcr/internal/output": {
			"ipcr/internal/appcore", "ipcr/internal/app",
			"ipcr/internal/cli", "ipcr/internal/probecli", "ipcr/internal/nestedcli",
			"ipcr/internal/pipeline", "ipcr/cmd/",
		},
		"ipcr/internal/probeoutput": {
			"ipcr/internal/appcore", "ipcr/internal/app",
			"ipcr/internal/cli", "ipcr/internal/probecli", "ipcr/internal/nestedcli",
			"ipcr/internal/pipeline", "ipcr/cmd/",
		},
		"ipcr/internal/nestedoutput": {
			"ipcr/internal/appcore", "ipcr/internal/app",
			"ipcr/internal/cli", "ipcr/internal/probecli", "ipcr/internal/nestedcli",
			"ipcr/internal/pipeline", "ipcr/cmd/",
		},
		"ipcr/internal/pretty": {
			"ipcr/internal/appcore", "ipcr/internal/app",
			"ipcr/internal/cli", "ipcr/internal/probecli", "ipcr/internal/nestedcli",
			"ipcr/internal/pipeline", "ipcr/cmd/",
		},
	}

	var violations []string
	for {
		var p pkg
		if err := dec.Decode(&p); err == io.EOF {
			break
		} else if err != nil {
			t.Fatalf("decode: %v", err)
		}
		if !strings.HasPrefix(p.ImportPath, "ipcr/") {
			continue
		}
		imp := p.ImportPath
		for prefix, forbidden := range bans {
			if !strings.HasPrefix(imp, prefix) {
				continue
			}
			for _, dep := range p.Imports {
				if !strings.HasPrefix(dep, "ipcr/") {
					continue
				}
				for _, ban := range forbidden {
					if strings.HasPrefix(dep, ban) {
						violations = append(violations, imp+" → "+dep)
					}
				}
			}
		}
	}

	if len(violations) > 0 {
		t.Fatalf("import boundary violations:\n  %s", strings.Join(violations, "\n  "))
	}
}

===== END ./internal/arch/arch_test.go =====

===== BEGIN ./internal/cli/options.go =====
// internal/cli/options.go
package cli

import (
	"flag"
	"fmt"
	"strings"

	"ipcr/internal/clibase"
	"ipcr/internal/cliutil"
	"ipcr/internal/version"
)

const (
	ModeRealistic = "realistic"
	ModeDebug     = "debug"
)

type Options struct {
	PrimerFile string
	Fwd        string
	Rev        string
	SeqFiles   []string

	Mismatches     int
	MinLen         int
	MaxLen         int
	HitCap         int
	TerminalWindow int

	Threads    int
	ChunkSize  int
	SeedLength int
	Circular   bool

	Output          string
	Products        bool
	Pretty          bool
	Mode            string
	Sort            bool
	Header          bool
	NoMatchExitCode int

	Quiet   bool
	Version bool
}

func NewFlagSet(name string) *flag.FlagSet {
	fs := flag.NewFlagSet(name, flag.ContinueOnError)
	fs.Usage = func() {
		out := fs.Output()
		def := func(flagName string) string {
			if f := fs.Lookup(flagName); f != nil {
				return f.DefValue
			}
			return ""
		}
		fmt.Fprintf(out, "%s – in-silico PCR\n\n", name)
		fmt.Fprintf(out, "Author:  Erick Samera (erick.samera@kpu.ca)\n")
		fmt.Fprintf(out, "License: MIT\n")
		fmt.Fprintf(out, "Version: %s\n\n", version.Version)
		fmt.Fprintln(out, "Usage:")
		fmt.Fprintf(out, "  %s [options] --forward AAA --reverse TTT --sequences ref.fa\n", name)
		fmt.Fprintf(out, "  %s [options] --forward AAA --reverse TTT ref*.fa gz/*.fa.gz\n", name)

		fmt.Fprintln(out, "\nInput:")
		fmt.Fprintln(out, "  -f, --forward string        Forward primer sequence (5'→3') [*]")
		fmt.Fprintln(out, "  -r, --reverse string        Reverse primer sequence (5'→3') [*]")
		fmt.Fprintln(out, "  -p, --primers string        TSV file of primer pairs [*]")
		fmt.Fprintln(out, "  -s, --sequences file        FASTA file(s) (repeatable) or '-' for STDIN [*]")

		fmt.Fprintln(out, "\nPCR Parameters:")
		fmt.Fprintf(out, "  -m, --mismatches int        Maximum mismatches per primer [%s]\n", def("mismatches"))
		fmt.Fprintf(out, "      --min-length int        Minimum product length [%s]\n", def("min-length"))
		fmt.Fprintf(out, "      --max-length int        Maximum product length [%s]\n", def("max-length"))
		fmt.Fprintf(out, "      --terminal-window int   3' terminal mismatch window (0=allow, -1=auto) [%s]\n", def("terminal-window"))
		fmt.Fprintf(out, "      --mode string           Matching mode: realistic | debug [%s]\n", def("mode"))
		fmt.Fprintf(out, "  -c, --circular              Treat each FASTA record as circular [%s]\n", def("circular"))

		fmt.Fprintln(out, "\nPerformance:")
		fmt.Fprintf(out, "  -t, --threads int           Number of worker threads (0 = all CPUs) [%s]\n", def("threads"))
		fmt.Fprintf(out, "      --hit-cap int           Max matches stored per primer/window (0 = unlimited) [%s]\n", def("hit-cap"))
		fmt.Fprintf(out, "      --chunk-size int        Chunk size (0 = no chunking) [%s]\n", def("chunk-size"))
		fmt.Fprintf(out, "      --seed-length int       Seed length for multi-pattern scan (0=auto) [%s]\n", def("seed-length"))

		fmt.Fprintln(out, "\nOutput:")
		fmt.Fprintf(out, "  -o, --output string         Output format: text | json | jsonl | fasta [%s]\n", def("output"))
		fmt.Fprintf(out, "      --products              Emit product sequences [%s]\n", def("products"))
		fmt.Fprintf(out, "      --pretty                Pretty ASCII alignment block (text mode) [%s]\n", def("pretty"))
		fmt.Fprintf(out, "      --sort                  Sort outputs for determinism [%s]\n", def("sort"))
		fmt.Fprintf(out, "      --no-header             Suppress header line [%s]\n", def("no-header"))
		fmt.Fprintf(out, "      --no-match-exit-code int  Exit code when no amplicons found [%s]\n", def("no-match-exit-code"))

		fmt.Fprintln(out, "\nMiscellaneous:")
		fmt.Fprintf(out, "  -q, --quiet                 Suppress non-essential warnings [%s]\n", def("quiet"))
		fmt.Fprintln(out, "  -v, --version               Print version and exit")
		fmt.Fprintln(out, "  -h, --help                  Show this help and exit")
	}
	return fs
}

func Parse() (Options, error) { return ParseArgs(flag.CommandLine, nil) }

type stringSlice []string
func (s *stringSlice) String() string     { return strings.Join(*s, ",") }
func (s *stringSlice) Set(v string) error { *s = append(*s, v); return nil }

func ParseArgs(fs *flag.FlagSet, argv []string) (Options, error) {
	var o Options
	var help bool

	// Register shared flags
	var c clibase.Common
	noHeader := clibase.Register(fs, &c)

	// Help flag (so -h returns flag.ErrHelp like before)
	fs.BoolVar(&help, "h", false, "show this help [false]")

	// Split & parse
	flagArgs, posArgs := cliutil.SplitFlagsAndPositionals(fs, argv)
	if err := fs.Parse(flagArgs); err != nil {
		return o, err
	}
	if help {
		return o, flag.ErrHelp
	}
	if c.Version {
		// Copy the version bit through so callers can print and exit.
		o.Version = true
		return o, nil
	}

	// Finalize header, expand positionals, validate
	if err := clibase.AfterParse(fs, &c, noHeader, posArgs); err != nil {
		return o, err
	}

	// Copy Common → Options (field-for-field)
	o.PrimerFile, o.Fwd, o.Rev, o.SeqFiles = c.PrimerFile, c.Fwd, c.Rev, c.SeqFiles
	o.Mismatches, o.MinLen, o.MaxLen, o.HitCap, o.TerminalWindow = c.Mismatches, c.MinLen, c.MaxLen, c.HitCap, c.TerminalWindow
	o.Threads, o.ChunkSize, o.SeedLength, o.Circular = c.Threads, c.ChunkSize, c.SeedLength, c.Circular
	o.Output, o.Products, o.Pretty, o.Mode = c.Output, c.Products, c.Pretty, c.Mode
	o.Sort, o.Header, o.NoMatchExitCode = c.Sort, c.Header, c.NoMatchExitCode
	o.Quiet = c.Quiet
	return o, nil
}

===== END ./internal/cli/options.go =====

===== BEGIN ./internal/cli/options_test.go =====
// internal/cli/options_test.go
package cli

import (
	"flag"
	"os"
	"path/filepath"
	"testing"
)

func newFS() *flag.FlagSet {
	return flag.NewFlagSet("test", flag.ContinueOnError)
}

// Helper for tests expecting successful parse.
func mustParse(t *testing.T, args ...string) Options {
	t.Helper()
	opts, err := ParseArgs(newFS(), args)
	if err != nil {
		t.Fatalf("parse err: %v", err)
	}
	return opts
}

// Should parse primer file input
func TestPrimersFileOK(t *testing.T) {
	o := mustParse(t, "--primers", "p.tsv", "ref.fa")
	if o.PrimerFile != "p.tsv" || o.Fwd != "" {
		t.Errorf("expected primers file only, got %+v", o)
	}
	if len(o.SeqFiles) != 1 || o.SeqFiles[0] != "ref.fa" {
		t.Errorf("expected positional sequence, got %+v", o.SeqFiles)
	}
}

// Should parse inline primer input with multiple sequence files (legacy flag)
func TestInlinePrimersOK(t *testing.T) {
	o := mustParse(t,
		"--forward", "AAA",
		"--reverse", "TTT",
		"--sequences", "ref.fa", "--sequences", "extra.fa",
	)
	if o.Fwd != "AAA" || len(o.SeqFiles) != 2 {
		t.Errorf("bad inline parse: %+v", o)
	}
}

// Should fail when reverse is missing
func TestErrorMissingReverse(t *testing.T) {
	_, err := ParseArgs(newFS(), []string{
		"--forward", "AAA", "ref.fa",
	})
	if err == nil {
		t.Fatal("expected error when reverse not supplied")
	}
}

// Should fail for mutual exclusion of primers and forward/reverse
func TestErrorMutualExclusion(t *testing.T) {
	_, err := ParseArgs(newFS(), []string{
		"--primers", "p.tsv", "--forward", "AAA",
		"--reverse", "TTT", "ref.fa",
	})
	if err == nil {
		t.Fatal("expected mutual-exclusion error")
	}
}

// Should fail when no primer input is given
func TestErrorNoPrimerInput(t *testing.T) {
	_, err := ParseArgs(newFS(), []string{"ref.fa"})
	if err == nil {
		t.Fatal("expected error with no primers")
	}
}

// Should fail when sequences are missing
func TestErrorNoSequences(t *testing.T) {
	_, err := ParseArgs(newFS(), []string{"--forward", "AAA", "--reverse", "TTT"})
	if err == nil {
		t.Fatal("expected error when sequences missing")
	}
}

func TestNewFlags(t *testing.T) {
	o := mustParse(t, "--forward", "AAA", "--reverse", "TTT", "ref.fa", "--sort", "--no-header", "--terminal-window", "2")
	if !o.Sort {
		t.Errorf("expected --sort = true")
	}
	if o.Header {
		t.Errorf("expected header=false due to --no-header")
	}
	if o.TerminalWindow != 2 {
		t.Errorf("terminal window parse failed, got %d", o.TerminalWindow)
	}
}

// Positional globs should expand to matching files
func TestPositionalGlobOK(t *testing.T) {
	dir := t.TempDir()
	a := filepath.Join(dir, "a.fa")
	b := filepath.Join(dir, "b.fa")
	if err := os.WriteFile(a, []byte(">a\nA\n"), 0644); err != nil {
		t.Fatal(err)
	}
	if err := os.WriteFile(b, []byte(">b\nA\n"), 0644); err != nil {
		t.Fatal(err)
	}
	pattern := filepath.Join(dir, "*.fa")

	o := mustParse(t, "--forward", "AAA", "--reverse", "TTT", pattern)
	if len(o.SeqFiles) != 2 {
		t.Fatalf("expected 2 files from glob, got %d: %+v", len(o.SeqFiles), o.SeqFiles)
	}
	// Order is determined by filepath.Glob; just assert both are present.
	foundA, foundB := false, false
	for _, f := range o.SeqFiles {
		if f == a {
			foundA = true
		} else if f == b {
			foundB = true
		}
	}
	if !foundA || !foundB {
		t.Fatalf("glob expansion missing files: %+v", o.SeqFiles)
	}
}

// Mix legacy --sequences and positional inputs
func TestMixFlagAndPositional(t *testing.T) {
	dir := t.TempDir()
	x := filepath.Join(dir, "x.fa")
	y := filepath.Join(dir, "y.fa")
	_ = os.WriteFile(x, []byte(">x\nA\n"), 0644)
	_ = os.WriteFile(y, []byte(">y\nA\n"), 0644)

	o := mustParse(t,
		"--forward", "AAA", "--reverse", "TTT",
		"--sequences", x, // legacy
		y,                // positional
	)
	if len(o.SeqFiles) != 2 {
		t.Fatalf("expected 2 seq files, got %d: %+v", len(o.SeqFiles), o.SeqFiles)
	}
}

// Unmatched glob should error
func TestGlobNoMatchErrors(t *testing.T) {
	_, err := ParseArgs(newFS(), []string{
		"--forward", "AAA", "--reverse", "TTT",
		filepath.Join(t.TempDir(), "*.nope"),
	})
	if err == nil {
		t.Fatal("expected error on unmatched glob")
	}
}

===== END ./internal/cli/options_test.go =====

===== BEGIN ./internal/clibase/common.go =====
// internal/clibase/common.go
package clibase

import (
	"errors"
	"flag"
	"fmt"

	"ipcr/internal/cliutil"
)

// Common holds CLI fields shared by ipcr and ipcr-probe.
type Common struct {
	// Input
	PrimerFile string
	Fwd        string
	Rev        string
	SeqFiles   []string

	// PCR
	Mismatches     int
	MinLen         int
	MaxLen         int
	HitCap         int
	TerminalWindow int
	Mode           string

	// Performance
	Threads    int
	ChunkSize  int
	SeedLength int
	Circular   bool

	// Output
	Output          string // text|json|jsonl|fasta
	Products        bool
	Pretty          bool
	Sort            bool
	Header          bool
	NoMatchExitCode int

	// Misc
	Quiet   bool
	Version bool
}

// sliceValue appends each value to a *[]string (for --sequences/-s)
type sliceValue struct{ dst *[]string }

func (s *sliceValue) String() string {
	if s.dst == nil { return "" }
	return fmt.Sprint(*s.dst)
}
func (s *sliceValue) Set(v string) error {
	*s.dst = append(*s.dst, v)
	return nil
}

// Register wires shared flags onto fs and returns a pointer to the “no-header” bool
// that the caller can use to set Common.Header = !noHeader after parsing.
func Register(fs *flag.FlagSet, c *Common) *bool {
	// Inputs
	fs.StringVar(&c.PrimerFile, "primers", "", "TSV primer file")
	fs.StringVar(&c.Fwd, "forward", "", "forward primer (5'→3')")
	fs.StringVar(&c.Rev, "reverse", "", "reverse primer (5'→3')")
	fs.StringVar(&c.PrimerFile, "p", "", "alias of --primers")
	fs.StringVar(&c.Fwd, "f", "", "alias of --forward")
	fs.StringVar(&c.Rev, "r", "", "alias of --reverse")
	seqVal := &sliceValue{dst: &c.SeqFiles}
	fs.Var(seqVal, "sequences", "FASTA file(s) (repeatable) or '-'")
	fs.Var(seqVal, "s", "alias of --sequences")

	// PCR
	fs.IntVar(&c.Mismatches, "mismatches", 0, "max mismatches per primer [0]")
	fs.IntVar(&c.MinLen, "min-length", 0, "minimum product length [0]")
	fs.IntVar(&c.MaxLen, "max-length", 2000, "maximum product length [2000]")
	fs.IntVar(&c.HitCap, "hit-cap", 10000, "max matches stored per primer/window (0=unlimited) [10000]")
	fs.IntVar(&c.TerminalWindow, "terminal-window", -1, "3' terminal window (0=allow, -1=auto) [-1]")
	fs.StringVar(&c.Mode, "mode", "realistic", "matching mode: realistic | debug")
	fs.IntVar(&c.Mismatches, "m", 0, "alias of --mismatches")

	// Performance
	fs.IntVar(&c.Threads, "threads", 0, "worker threads (0=all CPUs) [0]")
	fs.IntVar(&c.ChunkSize, "chunk-size", 0, "split sequences into N-bp windows (0=no chunking) [0]")
	fs.IntVar(&c.SeedLength, "seed-length", 12, "seed length for multi-pattern scan (0=auto) [12]")
	fs.IntVar(&c.Threads, "t", 0, "alias of --threads")
	fs.BoolVar(&c.Circular, "circular", false, "treat each FASTA record as circular [false]")
	fs.BoolVar(&c.Circular, "c", false, "alias of --circular")

	// Output
	fs.StringVar(&c.Output, "output", "text", "output: text | json | jsonl | fasta [text]")
	fs.StringVar(&c.Output, "o", "text", "alias of --output")
	fs.BoolVar(&c.Products, "products", false, "emit product sequences [false]")
	fs.BoolVar(&c.Pretty, "pretty", false, "pretty ASCII alignment block (text) [false]")
	fs.BoolVar(&c.Sort, "sort", false, "sort outputs deterministically [false]")
	noHeader := false
	fs.BoolVar(&noHeader, "no-header", false, "suppress header line [false]")
	fs.IntVar(&c.NoMatchExitCode, "no-match-exit-code", 1, "exit code when no amplicons found [1]")

	// Misc
	fs.BoolVar(&c.Quiet, "quiet", false, "suppress non-essential warnings [false]")
	fs.BoolVar(&c.Quiet, "q", false, "alias of --quiet")
	fs.BoolVar(&c.Version, "v", false, "print version and exit [false]")
	fs.BoolVar(&c.Version, "version", false, "print version and exit [false]")

	return &noHeader
}

// AfterParse finalizes header and expands positionals, then runs shared validation.
func AfterParse(fs *flag.FlagSet, c *Common, noHeader *bool, posArgs []string) error {
	c.Header = !*noHeader

	if len(posArgs) > 0 {
		exp, err := cliutil.ExpandPositionals(posArgs)
		if err != nil {
			return err
		}
		c.SeqFiles = append(c.SeqFiles, exp...)
	}
	return Validate(c)
}

// Validate applies shared CLI invariants used by all tools.
func Validate(c *Common) error {
	usingFile := c.PrimerFile != ""
	usingInline := c.Fwd != "" || c.Rev != ""
	switch {
	case usingFile && usingInline:
		return errors.New("--primers conflicts with --forward/--reverse")
	case usingInline && (c.Fwd == "" || c.Rev == ""):
		return errors.New("--forward and --reverse must be supplied together")
	case !usingFile && !usingInline:
		return errors.New("provide --primers or --forward/--reverse")
	}
	if len(c.SeqFiles) == 0 {
		return errors.New("at least one sequence file is required")
	}
	if c.Threads < 0 {
		return errors.New("--threads must be ≥ 0")
	}
	if c.ChunkSize < 0 {
		return errors.New("--chunk-size must be ≥ 0")
	}
	if c.HitCap < 0 {
		return errors.New("--hit-cap must be ≥ 0")
	}
	switch c.Output {
	case "text", "json", "jsonl", "fasta":
	default:
		return fmt.Errorf("invalid --output %q", c.Output)
	}
	if c.TerminalWindow < -1 {
		return errors.New("--terminal-window must be ≥ -1")
	}
	if c.NoMatchExitCode < 0 || c.NoMatchExitCode > 255 {
		return errors.New("--no-match-exit-code must be between 0 and 255")
	}
	return nil
}

===== END ./internal/clibase/common.go =====

===== BEGIN ./internal/cliutil/cliutil.go =====
// internal/cliutil/cliutil.go
package cliutil

import (
	"flag"
	"fmt"
	"path/filepath"
	"strings"
)

// BoolFlags returns names of flags that don't require a value.
func BoolFlags(fs *flag.FlagSet) map[string]bool {
	m := map[string]bool{}
	fs.VisitAll(func(f *flag.Flag) {
		if bf, ok := f.Value.(interface{ IsBoolFlag() bool }); ok && bf.IsBoolFlag() {
			m[f.Name] = true
		}
	})
	return m
}

// SplitFlagsAndPositionals separates flag-like args from positionals,
// preserving '-','--','--x=y' semantics. Use before fs.Parse(flagArgs).
func SplitFlagsAndPositionals(fs *flag.FlagSet, argv []string) (flagArgs, posArgs []string) {
	boolFlags := BoolFlags(fs)
	for i := 0; i < len(argv); i++ {
		arg := argv[i]
		if arg == "--" {
			posArgs = append(posArgs, argv[i+1:]...)
			break
		}
		if arg == "-" {
			posArgs = append(posArgs, arg)
			continue
		}
		if strings.HasPrefix(arg, "-") {
			if strings.Contains(arg, "=") {
				flagArgs = append(flagArgs, arg)
				continue
			}
			name := strings.TrimLeft(arg, "-")
			if eq := strings.IndexByte(name, '='); eq >= 0 {
				name = name[:eq]
			}
			needsVal := !boolFlags[name]
			flagArgs = append(flagArgs, arg)
			if needsVal && i+1 < len(argv) {
				flagArgs = append(flagArgs, argv[i+1])
				i++
			}
			continue
		}
		posArgs = append(posArgs, arg)
	}
	return
}

func hasGlobMeta(s string) bool { return strings.ContainsAny(s, "*?[") }

// ExpandPositionals expands any globs among path-like positionals.
func ExpandPositionals(posArgs []string) ([]string, error) {
	var out []string
	for _, a := range posArgs {
		if a == "-" {
			out = append(out, a)
			continue
		}
		if hasGlobMeta(a) {
			m, err := filepath.Glob(a)
			if err != nil {
				return nil, fmt.Errorf("bad glob %q: %v", a, err)
			}
			if len(m) == 0 {
				return nil, fmt.Errorf("no input matched %q", a)
			}
			out = append(out, m...)
		} else {
			out = append(out, a)
		}
	}
	return out, nil
}

===== END ./internal/cliutil/cliutil.go =====

===== BEGIN ./internal/cliutil/cliutil_test.go =====
package cliutil

import (
	"flag"
	"os"
	"path/filepath"
	"testing"
)

func TestSplitFlagsAndPositionals(t *testing.T) {
	fs := flag.NewFlagSet("x", flag.ContinueOnError)
	var b bool
	fs.BoolVar(&b, "bool", false, "")
	flagArgs, posArgs := SplitFlagsAndPositionals(fs, []string{"--bool", "pos1", "--", "pos2"})
	if len(flagArgs) != 1 || len(posArgs) != 2 || posArgs[0] != "pos1" || posArgs[1] != "pos2" {
		t.Fatalf("unexpected split: %v / %v", flagArgs, posArgs)
	}
}

func TestExpandPositionals(t *testing.T) {
	dir := t.TempDir()
	a := filepath.Join(dir, "a.fa")
	b := filepath.Join(dir, "b.fa")
	_ = os.WriteFile(a, []byte(">a\nA\n"), 0644)
	_ = os.WriteFile(b, []byte(">b\nA\n"), 0644)
	got, err := ExpandPositionals([]string{filepath.Join(dir, "*.fa")})
	if err != nil || len(got) != 2 {
		t.Fatalf("expand: err=%v got=%v", err, got)
	}
}

===== END ./internal/cliutil/cliutil_test.go =====

===== BEGIN ./internal/cmdutil/run.go =====
package cmdutil

import (
	"context"

	"ipcr/internal/engine"
	"ipcr/internal/pipeline"
	"ipcr/internal/primer"
)

// RunStream runs the shared pipeline, applies a visitor, and streams results via send.
// NOTE: now takes a pipeline.Simulator (not *engine.Engine).
func RunStream[T any](
	ctx context.Context,
	cfg pipeline.Config,
	seqFiles []string,
	pairs []primer.Pair,
	sim pipeline.Simulator,
	visit func(engine.Product) (bool, T, error),
	send func(T) error,
) (int, error) {
	total := 0
	err := pipeline.ForEachProduct(ctx, cfg, seqFiles, pairs, sim, func(p engine.Product) error {
		keep, out, vErr := visit(p)
		if vErr != nil {
			return vErr
		}
		if !keep {
			return nil
		}
		if err := send(out); err != nil {
			return err
		}
		total++
		return nil
	})
	return total, err
}

===== END ./internal/cmdutil/run.go =====

===== BEGIN ./internal/common/ids.go =====
// internal/common/ids.go
package common

import (
	"strconv"
	"strings"
)

// SplitChunkSuffix extracts the base ID and the chunk's start offset if the
// input looks like "record_id:123-456". It returns base, start, ok.
func SplitChunkSuffix(id string) (string, int, bool) {
	colon := strings.LastIndex(id, ":")
	if colon == -1 || colon == len(id)-1 {
		return id, 0, false
	}
	suffix := id[colon+1:]
	dash := strings.IndexByte(suffix, '-')
	if dash == -1 {
		return id, 0, false
	}
	startStr := suffix[:dash]
	start, err := strconv.Atoi(startStr)
	if err != nil {
		return id, 0, false
	}
	return id[:colon], start, true
}

===== END ./internal/common/ids.go =====

===== BEGIN ./internal/common/sort.go =====
// internal/common/sort.go
package common

import (
	"ipcr/internal/engine"
	"ipcr/internal/probeoutput"
	"sort"
)

// LessProduct defines a stable order for products (for -sort).
func LessProduct(a, b engine.Product) bool {
	if a.SequenceID != b.SequenceID {
		return a.SequenceID < b.SequenceID
	}
	if a.Start != b.Start {
		return a.Start < b.Start
	}
	if a.End != b.End {
		return a.End < b.End
	}
	if a.Type != b.Type {
		return a.Type < b.Type
	}
	return a.ExperimentID < b.ExperimentID
}

func SortProducts(ps []engine.Product) {
	sort.Slice(ps, func(i, j int) bool { return LessProduct(ps[i], ps[j]) })
}

func SortAnnotated(list []probeoutput.AnnotatedProduct) {
	sort.Slice(list, func(i, j int) bool {
		return LessProduct(list[i].Product, list[j].Product)
	})
}

===== END ./internal/common/sort.go =====

===== BEGIN ./internal/engine/doc.go =====
// Package engine contains the PCR simulation core. It never imports app, writers,
// cli, or pipeline; keep it domain-only.
//
// External outputs must not depend on the internal shape here — use pkg/api
// for stable wire types (JSON/JSONL v1).
package engine

===== END ./internal/engine/doc.go =====

===== BEGIN ./internal/engine/engine.go =====
// internal/engine/engine.go
package engine

import (
	"sort"

	"ipcr/internal/primer"
)

// Config holds PCR simulation parameters.
type Config struct {
	MaxMM          int
	TerminalWindow int // N bases at primer 3' end where mismatches are disallowed (0=allow)
	MinLen         int
	MaxLen         int
	HitCap         int
	NeedSites      bool // only compute FwdSite/RevSite for pretty text
	SeedLen        int  // seed length for multi-pattern scan (0=auto/full-length as implemented in seed.go)
	Circular       bool // treat templates as circular if true
}

// Engine runs PCR simulations with given config.
type Engine struct {
	cfg Config
}

// New creates a new Engine.
func New(c Config) *Engine { return &Engine{cfg: c} }

// SetHitCap updates the hit cap after creation.
func (e *Engine) SetHitCap(n int) { e.cfg.HitCap = n }

// -------------------- Existing single-pair path (kept) ----------------------
func (e *Engine) Simulate(seqID string, seq []byte, p primer.Pair) []Product {
	minL := p.MinProduct
	maxL := p.MaxProduct
	if minL == 0 { minL = e.cfg.MinLen }
	if maxL == 0 { maxL = e.cfg.MaxLen }

	a := []byte(p.Forward)
	b := []byte(p.Reverse)
	ra := primer.RevComp(a)
	rb := primer.RevComp(b)

	hc := e.cfg.HitCap
	tw := e.cfg.TerminalWindow

	fwdA := primer.FindMatches(seq, a,  e.cfg.MaxMM, hc, tw)
	fwdB := primer.FindMatches(seq, b,  e.cfg.MaxMM, hc, tw)
	revAraw := primer.FindMatches(seq, ra, e.cfg.MaxMM, hc, 0)
	revBraw := primer.FindMatches(seq, rb, e.cfg.MaxMM, hc, 0)

	revA := filterLeftTW(revAraw, tw)
	revB := filterLeftTW(revBraw, tw)

	return e.joinProducts(seqID, seq, p, fwdA, fwdB, revA, revB)
}

// -------------------- Seeded batch path (all pairs per chunk) --------------

type perPair struct {
	fwdA []primer.Match
	fwdB []primer.Match
	revA []primer.Match // rc(A) verified on forward genome
	revB []primer.Match // rc(B) verified on forward genome
}

// SimulateBatch scans seeds for all pairs in one pass, verifies candidates,
// then joins per pair to produce Products.
func (e *Engine) SimulateBatch(seqID string, seq []byte, pairs []primer.Pair) []Product {
	if len(pairs) == 0 { return nil }

	// Build seeds (exact A/C/G/T only) and AC automaton
	seeds, have := BuildSeeds(pairs, e.cfg.SeedLen, e.cfg.TerminalWindow)
	nodes, _ := buildAC(seeds)

	per := make([]perPair, len(pairs))

	// Precompute primers once per pair (hoisted RC)
	fwdABytes := make([][]byte, len(pairs))
	fwdBBytes := make([][]byte, len(pairs))
	rcA := make([][]byte, len(pairs))
	rcB := make([][]byte, len(pairs))
	for i := range pairs {
		fwdABytes[i] = []byte(pairs[i].Forward)
		fwdBBytes[i] = []byte(pairs[i].Reverse)
		rcA[i] = primer.RevComp(fwdABytes[i])
		rcB[i] = primer.RevComp(fwdBBytes[i])
	}

	// per-orientation dedup (start positions)
	seenA := make([]map[int]struct{}, len(pairs))
	seenB := make([]map[int]struct{}, len(pairs))
	seena := make([]map[int]struct{}, len(pairs))
	seenb := make([]map[int]struct{}, len(pairs))
	for i := range pairs {
		seenA[i], seenB[i] = make(map[int]struct{}), make(map[int]struct{})
		seena[i], seenb[i] = make(map[int]struct{}), make(map[int]struct{})
	}

	// Verify around seed hits
	hits := scanAC(seq, nodes, seeds)
	maxMM := e.cfg.MaxMM
	tw := e.cfg.TerminalWindow

	for _, h := range hits {
		s := seeds[h.SeedIdx]
		switch s.Which {
		case 'A':
			start := h.Pos - s.SeedOffset
			if _, dup := seenA[s.PairIdx][start]; dup { break }
			if m, ok := verifyAt(seq, start, fwdABytes[s.PairIdx], maxMM, 0, tw); ok {
				seenA[s.PairIdx][start] = struct{}{}
				if e.cfg.HitCap == 0 || len(per[s.PairIdx].fwdA) < e.cfg.HitCap {
					per[s.PairIdx].fwdA = append(per[s.PairIdx].fwdA, m)
				}
			}
		case 'B':
			start := h.Pos - s.SeedOffset
			if _, dup := seenB[s.PairIdx][start]; dup { break }
			if m, ok := verifyAt(seq, start, fwdBBytes[s.PairIdx], maxMM, 0, tw); ok {
				seenB[s.PairIdx][start] = struct{}{}
				if e.cfg.HitCap == 0 || len(per[s.PairIdx].fwdB) < e.cfg.HitCap {
					per[s.PairIdx].fwdB = append(per[s.PairIdx].fwdB, m)
				}
			}
		case 'a': // rc(A) verified on forward genome; original 3' window is LEFT end here
			start := h.Pos
			if _, dup := seena[s.PairIdx][start]; dup { break }
			if m, ok := verifyAt(seq, start, rcA[s.PairIdx], maxMM, tw, 0); ok {
				seena[s.PairIdx][start] = struct{}{}
				if e.cfg.HitCap == 0 || len(per[s.PairIdx].revA) < e.cfg.HitCap {
					per[s.PairIdx].revA = append(per[s.PairIdx].revA, m)
				}
			}
		case 'b': // rc(B)
			start := h.Pos
			if _, dup := seenb[s.PairIdx][start]; dup { break }
			if m, ok := verifyAt(seq, start, rcB[s.PairIdx], maxMM, tw, 0); ok {
				seenb[s.PairIdx][start] = struct{}{}
				if e.cfg.HitCap == 0 || len(per[s.PairIdx].revB) < e.cfg.HitCap {
					per[s.PairIdx].revB = append(per[s.PairIdx].revB, m)
				}
			}
		}
	}

	// Fallback for orientations lacking seeds (ambiguous primers etc.)
	for i := range pairs {
		hc := e.cfg.HitCap
		if !have[i]['A'] {
			per[i].fwdA = primer.FindMatches(seq, fwdABytes[i], e.cfg.MaxMM, hc, tw)
		}
		if !have[i]['B'] {
			per[i].fwdB = primer.FindMatches(seq, fwdBBytes[i], e.cfg.MaxMM, hc, tw)
		}
		if !have[i]['a'] {
			raw := primer.FindMatches(seq, rcA[i], e.cfg.MaxMM, hc, 0)
			per[i].revA = filterLeftTW(raw, tw)
		}
		if !have[i]['b'] {
			raw := primer.FindMatches(seq, rcB[i], e.cfg.MaxMM, hc, 0)
			per[i].revB = filterLeftTW(raw, tw)
		}
	}

	// Join per pair
	var out []Product
	for i := range pairs {
		out = append(out, e.joinProducts(seqID, seq, pairs[i],
			per[i].fwdA, per[i].fwdB, per[i].revA, per[i].revB)...)
	}
	return out
}

func filterLeftTW(ms []primer.Match, tw int) []primer.Match {
	if tw <= 0 { return ms }
	out := make([]primer.Match, 0, len(ms))
outer:
	for _, m := range ms {
		for _, j := range m.MismatchIdx {
			if j < tw { continue outer }
		}
		out = append(out, m)
	}
	return out
}

// -------------------------- Join & helpers ----------------------------------

func (e *Engine) joinProducts(seqID string, seq []byte, p primer.Pair,
	fwdA, fwdB, revA, revB []primer.Match,
) []Product {
	minL := p.MinProduct
	maxL := p.MaxProduct
	if minL == 0 { minL = e.cfg.MinLen }
	if maxL == 0 { maxL = e.cfg.MaxLen }

	a := []byte(p.Forward)
	b := []byte(p.Reverse)
	alen := len(a)
	blen := len(b)

	flip := func(n int, idx []int) []int {
		if len(idx) == 0 { return nil }
		out := make([]int, len(idx))
		for i, v := range idx { out[i] = n - 1 - v }
		return out
	}

	var out []Product

	// --- A (fwd) × rc(B) => "forward"
	bStarts := make([]int, len(revB))
	for i, m := range revB { bStarts[i] = m.Pos }
	if !sort.IntsAreSorted(bStarts) {
		sort.Ints(bStarts)
		sort.SliceStable(revB, func(i, j int) bool { return revB[i].Pos < revB[j].Pos })
	}
	for _, ma := range fwdA {
		last := len(seq) - blen
		lo := ma.Pos + 1 // strictly to the right
		if minL > 0 {
			lo = ma.Pos + minL - blen
			if lo <= ma.Pos { lo = ma.Pos + 1 }
		}
		if lo < 0 { lo = 0 }
		hi := last
		if maxL > 0 {
			hi = ma.Pos + maxL - blen
			if hi > last { hi = last }
		}
		if hi >= lo {
			iMin := sort.SearchInts(bStarts, lo)
			iMax := sort.Search(len(bStarts), func(i int) bool { return bStarts[i] > hi }) - 1
			if iMin < 0 { iMin = 0 }
			if iMax >= len(bStarts) { iMax = len(bStarts) - 1 }
			if iMin <= iMax {
				// Descending: farthest-right first (restores legacy test expectations)
				for j := iMax; j >= iMin; j-- {
					bStart := bStarts[j]
					mb := revB[j]
					end := bStart + blen
					length := end - ma.Pos
					if (minL != 0 && length < minL) || (maxL != 0 && length > maxL) { continue }

					var fwdSite, revSite string
					if e.cfg.NeedSites {
						if ma.Pos+alen <= len(seq) { fwdSite = string(seq[ma.Pos:ma.Pos+alen]) }
						if bStart+blen <= len(seq) { revSite = string(primer.RevComp(seq[bStart : bStart+blen])) }
					}
					out = append(out, Product{
						ExperimentID:   p.ID,
						SequenceID:     seqID,
						Start:          ma.Pos,
						End:            end,
						Length:         length,
						Type:           "forward",
						FwdMM:          ma.Mismatches,
						RevMM:          mb.Mismatches,
						FwdMismatchIdx: ma.MismatchIdx,
						RevMismatchIdx: flip(blen, mb.MismatchIdx),
						FwdPrimer:      p.Forward,
						RevPrimer:      p.Reverse,
						FwdSite:        fwdSite,
						RevSite:        revSite,
					})
				}
			}
		}

		// Circular wrap-around: allow rev match before forward match
		if e.cfg.Circular {
			// segment from forward to end: X; need remainder on the left to meet min/max
			X := len(seq) - ma.Pos
			loWrap := 0
			if minL > 0 {
				needed := minL - X - blen
				if needed < 0 { needed = 0 }
				loWrap = needed
			}
			hiWrap := ma.Pos - 1
			if maxL > 0 {
				allowed := maxL - X - blen
				if allowed < hiWrap { hiWrap = allowed }
			}
			if hiWrap >= loWrap {
				iMinW := sort.SearchInts(bStarts, loWrap)
				iMaxW := sort.Search(len(bStarts), func(i int) bool { return bStarts[i] > hiWrap }) - 1
				if iMinW < 0 { iMinW = 0 }
				if iMaxW >= len(bStarts) { iMaxW = len(bStarts) - 1 }
				for j := iMaxW; j >= iMinW; j-- {
					bStart := bStarts[j]
					if bStart >= ma.Pos { continue }
					mb := revB[j]
					end := bStart + blen
					length := (len(seq) - ma.Pos) + end
					if (minL != 0 && length < minL) || (maxL != 0 && length > maxL) { continue }

					var fwdSite, revSite string
					if e.cfg.NeedSites {
						if ma.Pos+alen <= len(seq) { fwdSite = string(seq[ma.Pos:ma.Pos+alen]) }
						if end <= len(seq) { revSite = string(primer.RevComp(seq[bStart:end])) }
					}
					out = append(out, Product{
						ExperimentID:   p.ID,
						SequenceID:     seqID,
						Start:          ma.Pos,
						End:            end,
						Length:         length,
						Type:           "forward",
						FwdMM:          ma.Mismatches,
						RevMM:          mb.Mismatches,
						FwdMismatchIdx: ma.MismatchIdx,
						RevMismatchIdx: flip(blen, mb.MismatchIdx),
						FwdPrimer:      p.Forward,
						RevPrimer:      p.Reverse,
						FwdSite:        fwdSite,
						RevSite:        revSite,
					})
				}
			}
		}
	}

	// --- B (fwd) × rc(A) => "revcomp"
	aStarts := make([]int, len(revA))
	for i, m := range revA { aStarts[i] = m.Pos }
	if !sort.IntsAreSorted(aStarts) {
		sort.Ints(aStarts)
		sort.SliceStable(revA, func(i, j int) bool { return revA[i].Pos < revA[j].Pos })
	}
	for _, mb := range fwdB {
		last := len(seq) - alen
		lo := mb.Pos + 1
		if minL > 0 {
			lo = mb.Pos + minL - alen
			if lo <= mb.Pos { lo = mb.Pos + 1 }
		}
		if lo < 0 { lo = 0 }
		hi := last
		if maxL > 0 {
			hi = mb.Pos + maxL - alen
			if hi > last { hi = last }
		}
		if hi >= lo {
			iMin := sort.SearchInts(aStarts, lo)
			iMax := sort.Search(len(aStarts), func(i int) bool { return aStarts[i] > hi }) - 1
			if iMin < 0 { iMin = 0 }
			if iMax >= len(aStarts) { iMax = len(aStarts) - 1 }
			if iMin <= iMax {
				for j := iMax; j >= iMin; j-- {
					aStart := aStarts[j]
					ma := revA[j]
					end := aStart + alen
					length := end - mb.Pos
					if (minL != 0 && length < minL) || (maxL != 0 && length > maxL) { continue }

					var fwdSite, revSite string
					if e.cfg.NeedSites {
						if mb.Pos+blen <= len(seq) { fwdSite = string(seq[mb.Pos:mb.Pos+blen]) }
						if aStart+alen <= len(seq) { revSite = string(primer.RevComp(seq[aStart:aStart+alen])) }
					}
					out = append(out, Product{
						ExperimentID:   p.ID,
						SequenceID:     seqID,
						Start:          mb.Pos,
						End:            end,
						Length:         length,
						Type:           "revcomp",
						FwdMM:          mb.Mismatches,
						RevMM:          ma.Mismatches,
						FwdMismatchIdx: mb.MismatchIdx,
						RevMismatchIdx: flip(alen, ma.MismatchIdx),
						FwdPrimer:      p.Reverse,
						RevPrimer:      p.Forward,
						FwdSite:        fwdSite,
						RevSite:        revSite,
					})
				}
			}
		}

		// Circular wrap-around: allow rc(A) before B forward match
		if e.cfg.Circular {
			X := len(seq) - mb.Pos
			loWrap := 0
			if minL > 0 {
				needed := minL - X - alen
				if needed < 0 { needed = 0 }
				loWrap = needed
			}
			hiWrap := mb.Pos - 1
			if maxL > 0 {
				allowed := maxL - X - alen
				if allowed < hiWrap { hiWrap = allowed }
			}
			if hiWrap >= loWrap {
				iMinW := sort.SearchInts(aStarts, loWrap)
				iMaxW := sort.Search(len(aStarts), func(i int) bool { return aStarts[i] > hiWrap }) - 1
				if iMinW < 0 { iMinW = 0 }
				if iMaxW >= len(aStarts) { iMaxW = len(aStarts) - 1 }
				for j := iMaxW; j >= iMinW; j-- {
					aStart := aStarts[j]
					if aStart >= mb.Pos { continue }
					ma := revA[j]
					end := aStart + alen
					length := (len(seq) - mb.Pos) + end
					if (minL != 0 && length < minL) || (maxL != 0 && length > maxL) { continue }

					var fwdSite, revSite string
					if e.cfg.NeedSites {
						if mb.Pos+blen <= len(seq) { fwdSite = string(seq[mb.Pos:mb.Pos+blen]) }
						if end <= len(seq) { revSite = string(primer.RevComp(seq[aStart:end])) }
					}
					out = append(out, Product{
						ExperimentID:   p.ID,
						SequenceID:     seqID,
						Start:          mb.Pos,
						End:            end,
						Length:         length,
						Type:           "revcomp",
						FwdMM:          mb.Mismatches,
						RevMM:          ma.Mismatches,
						FwdMismatchIdx: mb.MismatchIdx,
						RevMismatchIdx: flip(alen, ma.MismatchIdx),
						FwdPrimer:      p.Reverse,
						RevPrimer:      p.Forward,
						FwdSite:        fwdSite,
						RevSite:        revSite,
					})
				}
			}
		}
	}
	return out
}

===== END ./internal/engine/engine.go =====

===== BEGIN ./internal/engine/engine_test.go =====
// internal/engine/engine_test.go
package engine

import (
	"bytes"
	"testing"

	"ipcr/internal/primer"
)

// Minimal simulation: should find one full-length product
func TestSimulateMinimal(t *testing.T) {
	seq := []byte("ACGTACGTACGT")
	pair := primer.Pair{
		ID:      "test",
		Forward: "ACG",
		Reverse: "ACG",
	}

	eng := New(Config{MaxMM: 0, TerminalWindow: 0})
	got := eng.Simulate("dummySeq", seq, pair)

	if len(got) == 0 {
		t.Fatal("expected at least one product")
	}

	first := got[0]
	if first.Start != 0 || first.End != 12 || first.Length != 12 {
		t.Errorf("unexpected product coords: %+v, want Start=0 End=12 Length=12", first)
	}

	wantSeq := seq[first.Start:first.End]
	if !bytes.Equal(wantSeq, primer.RevComp(primer.RevComp(wantSeq))) {
		t.Error("round-trip revcomp failed")
	}
}

// Should filter product lengths correctly and set type
func TestLengthFilteringAndType(t *testing.T) {
	seq := []byte("ACGTACGTACGT")
	pair := primer.Pair{
		ID:         "t",
		Forward:    "ACG",
		Reverse:    "ACG",
		MinProduct: 10,
		MaxProduct: 12,
	}

	eng := New(Config{MaxMM: 0, TerminalWindow: 0})
	hits := eng.Simulate("seq", seq, pair)

	if len(hits) == 0 {
		t.Fatal("expected product within bounds")
	}
	for _, p := range hits {
		if p.Length < 10 || p.Length > 12 {
			t.Errorf("product length %d outside bounds", p.Length)
		}
	}
}

// Should return no products outside bounds
func TestLengthOutOfRange(t *testing.T) {
	seq := []byte("ACGTACGTACGT")
	pair := primer.Pair{
		ID:         "t2",
		Forward:    "ACG",
		Reverse:    "ACG",
		MinProduct: 5,
		MaxProduct: 7,
	}

	eng := New(Config{MaxMM: 0, TerminalWindow: 0})
	hits := eng.Simulate("seq", seq, pair)

	if len(hits) != 0 {
		t.Fatalf("expected zero products, got %d", len(hits))
	}
}

// Should detect at least one revcomp product
func TestRevcompProduct(t *testing.T) {
	seq := []byte("TTTACGACGTAAA")
	pair := primer.Pair{
		ID:      "rev",
		Forward: "ACG",
		Reverse: "TTT",
	}
	eng := New(Config{})
	hits := eng.Simulate("s", seq, pair)

	found := false
	for _, h := range hits {
		if h.Type == "revcomp" {
			found = true
			break
		}
	}
	if !found {
		t.Fatalf("expected at least one revcomp product, got %+v", hits)
	}
}

// Circular template should allow wrap-around amplicon when reverse site is left of forward site.
func TestCircularAmplicon(t *testing.T) {
	seq := []byte("TGACAAG") // 7 bp circular
	pair := primer.Pair{ID: "p1", Forward: "AG", Reverse: "TC"}

	// Linear mode: no amplicon for this configuration.
	engLin := New(Config{Circular: false, MaxMM: 0, MinLen: 0, MaxLen: 0})
	hitsLin := engLin.Simulate("seq1", seq, pair)
	if len(hitsLin) != 0 {
		t.Errorf("expected no amplicon in linear mode, got %d", len(hitsLin))
	}

	// Circular mode: should produce one wrap-around product.
	engCirc := New(Config{Circular: true, MaxMM: 0, MinLen: 0, MaxLen: 0})
	hitsCirc := engCirc.Simulate("seq1", seq, pair)
	if len(hitsCirc) != 1 {
		t.Fatalf("expected 1 amplicon in circular mode, got %d", len(hitsCirc))
	}
	prod := hitsCirc[0]
	if prod.Start <= prod.End {
		t.Errorf("expected wrap-around coordinates (Start > End), got Start=%d End=%d", prod.Start, prod.End)
	}
	expectedLen := len(seq) - prod.Start + prod.End
	if prod.Length != expectedLen {
		t.Errorf("expected product length %d, got %d", expectedLen, prod.Length)
	}
}

===== END ./internal/engine/engine_test.go =====

===== BEGIN ./internal/engine/product.go =====
package engine

type Product struct {
	ExperimentID string `json:"experiment_id"`
	SequenceID   string `json:"sequence_id"`
	Start        int    `json:"start"`
	End          int    `json:"end"`
	Length       int    `json:"length"`
	Type         string `json:"type"`

	// mismatch summary & positions (primer 5'→3', 0-based)
	FwdMM          int   `json:"fwd_mm,omitempty"`
	RevMM          int   `json:"rev_mm,omitempty"`
	FwdMismatchIdx []int `json:"fwd_mismatch_idx,omitempty"`
	RevMismatchIdx []int `json:"rev_mismatch_idx,omitempty"`

	// pretty support: primer seqs and matching target sites (in the same 5'→3' orientation)
	FwdPrimer string `json:"-"`
	RevPrimer string `json:"-"`
	FwdSite   string `json:"-"`
	RevSite   string `json:"-"`

	// Optional amplicon sequence
	Seq string `json:"seq,omitempty"`

	SourceFile string `json:"source_file"`
}

===== END ./internal/engine/product.go =====

===== BEGIN ./internal/engine/seed.go =====
// internal/engine/seed.go
package engine

import (
	"ipcr/internal/primer"
)

// ---- Seeds & AC automaton --------------------------------------------------

type Seed struct {
	PairIdx    int   // which primer pair
	Which      byte  // 'A','B','a','b' (lower = rc primer scanned on forward strand)
	Pat        []byte
	PrimerLen  int
	SeedOffset int   // start offset of seed within the primer used for verification
}

// choose an exact 3'‑anchored seed length (exact seeds only)
func seedLenFor(primerLen int, cfg int) int {
	// cfg == 0 => auto (min(12, primerLen))
	if cfg <= 0 {
		if primerLen < 12 {
			return primerLen
		}
		return 12
	}
	if cfg > primerLen {
		return primerLen
	}
	if cfg < 1 {
		return 1
	}
	return cfg
}

func isACGT(b byte) bool { return b == 'A' || b == 'C' || b == 'G' || b == 'T' }
func isUnambigBytes(p []byte) bool {
	for _, c := range p {
		if !isACGT(c) { return false }
	}
	return true
}

// BuildSeeds: 3' suffix for forward primers; 5' prefix for rc‑primers.
// seedLen=0 => auto (min(12, primerLen)).
func BuildSeeds(pairs []primer.Pair, seedLen int, _ int) (seeds []Seed, has map[int]map[byte]bool) {
	seeds = make([]Seed, 0, 4*len(pairs))
	has = make(map[int]map[byte]bool, len(pairs))
	mark := func(i int, w byte) {
		m, ok := has[i]; if !ok { m = make(map[byte]bool, 4); has[i] = m }
		m[w] = true
	}
	for i, p := range pairs {
		a := []byte(p.Forward)
		b := []byte(p.Reverse)
		ra := primer.RevComp(a)
		rb := primer.RevComp(b)

		// Forward A seed (3' suffix)
		if len(a) > 0 {
			sl := seedLenFor(len(a), seedLen)
			suf := a[len(a)-sl:]
			if isUnambigBytes(suf) {
				seeds = append(seeds, Seed{PairIdx: i, Which: 'A', Pat: suf, PrimerLen: len(a), SeedOffset: len(a)-sl})
				mark(i, 'A')
			}
		}
		// Forward B seed (3' suffix)
		if len(b) > 0 {
			sl := seedLenFor(len(b), seedLen)
			suf := b[len(b)-sl:]
			if isUnambigBytes(suf) {
				seeds = append(seeds, Seed{PairIdx: i, Which: 'B', Pat: suf, PrimerLen: len(b), SeedOffset: len(b)-sl})
				mark(i, 'B')
			}
		}
		// RC(A) seed: 5' prefix of rc(A)
		if len(ra) > 0 {
			sl := seedLenFor(len(ra), seedLen)
			pre := ra[:sl]
			if isUnambigBytes(pre) {
				seeds = append(seeds, Seed{PairIdx: i, Which: 'a', Pat: pre, PrimerLen: len(ra), SeedOffset: 0})
				mark(i, 'a')
			}
		}
		// RC(B) seed: 5' prefix of rc(B)
		if len(rb) > 0 {
			sl := seedLenFor(len(rb), seedLen)
			pre := rb[:sl]
			if isUnambigBytes(pre) {
				seeds = append(seeds, Seed{PairIdx: i, Which: 'b', Pat: pre, PrimerLen: len(rb), SeedOffset: 0})
				mark(i, 'b')
			}
		}
	}
	return seeds, has
}

// ------------------------ Aho–Corasick (AC) -------------------------------

type acNode struct {
	next [4]int  // -1 means no edge; indices into nodes slice
	fail int
	out  []int   // seed indices ending here
}

func baseIdx(b byte) int {
	switch b {
	case 'A': return 0
	case 'C': return 1
	case 'G': return 2
	case 'T': return 3
	default:  return -1
	}
}

func buildAC(seeds []Seed) ([]acNode, []int) {
	nodes := make([]acNode, 1)
	for i := range nodes[0].next { nodes[0].next[i] = -1 }

	ends := make([]int, len(seeds)) // end node index for each seed
	// goto function
	for si, s := range seeds {
		state := 0
		for _, b := range s.Pat {
			ix := baseIdx(b)
			if ix < 0 {
				state = 0
				continue
			}
			if nodes[state].next[ix] == -1 {
				nodes[state].next[ix] = len(nodes)
				var nn acNode
				for k := range nn.next { nn.next[k] = -1 }
				nn.fail = 0
				nodes = append(nodes, nn)
			}
			state = nodes[state].next[ix]
		}
		nodes[state].out = append(nodes[state].out, si)
		ends[si] = state
	}

	// failure links (BFS)
	queue := make([]int, 0, len(nodes))
	for ch := 0; ch < 4; ch++ {
		nx := nodes[0].next[ch]
		if nx != -1 {
			nodes[nx].fail = 0
			queue = append(queue, nx)
		} else {
			nodes[0].next[ch] = 0
		}
	}
	for qh := 0; qh < len(queue); qh++ {
		r := queue[qh]
		for ch := 0; ch < 4; ch++ {
			s := nodes[r].next[ch]
			if s != -1 {
				queue = append(queue, s)
				f := nodes[r].fail
				nodes[s].fail = nodes[f].next[ch]
				nodes[s].out = append(nodes[s].out, nodes[nodes[s].fail].out...)
			} else {
				nodes[r].next[ch] = nodes[nodes[r].fail].next[ch]
			}
		}
	}
	return nodes, ends
}

type seedHit struct {
	SeedIdx int
	Pos     int // start position of the seed match in seq
}

// scanAC returns all seed matches (start coordinates).
func scanAC(seq []byte, nodes []acNode, seeds []Seed) []seedHit {
	var hits []seedHit
	state := 0
	for i := 0; i < len(seq); i++ {
		ix := baseIdx(seq[i])
		if ix < 0 {
			state = 0
			continue
		}
		state = nodes[state].next[ix]
		if len(nodes[state].out) == 0 { continue }
		for _, si := range nodes[state].out {
			hits = append(hits, seedHit{
				SeedIdx: si,
				Pos:     i - (len(seeds[si].Pat) - 1),
			})
		}
	}
	return hits
}

// ---------------------- Verification helpers -------------------------------

// verifyAt checks primer vs seq[start:] allowing up to maxMM mismatches,
// disallowing mismatches in [0,twLeft) (left end) and [n-twRight, n) (right end).
func verifyAt(seq []byte, start int, pr []byte, maxMM, twLeft, twRight int) (primer.Match, bool) {
	n := len(pr)
	if start < 0 || start+n > len(seq) { return primer.Match{}, false }
	cutLeft := twLeft
	if cutLeft < 0 { cutLeft = 0 }
	cutRightFrom := n - twRight
	if twRight <= 0 { cutRightFrom = n + 1 } // disable

	mm := 0
	var idx []int
	for j := 0; j < n; j++ {
		if !primer.BaseMatch(seq[start+j], pr[j]) {
			if j < cutLeft || j >= cutRightFrom { return primer.Match{}, false }
			mm++
			if mm > maxMM { return primer.Match{}, false }
			idx = append(idx, j)
		}
	}
	return primer.Match{Pos: start, Mismatches: mm, Length: n, MismatchIdx: idx}, true
}

===== END ./internal/engine/seed.go =====

===== BEGIN ./internal/fasta/reader.go =====
// internal/fasta/reader.go
package fasta

import (
	"bufio"
	"bytes"
	"compress/gzip"
	"fmt"
	"io"
	"os"
	"runtime"
	"strings"
)

// Record represents a parsed FASTA sequence chunk.
type Record struct {
	ID  string
	Seq []byte
}

// StreamChunks streams sequence windows (chunks) from a FASTA file.
// If win==0, yields whole records as a single chunk.
func StreamChunks(path string, win, overlap int) (<-chan Record, error) {
	rc, err := openReader(path)
	if err != nil {
		return nil, err
	}

	// Bigger buffer to reduce goroutine ping‑pong (was 4).
	out := make(chan Record, 2*runtime.NumCPU())
	go func() {
		defer rc.Close()
		defer close(out)

		r := bufio.NewReader(rc)
		var (
			id         string
			buf        []byte
			startCoord int
		)

		flushWindow := func(endCoord int) {
			if len(buf) == 0 {
				return
			}
			out <- Record{
				ID:  fmt.Sprintf("%s:%d-%d", id, startCoord, endCoord),
				Seq: bytes.Clone(buf), // copy; workers may mutate
			}
		}

		for {
			line, err := r.ReadBytes('\n')
			eof := err == io.EOF
			if len(line) > 0 && line[len(line)-1] == '\n' {
				line = line[:len(line)-1]
			}
			if eof && len(line) == 0 {
				break
			}
			if len(line) > 0 && line[0] == '>' {
				// New header: flush previous record (if any)
				if id != "" {
					flushWindow(startCoord + len(buf))
				}
				id = strings.Fields(string(line[1:]))[0]
				buf = buf[:0]
				startCoord = 0
				continue
			}
			// Sequence line
			line = bytes.ToUpper(line)
			for len(line) > 0 {
				rem := win - len(buf)
				if win == 0 {
					rem = len(line)
				}
				if rem > len(line) {
					rem = len(line)
				}
				buf = append(buf, line[:rem]...)
				line = line[rem:]

				// If buffer full, flush and slide window
				if win > 0 && len(buf) == win {
					flushWindow(startCoord + win)
					slide := win - overlap
					if slide < 1 {
						slide = win // avoid infinite loop
					}
					startCoord += slide
					// Allocation‑free slide: move tail in place and shrink.
					copy(buf, buf[slide:])
					buf = buf[:win-slide]
				}
			}
			if eof {
				break
			}
		}
		// Flush tail of last record
		if id != "" {
			flushWindow(startCoord + len(buf))
		}
	}()
	return out, nil
}

// multiReadCloser closes multiple io.Closers when Close() is called.
type multiReadCloser struct {
	io.Reader
	closers []io.Closer
}

func (m *multiReadCloser) Close() error {
	var err error
	for _, c := range m.closers {
		if cerr := c.Close(); cerr != nil && err == nil {
			err = cerr
		}
	}
	return err
}

func openReader(path string) (io.ReadCloser, error) {
	if path == "-" {
		return io.NopCloser(os.Stdin), nil
	}
	fh, err := os.Open(path)
	if err != nil {
		return nil, err
	}
	// Detect gzip by magic number (1F 8B), but also allow .gz by suffix
	var sig [2]byte
	n, _ := fh.Read(sig[:])
	_, _ = fh.Seek(0, io.SeekStart)
	if n == 2 && sig[0] == 0x1f && sig[1] == 0x8b || strings.HasSuffix(path, ".gz") {
		gr, err := gzip.NewReader(fh)
		if err != nil {
			fh.Close()
			return nil, err
		}
		return &multiReadCloser{Reader: gr, closers: []io.Closer{gr, fh}}, nil
	}
	return fh, nil
}

===== END ./internal/fasta/reader.go =====

===== BEGIN ./internal/fasta/reader_test.go =====
package fasta

import (
	"compress/gzip"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"testing"
	"time"
)

const plain = `>seq1
ACGT
>seq2
NNnn
`

// writeGz creates a gzipped FASTA file with provided data, returns the file path.
func writeGz(t *testing.T, data string) string {
	tmpdir := os.TempDir()
	path := filepath.Join(tmpdir, fmt.Sprintf("test-%d.fa.gz", time.Now().UnixNano()))
	fh, err := os.Create(path)
	if err != nil {
		t.Fatalf("tmp: %v", err)
	}
	gw := gzip.NewWriter(fh)
	if _, err := gw.Write([]byte(data)); err != nil {
		t.Fatalf("write gz: %v", err)
	}
	if err := gw.Close(); err != nil {
		t.Fatalf("close gzip: %v", err)
	}
	if err := fh.Sync(); err != nil {
		t.Fatalf("sync file: %v", err)
	}
	if err := fh.Close(); err != nil {
		t.Fatalf("close file: %v", err)
	}
	return path
}

func TestStreamGzip(t *testing.T) {
	gzPath := writeGz(t, plain)
	defer os.Remove(gzPath)

	ch, err := StreamChunks(gzPath, 0, 0)
	if err != nil {
		t.Fatalf("stream gz: %v", err)
	}

	var ids []string
	for r := range ch {
		ids = append(ids, r.ID)
	}

	if len(ids) != 2 || !strings.HasPrefix(ids[0], "seq1") || !strings.HasPrefix(ids[1], "seq2") {
		t.Fatalf("gzip parse failed, ids=%v", ids)
	}
}

func TestStreamStdin(t *testing.T) {
	// Fake stdin by swapping os.Stdin
	orig := os.Stdin
	r, w, _ := os.Pipe()
	os.Stdin = r
	defer func() { os.Stdin = orig }()

	// Write sample then close writer to signal EOF
	go func() {
		io.WriteString(w, plain)
		w.Close()
	}()

	ch, err := StreamChunks("-", 0, 0)
	if err != nil {
		t.Fatalf("stream stdin: %v", err)
	}
	count := 0
	for range ch {
		count++
	}
	if count != 2 {
		t.Fatalf("expected 2 records from stdin, got %d", count)
	}
}

===== END ./internal/fasta/reader_test.go =====

===== BEGIN ./internal/integration/integration_test.go =====
package integration

import (
	"bufio"
	"bytes"
	"encoding/json"
	"fmt"
	"os"
	"sort"
	"strconv"
	"strings"
	"testing"

	"ipcr/internal/app"
	"ipcr/internal/engine"
	"ipcr/internal/output"
	"ipcr/pkg/api"
)

func write(t *testing.T, fn, data string) string {
	t.Helper()
	if err := os.WriteFile(fn, []byte(data), 0644); err != nil {
		t.Fatalf("write %s: %v", fn, err)
	}
	return fn
}

func TestEndToEnd(t *testing.T) {
	fa := write(t, "itest.fa", ">s\nACGTACGTACGT\n")
	defer os.Remove(fa)

	var out, errBuf bytes.Buffer
	code := app.Run([]string{
		"--forward", "ACG",
		"--reverse", "ACG",
		"--sequences", fa,
	}, &out, &errBuf)

	if code != 0 {
		t.Fatalf("run exit %d, err=%s", code, errBuf.String())
	}
	if out.Len() == 0 {
		t.Fatalf("expected text output")
	}
}

func TestParallelMatchesEqualSerial(t *testing.T) {
	fa := write(t, "par.fa", ">s\nACGTACGTACGT\n")
	defer os.Remove(fa)

	run := func(threads int) string {
		var out, errB bytes.Buffer
		code := app.Run([]string{
			"--forward", "ACG",
			"--reverse", "ACG",
			"--sequences", fa,
			"--threads", fmt.Sprint(threads),
			"--output", "json",
			"--sort",
		}, &out, &errB)
		if code != 0 {
			t.Fatalf("exit %d err %s", code, errB.String())
		}
		return out.String()
	}

	serial := run(1)
	parallel := run(4)

	if serial != parallel {
		t.Fatalf("parallel output differs from serial\nserial: %s\nparallel:%s", serial, parallel)
	}
}

// text vs TSV parity still uses engine.Product directly for the writer API
func TestTextVsTSVParity(t *testing.T) {
	list := []engine.Product{
		{SequenceID: "s:0-12", ExperimentID: "x", Start: 0, End: 12, Length: 12, Type: "forward", FwdMM: 0, RevMM: 1, FwdMismatchIdx: nil, RevMismatchIdx: []int{2}},
		{SequenceID: "s:0-12", ExperimentID: "x", Start: 4, End: 8, Length: 4, Type: "revcomp", FwdMM: 1, RevMM: 0, FwdMismatchIdx: []int{1}, RevMismatchIdx: nil},
	}

	var textB, tsvB bytes.Buffer

	ch := make(chan engine.Product, len(list))
	for _, p := range list { ch <- p }
	close(ch)
	if err := output.StreamText(&textB, ch, false, false); err != nil {
		t.Fatalf("stream text: %v", err)
	}

	if err := output.WriteTSV(&tsvB, list, false); err != nil {
		t.Fatalf("write tsv: %v", err)
	}

	if textB.String() != tsvB.String() {
		t.Fatalf("parity mismatch\ntext:\n%s\ntsv:\n%s", textB.String(), tsvB.String())
	}
}

// ---- helpers for JSON canonicalization (now using api.ProductV1) ----

func baseAndOffset(id string) (string, int) {
	colon := strings.LastIndex(id, ":")
	if colon == -1 || colon == len(id)-1 { return id, 0 }
	suffix := id[colon+1:]
	dash := strings.IndexByte(suffix, '-')
	if dash == -1 { return id, 0 }
	startStr := suffix[:dash]
	if start, err := strconv.Atoi(startStr); err == nil {
		return id[:colon], start
	}
	return id, 0
}

// canonicalizeJSON parses the JSON array of v1 products and normalizes chunked coords.
func canonicalizeJSON(js string) ([]string, error) {
	var prods []api.ProductV1
	if err := json.Unmarshal([]byte(js), &prods); err != nil {
		return nil, err
	}
	uniq := make(map[string]struct{}, len(prods))
	for _, p := range prods {
		base, off := baseAndOffset(p.SequenceID)
		gs, ge := p.Start+off, p.End+off
		sig := fmt.Sprintf("%s\t%s\t%d\t%d\t%d\t%s",
			base, p.ExperimentID, gs, ge, p.Length, p.Type)
		uniq[sig] = struct{}{}
	}
	out := make([]string, 0, len(uniq))
	for k := range uniq {
		out = append(out, k)
	}
	sort.Strings(out)
	return out, nil
}

func TestChunkingKeepsBoundaryHits(t *testing.T) {
	fa := write(t, "chunk.fa", ">s\nACGTACGTACGTACGTACGTACGTACGT\n")
	defer os.Remove(fa)

	runJSON := func(chunk int) string {
		var out, errB bytes.Buffer
		args := []string{
			"--forward", "ACGTAC",
			"--reverse", "ACGTAC",
			"--sequences", fa,
			"--output", "json",
			"--sort",
			"--max-length", "8",
		}
		if chunk > 0 {
			args = append(args, "--chunk-size", fmt.Sprint(chunk))
		}
		code := app.Run(args, &out, &errB)
		if code != 0 {
			t.Fatalf("exit %d err %s", code, errB.String())
		}
		return out.String()
	}

	noChunkJSON := runJSON(0)
	chunkedJSON := runJSON(16)

	nc, err := canonicalizeJSON(noChunkJSON)
	if err != nil { t.Fatalf("canonicalize no-chunk (json): %v", err) }
	ck, err := canonicalizeJSON(chunkedJSON)
	if err != nil { t.Fatalf("canonicalize chunked (json): %v", err) }

	if strings.Join(nc, "\n") != strings.Join(ck, "\n") {
		var rawNo, rawCh bytes.Buffer
		_ = app.Run([]string{
			"--forward", "ACGTAC", "--reverse", "ACGTAC",
			"--sequences", fa, "--output", "text", "--sort", "--no-header",
			"--max-length", "8",
		}, &rawNo, &bytes.Buffer{})
		_ = app.Run([]string{
			"--forward", "ACGTAC", "--reverse", "ACGTAC",
			"--sequences", fa, "--output", "text", "--sort", "--no-header",
			"--max-length", "8", "--chunk-size", "16",
		}, &rawCh, &bytes.Buffer{})

		t.Fatalf("chunked output differs from no-chunking\nno-chunk(norm):\n%s\nchunked(norm):\n%s\n\nno-chunk(text):\n%s\nchunked(text):\n%s",
			strings.Join(nc, "\n"), strings.Join(ck, "\n"),
			trimHead(rawNo.String()), trimHead(rawCh.String()))
	}
}

func trimHead(out string) string {
	var b strings.Builder
	sc := bufio.NewScanner(strings.NewReader(out))
	for sc.Scan() {
		line := strings.TrimSpace(sc.Text())
		if line == "" ||
			strings.HasPrefix(line, "sequence_id") ||
			strings.HasPrefix(line, "source_file") ||
			strings.HasPrefix(line, "FWD ") ||
			strings.HasPrefix(line, "REV ") {
			continue
		}
		b.WriteString(line)
		b.WriteByte('\n')
	}
	return b.String()
}

===== END ./internal/integration/integration_test.go =====

===== BEGIN ./internal/multiplexapp/app.go =====
// ./internal/multiplexapp/app.go
package multiplexapp

import (
	"bufio"
	"context"
	"errors"
	"flag"
	"fmt"
	"io"

	"ipcr/internal/appcore"
	"ipcr/internal/cli"
	"ipcr/internal/engine"
	"ipcr/internal/primer"
	"ipcr/internal/runutil"
	"ipcr/internal/version"
	"ipcr/internal/visitors"
	"ipcr/internal/writers"
)

func RunContext(parent context.Context, argv []string, stdout, stderr io.Writer) int {
	outw := bufio.NewWriter(stdout)
	defer outw.Flush()

	fs := cli.NewFlagSet("ipcr-multiplex")
	fs.SetOutput(io.Discard)

	if len(argv) == 0 {
		_, _ = cli.ParseArgs(fs, []string{"-h"})
		fs.SetOutput(outw)
		fs.Usage()
		if err := outw.Flush(); writers.IsBrokenPipe(err) { return 0 }
		if err != nil { fmt.Fprintln(stderr, err); return 3 }
		return 0
	}

	opts, err := cli.ParseArgs(fs, argv)
	if err != nil {
		if errors.Is(err, flag.ErrHelp) {
			fs.SetOutput(outw); fs.Usage()
			if e := outw.Flush(); writers.IsBrokenPipe(e) { return 0 }
			if e != nil { fmt.Fprintln(stderr, e); return 3 }
			return 0
		}
		fmt.Fprintln(stderr, err)
		fs.SetOutput(outw); fs.Usage()
		if e := outw.Flush(); writers.IsBrokenPipe(e) { return 0 }
		if e != nil { fmt.Fprintln(stderr, e); return 3 }
		return 2
	}

	if opts.Version {
		fmt.Fprintf(outw, "ipcr version %s (ipcr-multiplex)\n", version.Version)
		if e := outw.Flush(); writers.IsBrokenPipe(e) { return 0 }
		if e != nil { fmt.Fprintln(stderr, e); return 3 }
		return 0
	}

	// Primer pairs (supports TSV with many pairs = multiplex)
	var pairs []primer.Pair
	if opts.PrimerFile != "" {
		pairs, err = primer.LoadTSV(opts.PrimerFile)
		if err != nil { fmt.Fprintln(stderr, err); return 2 }
	} else {
		pairs = []primer.Pair{{
			ID:         "manual",
			Forward:    opts.Fwd,
			Reverse:    opts.Rev,
			MinProduct: opts.MinLen,
			MaxProduct: opts.MaxLen,
		}}
	}

	termWin := runutil.ComputeTerminalWindow(opts.Mode, opts.TerminalWindow)
	coreOpts := appcore.Options{
		SeqFiles:        opts.SeqFiles,
		MaxMM:           opts.Mismatches,
		TerminalWindow:  termWin,
		MinLen:          opts.MinLen,
		MaxLen:          opts.MaxLen,
		HitCap:          opts.HitCap,
		SeedLength:      opts.SeedLength,
		Circular:        opts.Circular,
		Threads:         opts.Threads,
		ChunkSize:       opts.ChunkSize,
		Quiet:           opts.Quiet,
		NoMatchExitCode: opts.NoMatchExitCode,
	}
	writer := appcore.NewProductWriterFactory(opts.Output, opts.Sort, opts.Header, opts.Pretty, opts.Products)

	// For now this is pass-through; later you can add per-panel constraints.
	return appcore.Run[engine.Product](parent, stdout, stderr, coreOpts, pairs, visitors.PassThrough{}.Visit, writer)
}

func Run(argv []string, stdout, stderr io.Writer) int {
	return RunContext(context.Background(), argv, stdout, stderr)
}

===== END ./internal/multiplexapp/app.go =====

===== BEGIN ./internal/nestedapp/app.go =====
// ./internal/nestedapp/app.go
package nestedapp

import (
	"bufio"
	"context"
	"errors"
	"flag"
	"fmt"
	"io"
	"strings"

	"ipcr/internal/appcore"
	"ipcr/internal/engine"
	"ipcr/internal/nestedcli"
	"ipcr/internal/primer"
	"ipcr/internal/runutil"
	"ipcr/internal/version"
	"ipcr/internal/visitors"
	"ipcr/internal/writers"
)

func RunContext(parent context.Context, argv []string, stdout, stderr io.Writer) int {
	outw := bufio.NewWriter(stdout)
	defer outw.Flush()

	fs := nestedcli.NewFlagSet("ipcr-nested")
	fs.SetOutput(io.Discard)

	if len(argv) == 0 {
		_, _ = nestedcli.ParseArgs(fs, []string{"-h"})
		fs.SetOutput(outw); fs.Usage()
		if err := outw.Flush(); writers.IsBrokenPipe(err) { return 0 }
		if err != nil { fmt.Fprintln(stderr, err); return 3 }
		return 0
	}

	opts, err := nestedcli.ParseArgs(fs, argv)
	if err != nil {
		if errors.Is(err, flag.ErrHelp) {
			fs.SetOutput(outw); fs.Usage()
			if e := outw.Flush(); writers.IsBrokenPipe(e) { return 0 }
			if e != nil { fmt.Fprintln(stderr, e); return 3 }
			return 0
		}
		fmt.Fprintln(stderr, err)
		fs.SetOutput(outw); fs.Usage()
		if e := outw.Flush(); writers.IsBrokenPipe(e) { return 0 }
		if e != nil { fmt.Fprintln(stderr, e); return 3 }
		return 2
	}

	if opts.Version {
		fmt.Fprintf(outw, "ipcr version %s (ipcr-nested)\n", version.Version)
		if e := outw.Flush(); writers.IsBrokenPipe(e) { return 0 }
		if e != nil { fmt.Fprintln(stderr, e); return 3 }
		return 0
	}

	// Outer primer pairs
	var outer []primer.Pair
	if opts.PrimerFile != "" {
		outer, err = primer.LoadTSV(opts.PrimerFile)
		if err != nil { fmt.Fprintln(stderr, err); return 2 }
	} else {
		outer = []primer.Pair{{
			ID:         "outer",
			Forward:    opts.Fwd,
			Reverse:    opts.Rev,
			MinProduct: opts.MinLen,
			MaxProduct: opts.MaxLen,
		}}
	}

	// Inner primer pairs
	var inner []primer.Pair
	if opts.InnerPrimerFile != "" {
		inner, err = primer.LoadTSV(opts.InnerPrimerFile)
		if err != nil { fmt.Fprintln(stderr, err); return 2 }
	} else {
		inner = []primer.Pair{{
			ID:         "inner",
			Forward:    strings.ToUpper(opts.InnerFwd),
			Reverse:    strings.ToUpper(opts.InnerRev),
			// For inner stage we don’t enforce min/max by default; can add flags later.
		}}
	}

	termWin := runutil.ComputeTerminalWindow(opts.Mode, opts.TerminalWindow)
	coreOpts := appcore.Options{
		SeqFiles:        opts.SeqFiles,
		MaxMM:           opts.Mismatches,
		TerminalWindow:  termWin,
		MinLen:          opts.MinLen,
		MaxLen:          opts.MaxLen,
		HitCap:          opts.HitCap,
		SeedLength:      opts.SeedLength,
		Circular:        opts.Circular,
		Threads:         opts.Threads,
		ChunkSize:       opts.ChunkSize,
		Quiet:           opts.Quiet,
		NoMatchExitCode: opts.NoMatchExitCode,
	}

	writer := appcore.NewNestedWriterFactory(opts.Output, opts.Sort, opts.Header)

	visitor := visitors.Nested{
		InnerPairs: inner,
		EngineCfg: engine.Config{
			MaxMM:          opts.Mismatches,
			TerminalWindow: termWin,
			// inner MinLen/MaxLen can be added as extra flags later
			SeedLen:   opts.SeedLength,
			Circular:  false, // inner stage scans linear amplicon strings
			NeedSites: false,
		},
		RequireInner: opts.RequireInner,
	}

	return appcore.Run(parent, stdout, stderr, coreOpts, outer, visitor.Visit, writer)
}

func Run(argv []string, stdout, stderr io.Writer) int {
	return RunContext(context.Background(), argv, stdout, stderr)
}

===== END ./internal/nestedapp/app.go =====

===== BEGIN ./internal/nestedcli/options.go =====
// ./internal/nestedcli/options.go
package nestedcli

import (
	"flag"
	"fmt"
	"strings"

	"ipcr/internal/clibase"
	"ipcr/internal/cliutil"
)

type Options struct {
	// Outer (via Common)
	PrimerFile string
	Fwd        string
	Rev        string
	SeqFiles   []string

	Mismatches     int
	MinLen         int
	MaxLen         int
	HitCap         int
	TerminalWindow int
	Mode           string

	Threads    int
	ChunkSize  int
	SeedLength int
	Circular   bool

	Output          string
	Sort            bool
	Header          bool
	NoMatchExitCode int
	Pretty          bool // accepted but not used for nested (no pretty renderer yet)
	Products        bool // ignored

	Quiet   bool
	Version bool

	// Inner
	InnerPrimerFile string
	InnerFwd        string
	InnerRev        string
	RequireInner    bool
}

func NewFlagSet(name string) *flag.FlagSet {
	fs := flag.NewFlagSet(name, flag.ContinueOnError)
	fs.Usage = func() {
		out := fs.Output()
		def := func(n string) string { if f := fs.Lookup(n); f != nil { return f.DefValue }; return "" }
		fmt.Fprintf(out, "%s – nested in-silico PCR (outer + inner)\n\n", name)
		fmt.Fprintln(out, "Usage:")
		fmt.Fprintf(out, "  %s --forward AAA --reverse TTT --inner-forward CCC --inner-reverse GGG ref.fa\n", name)
		fmt.Fprintf(out, "  %s --primers outer.tsv --inner-primers inner.tsv ref*.fa.gz\n", name)

		fmt.Fprintln(out, "\nOuter (same as ipcr):")
		fmt.Fprintln(out, "  -f, --forward string         Outer forward primer (5'→3')")
		fmt.Fprintln(out, "  -r, --reverse string         Outer reverse primer (5'→3')")
		fmt.Fprintln(out, "  -p, --primers string         Outer primer TSV (id fwd rev [min] [max])")
		fmt.Fprintln(out, "  -s, --sequences file         FASTA file(s) (repeatable) or '-' for STDIN")

		fmt.Fprintln(out, "\nInner:")
		fmt.Fprintln(out, "      --inner-forward string   Inner forward primer (5'→3')")
		fmt.Fprintln(out, "      --inner-reverse string   Inner reverse primer (5'→3')")
		fmt.Fprintln(out, "      --inner-primers string   Inner primer TSV (id fwd rev [min] [max])")
		fmt.Fprintf(out, "      --require-inner          Only keep outer amplicons that contain an inner product [%s]\n", def("require-inner"))

		fmt.Fprintln(out, "\nPCR/Performance/Output/Misc (outer stage; same as ipcr):")
		fmt.Fprintln(out, "      --mismatches, --min-length, --max-length, --terminal-window, --threads, --hit-cap, --chunk-size, --seed-length, --circular")
		fmt.Fprintln(out, "      --output text|json|jsonl|fasta, --sort, --no-header, --no-match-exit-code, --quiet, --version")
	}
	return fs
}

type stringSlice []string
func (s *stringSlice) String() string     { return strings.Join(*s, ",") }
func (s *stringSlice) Set(v string) error { *s = append(*s, v); return nil }

func ParseArgs(fs *flag.FlagSet, argv []string) (Options, error) {
	var o Options
	var help bool

	var c clibase.Common
	noHeader := clibase.Register(fs, &c)

	// Inner flags
	fs.StringVar(&o.InnerPrimerFile, "inner-primers", "", "Inner primer TSV")
	fs.StringVar(&o.InnerFwd, "inner-forward", "", "Inner forward primer (5'→3')")
	fs.StringVar(&o.InnerRev, "inner-reverse", "", "Inner reverse primer (5'→3')")
	fs.BoolVar(&o.RequireInner, "require-inner", false, "Only keep amplicons that contain an inner product [false]")

	// Help
	fs.BoolVar(&help, "h", false, "show this help [false]")

	flagArgs, posArgs := cliutil.SplitFlagsAndPositionals(fs, argv)
	if err := fs.Parse(flagArgs); err != nil { return o, err }
	if help { return o, flag.ErrHelp }
	if c.Version { o.Version = true; return o, nil }

	if err := clibase.AfterParse(fs, &c, noHeader, posArgs); err != nil { return o, err }

	// Validate inner
	usingFile := o.InnerPrimerFile != ""
	usingInline := o.InnerFwd != "" || o.InnerRev != ""
	switch {
	case usingFile && usingInline:
		return o, fmt.Errorf("--inner-primers conflicts with --inner-forward/--inner-reverse")
	case usingInline && (o.InnerFwd == "" || o.InnerRev == ""):
		return o, fmt.Errorf("--inner-forward and --inner-reverse must be supplied together")
	case !usingFile && !usingInline:
		return o, fmt.Errorf("provide --inner-primers or --inner-forward/--inner-reverse")
	}

	// Copy Common → Options
	o.PrimerFile, o.Fwd, o.Rev, o.SeqFiles = c.PrimerFile, c.Fwd, c.Rev, c.SeqFiles
	o.Mismatches, o.MinLen, o.MaxLen, o.HitCap, o.TerminalWindow, o.Mode =
		c.Mismatches, c.MinLen, c.MaxLen, c.HitCap, c.TerminalWindow, c.Mode
	o.Threads, o.ChunkSize, o.SeedLength, o.Circular = c.Threads, c.ChunkSize, c.SeedLength, c.Circular
	o.Output, o.Products, o.Pretty, o.Sort, o.Header, o.NoMatchExitCode =
		c.Output, c.Products, c.Pretty, c.Sort, c.Header, c.NoMatchExitCode
	o.Quiet = c.Quiet
	return o, nil
}

func Parse() (Options, error) { return ParseArgs(NewFlagSet("ipcr-nested"), nil) }

===== END ./internal/nestedcli/options.go =====

===== BEGIN ./internal/nestedoutput/json.go =====
// ./internal/nestedoutput/json.go
package nestedoutput

import (
	"encoding/json"
	"io"

	"ipcr/pkg/api"
)

func toAPINested(np NestedProduct) api.NestedProductV1 {
	p := np.Product
	return api.NestedProductV1{
		// Outer
		ExperimentID:   p.ExperimentID,
		SequenceID:     p.SequenceID,
		Start:          p.Start,
		End:            p.End,
		Length:         p.Length,
		Type:           p.Type,
		FwdMM:          p.FwdMM,
		RevMM:          p.RevMM,
		FwdMismatchIdx: append([]int(nil), p.FwdMismatchIdx...),
		RevMismatchIdx: append([]int(nil), p.RevMismatchIdx...),
		Seq:            p.Seq,
		SourceFile:     p.SourceFile,
		// Inner
		InnerFound:   np.InnerFound,
		InnerPairID:  np.InnerPairID,
		InnerStart:   np.InnerStart,
		InnerEnd:     np.InnerEnd,
		InnerLength:  np.InnerLength,
		InnerType:    np.InnerType,
		InnerFwdMM:   np.InnerFwdMM,
		InnerRevMM:   np.InnerRevMM,
	}
}

func WriteJSON(w io.Writer, list []NestedProduct) error {
	enc := json.NewEncoder(w)
	enc.SetIndent("", "  ")
	out := make([]api.NestedProductV1, 0, len(list))
	for _, np := range list {
		out = append(out, toAPINested(np))
	}
	return enc.Encode(out)
}

===== END ./internal/nestedoutput/json.go =====

===== BEGIN ./internal/nestedoutput/text.go =====
// ./internal/nestedoutput/text.go
package nestedoutput

import (
	"fmt"
	"io"
)

func writeRowTSV(w io.Writer, np NestedProduct) error {
	p := np.Product
	_, err := fmt.Fprintf(
		w, "%s\t%s\t%s\t%d\t%d\t%d\t%s\t%s\t%t\t%s\t%s\t%s\t%s\t%s\t%s\n",
		p.SourceFile, p.SequenceID, p.ExperimentID,
		p.Start, p.End, p.Length, p.Type,
		np.InnerPairID, np.InnerFound,
		ise(np.InnerStart), ise(np.InnerEnd), ise(np.InnerLength),
		np.InnerType, isi(np.InnerFwdMM), isi(np.InnerRevMM),
	)
	return err
}

func StreamText(w io.Writer, in <-chan NestedProduct, header bool) error {
	if header {
		if _, err := io.WriteString(w, TSVHeaderNested+"\n"); err != nil { return err }
	}
	for np := range in {
		if err := writeRowTSV(w, np); err != nil { return err }
	}
	return nil
}

func WriteText(w io.Writer, list []NestedProduct, header bool) error {
	if header {
		if _, err := io.WriteString(w, TSVHeaderNested+"\n"); err != nil { return err }
	}
	for _, np := range list {
		if err := writeRowTSV(w, np); err != nil { return err }
	}
	return nil
}

func ise(v int) string {
	if v == 0 {
		return "" // empty when not applicable
	}
	return fmt.Sprintf("%d", v)
}
func isi(v int) string {
	if v == 0 {
		return "" // empty when not applicable
	}
	return fmt.Sprintf("%d", v)
}

===== END ./internal/nestedoutput/text.go =====

===== BEGIN ./internal/nestedoutput/types.go =====
// ./internal/nestedoutput/types.go
package nestedoutput

import "ipcr/internal/engine"

type NestedProduct struct {
	// Outer
	engine.Product

	// Inner summary (relative to Product.Seq)
	InnerFound  bool   `json:"inner_found"`
	InnerPairID string `json:"inner_experiment_id,omitempty"`
	InnerStart  int    `json:"inner_start,omitempty"`
	InnerEnd    int    `json:"inner_end,omitempty"`
	InnerLength int    `json:"inner_length,omitempty"`
	InnerType   string `json:"inner_type,omitempty"`
	InnerFwdMM  int    `json:"inner_fwd_mm,omitempty"`
	InnerRevMM  int    `json:"inner_rev_mm,omitempty"`
}

const TSVHeaderNested = "source_file\tsequence_id\touter_experiment_id\touter_start\touter_end\touter_length\touter_type\t" +
	"inner_experiment_id\tinner_found\tinner_start\tinner_end\tinner_length\tinner_type\tinner_fwd_mm\tinner_rev_mm"

===== END ./internal/nestedoutput/types.go =====

===== BEGIN ./internal/oligo/oligo.go =====
// internal/oligo/oligo.go
package oligo

import (
	"strings"

	"ipcr/internal/primer"
)

type Hit struct {
	Found  bool
	Strand string // "+" or "-"
	Pos    int
	MM     int
	Site   string
}

// BestHit returns the best (fewest mismatches, then leftmost) hit of probe on
// either strand of amplicon, allowing up to maxMM mismatches.
func BestHit(amplicon string, probe string, maxMM int) Hit {
	amp := strings.ToUpper(amplicon)
	prb := strings.ToUpper(probe)
	prbB := []byte(prb)
	rcB := primer.RevComp(prbB)

	// Exact match fast-path
	if maxMM == 0 {
		if i := strings.Index(amp, prb); i >= 0 {
			return Hit{Found: true, Strand: "+", Pos: i, MM: 0, Site: amp[i : i+len(prb)]}
		}
		rc := string(rcB)
		if i := strings.Index(amp, rc); i >= 0 {
			return Hit{Found: true, Strand: "-", Pos: i, MM: 0, Site: amp[i : i+len(rc)]}
		}
		return Hit{}
	}

	plus := primer.FindMatches([]byte(amp), prbB, maxMM, 0, 0)
	minus := primer.FindMatches([]byte(amp), rcB, maxMM, 0, 0)

	best := Hit{}
	selectBest := func(pos, mm int, strand string, patLen int) {
		site := ""
		if end := pos + patLen; end <= len(amp) {
			site = amp[pos:end]
		}
		c := Hit{Found: true, Strand: strand, Pos: pos, MM: mm, Site: site}
		if !best.Found || c.MM < best.MM || (c.MM == best.MM && c.Pos < best.Pos) {
			best = c
		}
	}
	if len(plus) > 0 {
		bestLocal := plus[0]
		for _, h := range plus[1:] {
			if h.Mismatches < bestLocal.Mismatches || (h.Mismatches == bestLocal.Mismatches && h.Pos < bestLocal.Pos) {
				bestLocal = h
			}
		}
		selectBest(bestLocal.Pos, bestLocal.Mismatches, "+", len(prb))
	}
	if len(minus) > 0 {
		bestLocal := minus[0]
		for _, h := range minus[1:] {
			if h.Mismatches < bestLocal.Mismatches || (h.Mismatches == bestLocal.Mismatches && h.Pos < bestLocal.Pos) {
				bestLocal = h
			}
		}
		selectBest(bestLocal.Pos, bestLocal.Mismatches, "-", len(rcB))
	}
	return best
}

===== END ./internal/oligo/oligo.go =====

===== BEGIN ./internal/oligo/oligo_test.go =====
package oligo

import "testing"

func TestBestHit(t *testing.T) {
	h := BestHit("ACGTACGTACGT", "GTAC", 0)
	if !h.Found || h.Pos != 2 || h.MM != 0 || h.Strand != "+" {
		t.Fatalf("unexpected hit: %+v", h)
	}
	h2 := BestHit("ACGTACGTACGT", "GTGC", 1) // RC=GCAC; allow 1 mm
	if !h2.Found {
		t.Fatalf("expected a hit on RC with mismatches")
	}
}

===== END ./internal/oligo/oligo_test.go =====

===== BEGIN ./internal/output/common.go =====
package output

// TSVHeader is the canonical header row for text/TSV outputs.
// Keep this as the single source of truth; all writers should use it.
const TSVHeader = "source_file\tsequence_id\texperiment_id\tstart\tend\tlength\ttype\tfwd_mm\trev_mm\tfwd_mm_i\trev_mm_i"

===== END ./internal/output/common.go =====

===== BEGIN ./internal/output/fasta.go =====
package output

import (
	"fmt"
	"io"

	"ipcr/internal/engine"
)

// StreamFASTA streams FASTA records from a channel to the writer.
func StreamFASTA(w io.Writer, in <-chan engine.Product) error {
	idx := 1
	for p := range in {
		if p.Seq == "" {
			continue
		}
		if _, err := fmt.Fprintf(
			w,
			">%s_%d start=%d end=%d len=%d source_file=%s\n%s\n",
			p.ExperimentID, idx, p.Start, p.End, p.Length, p.SourceFile, p.Seq,
		); err != nil {
			return err
		}
		idx++
	}
	return nil
}

// WriteFASTA writes a slice of products as FASTA records to the writer.
func WriteFASTA(w io.Writer, list []engine.Product) error {
	for i, p := range list {
		if p.Seq == "" {
			continue
		}
		if _, err := fmt.Fprintf(
			w,
			">%s_%d start=%d end=%d len=%d source_file=%s\n%s\n",
			p.ExperimentID, i+1, p.Start, p.End, p.Length, p.SourceFile, p.Seq,
		); err != nil {
			return err
		}
	}
	return nil
}

// WriteTSV writes products as a tab-delimited table (parity with text output).
func WriteTSV(w io.Writer, list []engine.Product, header bool) error {
	if header {
		if _, err := fmt.Fprintln(w, TSVHeader); err != nil {
			return err
		}
	}
	for _, p := range list {
		if _, err := fmt.Fprintf(
			w, "%s\t%s\t%s\t%d\t%d\t%d\t%s\t%d\t%d\t%s\t%s\n",
			p.SourceFile, p.SequenceID, p.ExperimentID,
			p.Start, p.End, p.Length, p.Type,
			p.FwdMM, p.RevMM,
			intsCSV(p.FwdMismatchIdx), intsCSV(p.RevMismatchIdx),
		); err != nil {
			return err
		}
	}
	return nil
}

===== END ./internal/output/fasta.go =====

===== BEGIN ./internal/output/fasta_test.go =====
// internal/output/fasta_test.go
package output

import (
	"bytes"
	"ipcr/internal/engine"
	"strings"
	"testing"
)

func TestWriteFASTA(t *testing.T) {
	buf := &bytes.Buffer{}
	list := []engine.Product{{
		ExperimentID: "p1", Seq: "ACGT",
		Start: 0, End: 4, Length: 4,
	}}
	if err := WriteFASTA(buf, list); err != nil {
		t.Fatalf("fasta: %v", err)
	}
	if !strings.Contains(buf.String(), ">p1_1") || !strings.Contains(buf.String(), "ACGT") {
		t.Fatalf("unexpected FASTA output: %s", buf.String())
	}
}
// ===
===== END ./internal/output/fasta_test.go =====

===== BEGIN ./internal/output/json.go =====
// internal/output/json.go
package output

import (
	"encoding/json"
	"io"

	"ipcr/internal/engine"
	"ipcr/pkg/api"
)

// ToAPIProduct converts a domain Product to the stable wire schema (v1).
func ToAPIProduct(p engine.Product) api.ProductV1 {
	return api.ProductV1{
		ExperimentID:   p.ExperimentID,
		SequenceID:     p.SequenceID,
		Start:          p.Start,
		End:            p.End,
		Length:         p.Length,
		Type:           p.Type,
		FwdMM:          p.FwdMM,
		RevMM:          p.RevMM,
		FwdMismatchIdx: append([]int(nil), p.FwdMismatchIdx...),
		RevMismatchIdx: append([]int(nil), p.RevMismatchIdx...),
		Seq:            p.Seq,
		SourceFile:     p.SourceFile,
	}
}

func ToAPIProducts(list []engine.Product) []api.ProductV1 {
	out := make([]api.ProductV1, 0, len(list))
	for _, p := range list {
		out = append(out, ToAPIProduct(p))
	}
	return out
}

// WriteJSON encodes Products using the stable wire schema (v1).
func WriteJSON(w io.Writer, list []engine.Product) error {
	enc := json.NewEncoder(w)
	enc.SetIndent("", "  ")
	return enc.Encode(ToAPIProducts(list))
}

===== END ./internal/output/json.go =====

===== BEGIN ./internal/output/json_test.go =====
package output

import (
	"bytes"
	"encoding/json"
	"ipcr/internal/engine"
	"ipcr/pkg/api"
	"testing"
)

func TestWriteJSON(t *testing.T) {
	buf := &bytes.Buffer{}
	list := []engine.Product{{
		ExperimentID: "p1", SequenceID: "s", Start: 0, End: 3, Length: 3, Type: "forward",
	}}
	if err := WriteJSON(buf, list); err != nil {
		t.Fatalf("json write: %v", err)
	}
	var got []api.ProductV1
	if err := json.Unmarshal(buf.Bytes(), &got); err != nil || len(got) != 1 || got[0].ExperimentID != "p1" {
		t.Fatalf("json round-trip failed: %v %v", err, got)
	}
}

===== END ./internal/output/json_test.go =====

===== BEGIN ./internal/output/text.go =====
package output

import (
	"fmt"
	"io"
	"strconv"
	"strings"

	"ipcr/internal/engine"
)

func intsCSV(a []int) string {
	if len(a) == 0 {
		return ""
	}
	ss := make([]string, len(a))
	for i, v := range a {
		ss[i] = strconv.Itoa(v)
	}
	return strings.Join(ss, ",")
}

func writeRowTSV(w io.Writer, p engine.Product) error {
	_, err := fmt.Fprintf(
		w, "%s\t%s\t%s\t%d\t%d\t%d\t%s\t%d\t%d\t%s\t%s\n",
		p.SourceFile, p.SequenceID, p.ExperimentID,
		p.Start, p.End, p.Length, p.Type,
		p.FwdMM, p.RevMM,
		intsCSV(p.FwdMismatchIdx), intsCSV(p.RevMismatchIdx),
	)
	return err
}

// New: renderer-capable streaming writer for text mode
func StreamTextWithRenderer(w io.Writer, in <-chan engine.Product, header bool, prettyMode bool, render func(engine.Product) string) error {
	if header {
		if _, err := fmt.Fprintln(w, TSVHeader); err != nil {
			return err
		}
	}
	for p := range in {
		if err := writeRowTSV(w, p); err != nil {
			return err
		}
		if prettyMode {
			if _, err := io.WriteString(w, render(p)); err != nil {
				return err
			}
		}
	}
	return nil
}

// New: renderer-capable buffered writer for text mode
func WriteTextWithRenderer(w io.Writer, list []engine.Product, header bool, prettyMode bool, render func(engine.Product) string) error {
	if header {
		if _, err := fmt.Fprintln(w, TSVHeader); err != nil {
			return err
		}
	}
	for _, p := range list {
		if err := writeRowTSV(w, p); err != nil {
			return err
		}
		if prettyMode {
			if _, err := io.WriteString(w, render(p)); err != nil {
				return err
			}
		}
	}
	return nil
}

// Backward-compat wrappers (use default renderer wired in output package)
func StreamText(w io.Writer, in <-chan engine.Product, header bool, prettyMode bool) error {
	return StreamTextWithRenderer(w, in, header, prettyMode, func(p engine.Product) string { return "" })
}

func WriteText(w io.Writer, list []engine.Product, header bool, prettyMode bool) error {
	return WriteTextWithRenderer(w, list, header, prettyMode, func(p engine.Product) string { return "" })
}

===== END ./internal/output/text.go =====

===== BEGIN ./internal/pipeline/doc.go =====
// Package pipeline streams FASTA chunks through an Engine-like Simulator,
// deduplicates cross-boundary hits, and calls a visit callback.
//
// The only contract to implement is Simulator (SimulateBatch).
// This keeps the pipeline swappable and testable.
package pipeline

===== END ./internal/pipeline/doc.go =====

===== BEGIN ./internal/pipeline/pipeline.go =====
// internal/pipeline/pipeline.go
package pipeline

import (
	"context"
	"sync"

	"ipcr/internal/common"
	"ipcr/internal/engine"
	"ipcr/internal/fasta"
	"ipcr/internal/primer"
)

// Config controls the scanning pipeline.
type Config struct {
	Threads   int  // number of worker goroutines (>=1)
	ChunkSize int  // FASTA chunking window; 0 disables chunking
	Overlap   int  // overlap between chunks (typically >= MaxLen or primerLen-1)
	Circular  bool // treat sequences as circular
	NeedSeq   bool // fill Product.Seq by slicing record sequence
}

// Key uniquely identifies a product in reference-global coordinates to
// deduplicate cross-chunk duplicates.
type Key struct {
	Base, File string
	Start, End int
	Type, Exp  string
}

// ForEachProduct streams deduplicated engine.Products to the caller via visit.
// It reads chunks from seqFiles, runs SimulateBatch over all primer pairs, fills
// Product.Seq if requested, normalizes IDs/coords, deduplicates, and calls visit.
// It returns the first error encountered (including context cancellation).
func ForEachProduct(
	ctx context.Context,
	cfg Config,
	seqFiles []string,
	pairs []primer.Pair,
	sim Simulator, // <-- accept the minimal interface
	visit func(engine.Product) error,
) error {
	if cfg.Threads < 1 {
		cfg.Threads = 1
	}

	type job struct {
		rec        fasta.Record
		sourceFile string
	}
	jobs := make(chan job, cfg.Threads*2)
	results := make(chan []engine.Product, cfg.Threads*2)

	// Workers
	var wg sync.WaitGroup
	wg.Add(cfg.Threads)
	for w := 0; w < cfg.Threads; w++ {
		go func() {
			defer wg.Done()
			for {
				select {
				case <-ctx.Done():
					return
				case j, ok := <-jobs:
					if !ok {
						return
					}
					hits := sim.SimulateBatch(j.rec.ID, j.rec.Seq, pairs)

					// Fill sequence and source file
					if cfg.NeedSeq {
						for i := range hits {
							if cfg.Circular && hits[i].Start > hits[i].End {
								seqBytes := j.rec.Seq
								hits[i].Seq = string(seqBytes[hits[i].Start:]) + string(seqBytes[:hits[i].End])
							} else {
								hits[i].Seq = string(j.rec.Seq[hits[i].Start:hits[i].End])
							}
						}
					}
					for i := range hits {
						hits[i].SourceFile = j.sourceFile
					}

					select {
					case results <- hits:
					case <-ctx.Done():
						return
					}
				}
			}
		}()
	}

	// Collector + deduper
	var (
		cerr error
		cwg  sync.WaitGroup
		seen = make(map[Key]struct{}, 1<<12)
	)
	cwg.Add(1)
	go func() {
		defer cwg.Done()
		for hs := range results {
			if cerr != nil {
				continue
			}
			for _, p := range hs {
				base, off, ok := common.SplitChunkSuffix(p.SequenceID)
				if !ok {
					base = p.SequenceID
					off = 0
				}
				gs, ge := p.Start+off, p.End+off
				k := Key{Base: base, File: p.SourceFile, Start: gs, End: ge, Type: p.Type, Exp: p.ExperimentID}
				if _, dup := seen[k]; dup {
					continue
				}
				seen[k] = struct{}{}
				if err := visit(p); err != nil && cerr == nil {
					cerr = err
				}
			}
		}
	}()

	// Feed work
feed:
	for _, fa := range seqFiles {
		rch, err := fasta.StreamChunks(fa, cfg.ChunkSize, cfg.Overlap)
		if err != nil {
			if cerr == nil {
				cerr = err
			}
			continue
		}
		for rec := range rch {
			select {
			case <-ctx.Done():
				break feed
			case jobs <- job{rec: rec, sourceFile: fa}:
			}
		}
	}

	close(jobs)
	wg.Wait()
	close(results)
	cwg.Wait()

	if ctx.Err() != nil {
		return ctx.Err()
	}
	return cerr
}

===== END ./internal/pipeline/pipeline.go =====

===== BEGIN ./internal/pipeline/pipeline_engine_contract_test.go =====
// internal/pipeline/pipeline_engine_contract_test.go
package pipeline

import (
	"context"
	"os"
	"testing"

	"ipcr/internal/engine"
	"ipcr/internal/primer"
)

// Compile-time check: the concrete engine satisfies the minimal contract.
var _ Simulator = (*engine.Engine)(nil)

// fake engine implementing the Simulator interface
type fakeEng struct{}

func (fakeEng) SimulateBatch(seqID string, seq []byte, pairs []primer.Pair) []engine.Product {
	return []engine.Product{{
		ExperimentID: "x", SequenceID: seqID,
		Start: 1, End: 3, Length: 2, Type: "forward",
	}}
}

func TestForEachProduct_UsesSimulatorAndFillsSeq(t *testing.T) {
	fn := "pipe_fake.fa"
	if err := os.WriteFile(fn, []byte(">s\nACGT\n"), 0644); err != nil {
		t.Fatal(err)
	}
	defer os.Remove(fn)

	var n int
	err := ForEachProduct(
		context.Background(),
		Config{Threads: 1, ChunkSize: 0, Overlap: 0, Circular: false, NeedSeq: true},
		[]string{fn},
		[]primer.Pair{{ID: "x"}},
		fakeEng{},
		func(p engine.Product) error {
			n++
			if p.Seq == "" {
				t.Fatalf("expected Seq to be filled by pipeline when NeedSeq=true")
			}
			return nil
		},
	)
	if err != nil {
		t.Fatalf("pipeline err: %v", err)
	}
	if n != 1 {
		t.Fatalf("want 1 product, got %d", n)
	}
}

===== END ./internal/pipeline/pipeline_engine_contract_test.go =====

===== BEGIN ./internal/pipeline/pipeline_test.go =====
package pipeline

import (
	"context"
	"os"
	"testing"

	"ipcr/internal/engine"
	"ipcr/internal/primer"
)

func TestForEachProduct_NoChunking(t *testing.T) {
	// Make a tiny FASTA
	fn := "pipe_test.fa"
	defer os.Remove(fn)
	if err := os.WriteFile(fn, []byte(">s\nACGTACGTACGT\n"), 0644); err != nil {
		t.Fatalf("write: %v", err)
	}
	pairs := []primer.Pair{{
		ID: "x", Forward: "ACG", Reverse: "ACG", MinProduct: 0, MaxProduct: 1000,
	}}
	eng := engine.New(engine.Config{MaxLen: 1000})
	var n int
	err := ForEachProduct(context.Background(), Config{
		Threads: 1, ChunkSize: 0, Overlap: 0, Circular: false, NeedSeq: true,
	}, []string{fn}, pairs, eng, func(p engine.Product) error {
		n++
		return nil
	})
	if err != nil {
		t.Fatalf("pipeline err: %v", err)
	}
	if n == 0 {
		t.Fatal("expected at least one product")
	}
}

===== END ./internal/pipeline/pipeline_test.go =====

===== BEGIN ./internal/pipeline/sim.go =====
// internal/pipeline/sim.go
package pipeline

import (
	"ipcr/internal/engine"
	"ipcr/internal/primer"
)

// Simulator is the minimal capability the pipeline needs.
// Any engine (including fakes in tests) can satisfy this.
type Simulator interface {
	SimulateBatch(seqID string, seq []byte, pairs []primer.Pair) []engine.Product
}

===== END ./internal/pipeline/sim.go =====

===== BEGIN ./internal/pretty/pretty.go =====
package pretty

import (
	"fmt"
	"strings"

	"ipcr/internal/engine"
)

// ProbeAnnotation carries the probe overlay to render on top of a Product.
type ProbeAnnotation struct {
	Name   string
	Seq    string // 5'→3' as provided
	Found  bool
	Strand string // "+" or "-"
	Pos    int    // 0-based in the amplicon (plus orientation)
	MM     int
	Site   string // matched site in amplicon (plus orientation)
}

// Options control the ASCII rendering.
type Options struct {
	// Interior width cap for readability (dots section). If <=0, use default (95).
	MaxGap int

	// Inline the probe letters into the genomic line (overwriting dots).
	ShowProbeInline bool

	// Draw a caret track (^^^^^) under the genomic line at the probe span.
	ShowCaret bool
	CaretGlyph string // default "^"

	// Draw probe bars '|||||' on the composite bars row (reverse-primer bars always shown).
	ShowProbeBars bool

	// Draw the left probe sequence block on the “sequence row”
	// ("5'-...-3'" for +, "3'-...-5'" for −). The reverse-primer block is always drawn.
	ShowProbeSeqRow bool

	// Glyphs
	ExactGlyph   string // default "|"
	PartialGlyph string // default "¦"
	DotGlyph     string // default "."
}

// DefaultOptions keeps the current look & feel (matching what you already approved).
var DefaultOptions = Options{
	MaxGap:         95,
	ShowProbeInline: true,
	ShowCaret:       false,
	CaretGlyph:      "^",
	ShowProbeBars:   true,
	ShowProbeSeqRow: true,
	ExactGlyph:      "|",
	PartialGlyph:    "¦",
	DotGlyph:        ".",
}

const (
	minInterPrimerGap = 5
	linePrefix        = "# "
)

func reverseString(s string) string {
	rs := []rune(s)
	for i, j := 0, len(rs)-1; i < j; i, j = i+1, j-1 {
		rs[i], rs[j] = rs[j], rs[i]
	}
	return string(rs)
}

func complementString(s string) string {
	out := make([]byte, len(s))
	for i := range s {
		switch s[i] {
		case 'A':
			out[i] = 'T'
		case 'T':
			out[i] = 'A'
		case 'C':
			out[i] = 'G'
		case 'G':
			out[i] = 'C'
		case 'R':
			out[i] = 'Y'
		case 'Y':
			out[i] = 'R'
		case 'S':
			out[i] = 'S'
		case 'W':
			out[i] = 'W'
		case 'K':
			out[i] = 'M'
		case 'M':
			out[i] = 'K'
		case 'B':
			out[i] = 'V'
		case 'V':
			out[i] = 'B'
		case 'D':
			out[i] = 'H'
		case 'H':
			out[i] = 'D'
		case 'N':
			out[i] = 'N'
		default:
			out[i] = s[i]
		}
	}
	return string(out)
}

func isACGT(b byte) bool { return b == 'A' || b == 'C' || b == 'G' || b == 'T' }

// Primer bars under a site (ipcr semantics)
func matchLineAmbig(primer, site string, mismIdx []int, exactGlyph, partialGlyph string) string {
	n := len(primer)
	if n <= 0 {
		return ""
	}
	if len(site) < n {
		n = len(site)
	}
	mism := make(map[int]struct{}, len(mismIdx))
	for _, i := range mismIdx {
		mism[i] = struct{}{}
	}
	var b strings.Builder
	b.Grow(n)
	for i := 0; i < n; i++ {
		if _, bad := mism[i]; bad {
			b.WriteByte(' ')
			continue
		}
		if isACGT(primer[i]) {
			b.WriteString(exactGlyph)
		} else {
			b.WriteString(partialGlyph)
		}
	}
	return b.String()
}

// scale an interior offset into the capped printed width (endpoint-preserving)
func scalePos(off, interior, inner int) int {
	if interior <= 1 || inner <= 1 {
		return 0
	}
	if off < 0 {
		off = 0
	}
	if off > interior-1 {
		off = interior - 1
	}
	return (off * (inner - 1)) / (interior - 1)
}

// intsCSV for printing mismatch indexes in the summary.
func intsCSV(a []int) string {
	if len(a) == 0 {
		return ""
	}
	ss := make([]string, len(a))
	for i, v := range a {
		ss[i] = fmt.Sprintf("%d", v)
	}
	return strings.Join(ss, ",")
}

// RenderProductWithOptions prints the ipcr-style block (no probe overlay).
func RenderProductWithOptions(p engine.Product, opt Options) string {
	const (
		prefixPlus  = "5'-"
		suffixPlus  = "-3'"
		prefixMinus = "3'-"
		suffixMinus = "-5'"
		arrowRight  = "-->"
		arrowLeft   = "<--"
	)

	if p.FwdPrimer == "" || p.RevPrimer == "" || p.FwdSite == "" || p.RevSite == "" {
		var b strings.Builder
		fmt.Fprintf(&b, "%s(pretty not available: sites missing)\n\n", linePrefix)
		return b.String()
	}

	maxGap := opt.MaxGap
	if maxGap <= 0 {
		maxGap = DefaultOptions.MaxGap
	}
	dot := opt.DotGlyph
	if dot == "" {
		dot = DefaultOptions.DotGlyph
	}

	aLen, bLen := len(p.FwdPrimer), len(p.RevPrimer)
	interior := p.Length - aLen - bLen
	if interior < 0 {
		interior = 0
	}

	inner := maxGap
	if interior < inner {
		inner = interior
	}
	innerMinus := inner
	innerPlus := inner
	if innerMinus < aLen+minInterPrimerGap {
		innerMinus = aLen + minInterPrimerGap
	}
	if innerPlus < bLen+minInterPrimerGap {
		innerPlus = bLen + minInterPrimerGap
	}

	contPlus := aLen + innerPlus
	contMinus := innerMinus + bLen
	if contMinus > contPlus {
		innerPlus += (contMinus - contPlus)
	} else if contPlus > contMinus {
		innerMinus += (contPlus - contMinus)
	}

	var b strings.Builder

	// 1) Forward primer (5'→3')
	fmt.Fprintf(&b, "%s%s%s%s\n", linePrefix, prefixPlus, p.FwdPrimer, suffixPlus)

	// 2) Bars under forward primer
	fmt.Fprintf(&b, "%s%s%s%s\n",
		linePrefix,
		strings.Repeat(" ", len(prefixPlus)),
		matchLineAmbig(p.FwdPrimer, p.FwdSite, p.FwdMismatchIdx, opt.ExactGlyphOrDefault(), opt.PartialGlyphOrDefault()),
		arrowRight,
	)

	// 3) (+) genomic line
	fmt.Fprintf(&b, "%s%s%s%s%s # (+)\n",
		linePrefix, prefixPlus, p.FwdSite, strings.Repeat(dot, innerPlus), suffixPlus,
	)

	// 4) (−) genomic line
	minusSite := complementString(p.RevSite)
	fmt.Fprintf(&b, "%s%s%s%s%s # (-)\n",
		linePrefix, prefixMinus, strings.Repeat(dot, innerMinus), minusSite, suffixMinus,
	)

	// 5) bars for reverse primer
	siteStart := len(prefixMinus) + innerMinus
	revBars := reverseString(matchLineAmbig(p.RevPrimer, p.RevSite, p.RevMismatchIdx, opt.ExactGlyphOrDefault(), opt.PartialGlyphOrDefault()))
	padBars := siteStart - len(arrowLeft)
	if padBars < 0 {
		padBars = 0
	}
	fmt.Fprintf(&b, "%s%s%s%s\n", linePrefix, strings.Repeat(" ", padBars), arrowLeft, revBars)

	// 6) reverse primer shown 3'→5'
	revPrimerDisplayed := reverseString(p.RevPrimer)
	padPrimer := siteStart - len(prefixMinus)
	if padPrimer < 0 {
		padPrimer = 0
	}
	fmt.Fprintf(&b, "%s%s%s%s%s\n", linePrefix, strings.Repeat(" ", padPrimer), prefixMinus, revPrimerDisplayed, suffixMinus)

	// spacer
	b.WriteString("#\n")
	return b.String()
}

// RenderProduct keeps backward compat (uses DefaultOptions).
func RenderProduct(p engine.Product) string {
	return RenderProductWithOptions(p, DefaultOptions)
}

// RenderAnnotatedWithOptions prints the ipcr-style block with the probe overlay.
func RenderAnnotatedWithOptions(p engine.Product, ann ProbeAnnotation, opt Options) string {
	const (
		prefixPlus  = "5'-"
		suffixPlus  = "-3'"
		prefixMinus = "3'-"
		suffixMinus = "-5'"
		arrowRight  = "-->"
		arrowLeft   = "<--"
	)

	if p.FwdPrimer == "" || p.RevPrimer == "" || p.FwdSite == "" || p.RevSite == "" {
		var b strings.Builder
		fmt.Fprintf(&b, "%s(pretty not available: sites missing)\n\n", linePrefix)
		return b.String()
	}

	maxGap := opt.MaxGap
	if maxGap <= 0 {
		maxGap = DefaultOptions.MaxGap
	}
	dot := opt.DotGlyph
	if dot == "" {
		dot = DefaultOptions.DotGlyph
	}

	aLen, bLen := len(p.FwdPrimer), len(p.RevPrimer)
	interior := p.Length - aLen - bLen
	if interior < 0 {
		interior = 0
	}

	inner := maxGap
	if interior < inner {
		inner = interior
	}
	innerMinus := inner
	innerPlus := inner
	if innerMinus < aLen+minInterPrimerGap {
		innerMinus = aLen + minInterPrimerGap
	}
	if innerPlus < bLen+minInterPrimerGap {
		innerPlus = bLen + minInterPrimerGap
	}

	contPlus := aLen + innerPlus
	contMinus := innerMinus + bLen
	if contMinus > contPlus {
		innerPlus += (contMinus - contPlus)
	} else if contPlus > contMinus {
		innerMinus += (contPlus - contMinus)
	}

	var b strings.Builder

	// 1) Forward primer (5'→3')
	fmt.Fprintf(&b, "%s%s%s%s\n", linePrefix, prefixPlus, p.FwdPrimer, suffixPlus)

	// 2) Bars under forward primer
	fmt.Fprintf(&b, "%s%s%s%s\n",
		linePrefix,
		strings.Repeat(" ", len(prefixPlus)),
		matchLineAmbig(p.FwdPrimer, p.FwdSite, p.FwdMismatchIdx, opt.ExactGlyphOrDefault(), opt.PartialGlyphOrDefault()),
		arrowRight,
	)

	// Prepare overlayable interiors
	plusInterior := strings.Repeat(dot, innerPlus)
	minusInterior := strings.Repeat(dot, innerMinus)

	type overlay struct {
		onPlus bool
		colAbs int
		seg    string
	}
	var ov *overlay

	// Compute overlay position and visible segment
	if ann.Found && p.Length > 0 && len(ann.Site) > 0 && opt.ShowProbeInline {
		start := ann.Pos
		site := ann.Site

		if ann.Strand == "+" {
			remStart := start
			if remStart < aLen {
				clip := aLen - remStart
				if clip < len(site) {
					site = site[clip:]
					remStart = aLen
				} else {
					site = ""
				}
			}
			if len(site) > 0 && remStart >= aLen && remStart < aLen+interior && innerPlus > 0 && interior > 0 {
				off := remStart - aLen
				s := scalePos(off, interior, innerPlus)
				slot := innerPlus - s
				seg := site
				if len(seg) > slot {
					seg = seg[:slot]
				}
				if len(seg) > 0 {
					ir := []rune(plusInterior)
					copy(ir[s:], []rune(seg))
					plusInterior = string(ir)
					ov = &overlay{onPlus: true, colAbs: len(prefixPlus) + aLen + s, seg: seg}
				}
			}
		} else { // "-"
			remStart := start
			if remStart < aLen {
				clip := aLen - remStart
				if clip < len(site) {
					site = site[clip:]
					remStart = aLen
				} else {
					site = ""
				}
			}
			if len(site) > 0 && remStart >= aLen && remStart < aLen+interior && innerMinus > 0 && interior > 0 {
				off := remStart - aLen
				s := scalePos(off, interior, innerMinus)
				slot := innerMinus - s
				seg := site
				if len(seg) > slot {
					seg = seg[:slot]
				}
				if len(seg) > 0 {
					ir := []rune(minusInterior)
					copy(ir[s:], []rune(seg))
					minusInterior = string(ir)
					ov = &overlay{onPlus: false, colAbs: len(prefixMinus) + s, seg: seg}
				}
			}
		}
	}

	// 3) (+) line (with overlay)
	fmt.Fprintf(&b, "%s%s%s%s%s # (+)\n",
		linePrefix, prefixPlus, p.FwdSite, plusInterior, suffixPlus,
	)

	// Optional caret under (+)
	if opt.ShowCaret && ov != nil && ov.onPlus {
		startCol := ov.colAbs
		if startCol < 0 {
			startCol = 0
		}
		g := opt.CaretGlyph
		if g == "" {
			g = DefaultOptions.CaretGlyph
		}
		fmt.Fprintf(&b, "%s%s%s\n", linePrefix, strings.Repeat(" ", startCol), strings.Repeat(g, len(ov.seg)))
	}

	// 4) (−) line (with overlay) — FIXED to use minusInterior
	minusSite := complementString(p.RevSite)
	fmt.Fprintf(&b, "%s%s%s%s%s # (-)\n",
		linePrefix, prefixMinus, minusInterior, minusSite, suffixMinus,
	)

	// Optional caret under (−)
	if opt.ShowCaret && ov != nil && !ov.onPlus {
		startCol := ov.colAbs
		if startCol < 0 {
			startCol = 0
		}
		g := opt.CaretGlyph
		if g == "" {
			g = DefaultOptions.CaretGlyph
		}
		fmt.Fprintf(&b, "%s%s%s\n", linePrefix, strings.Repeat(" ", startCol), strings.Repeat(g, len(ov.seg)))
	}

	// Composite bars: probe bars + reverse-primer bars
	siteStart := len(prefixMinus) + innerMinus
	revBars := reverseString(matchLineAmbig(p.RevPrimer, p.RevSite, p.RevMismatchIdx, opt.ExactGlyphOrDefault(), opt.PartialGlyphOrDefault()))
	arrowStartCol := siteStart - len(arrowLeft)

	width := arrowStartCol + len(arrowLeft) + len(revBars)
	if ov != nil && ov.colAbs+len(ov.seg) > width {
		width = ov.colAbs + len(ov.seg)
	}
	line := make([]rune, width)
	for i := range line {
		line[i] = ' '
	}
	if opt.ShowProbeBars && ov != nil {
		for i := 0; i < len(ov.seg); i++ {
			pos := ov.colAbs + i
			if pos >= 0 && pos < width {
				line[pos] = []rune(opt.ExactGlyphOrDefault())[0]
			}
		}
	}
	for i, r := range arrowLeft {
		line[arrowStartCol+i] = r
	}
	for i, r := range revBars {
		line[arrowStartCol+len(arrowLeft)+i] = r
	}
	fmt.Fprintf(&b, "%s%s\n", linePrefix, string(line))

	// Sequence row: left probe block (optional) + right reverse-primer block
	if opt.ShowProbeSeqRow {
		leftBlock := ""
		leftStartCol := 0
		if ov != nil {
			if ann.Strand == "+" {
				leftBlock = "5'-" + ov.seg + "-3'"
			} else {
				leftBlock = "3'-" + ov.seg + "-5'"
			}
			leftStartCol = ov.colAbs - len("5'-")
			if leftStartCol < 0 {
				leftStartCol = 0
			}
		}
		rightSeq := reverseString(p.RevPrimer)
		rightBlock := "3'-" + rightSeq + "-5'"
		rightStartCol := arrowStartCol + len(arrowLeft) - len("3'-")
		if rightStartCol < 0 {
			rightStartCol = 0
		}
		w2 := rightStartCol + len(rightBlock)
		if ov != nil && leftStartCol+len(leftBlock) > w2 {
			w2 = leftStartCol + len(leftBlock)
		}
		line2 := make([]rune, w2)
		for i := range line2 {
			line2[i] = ' '
		}
		if ov != nil {
			for i, r := range leftBlock {
				line2[leftStartCol+i] = r
			}
		}
		for i, r := range rightBlock {
			line2[rightStartCol+i] = r
		}
		fmt.Fprintf(&b, "%s%s\n", linePrefix, string(line2))
	} else {
		revPrimerDisplayed := reverseString(p.RevPrimer)
		padPrimer := siteStart - len(prefixMinus)
		if padPrimer < 0 {
			padPrimer = 0
		}
		fmt.Fprintf(&b, "%s%s%s%s%s\n", linePrefix, strings.Repeat(" ", padPrimer), prefixMinus, revPrimerDisplayed, suffixMinus)
	}

	// Summary
	if ann.Found {
		fmt.Fprintf(&b, "%sprobe %q (%s) pos=%d mm=%d site=%s fwd_mm=%d@[%s] rev_mm=%d@[%s]\n",
			linePrefix,
			ann.Name, ann.Strand, ann.Pos, ann.MM, ann.Site,
			p.FwdMM, intsCSV(p.FwdMismatchIdx),
			p.RevMM, intsCSV(p.RevMismatchIdx),
		)
	} else {
		fmt.Fprintf(&b, "%sprobe %q NOT FOUND fwd_mm=%d@[%s] rev_mm=%d@[%s]\n",
			linePrefix, ann.Name,
			p.FwdMM, intsCSV(p.FwdMismatchIdx),
			p.RevMM, intsCSV(p.RevMismatchIdx),
		)
	}
	b.WriteString("#\n")
	return b.String()
}


// RenderAnnotated keeps backward compat (uses DefaultOptions).
func RenderAnnotated(p engine.Product, ann ProbeAnnotation) string {
	return RenderAnnotatedWithOptions(p, ann, DefaultOptions)
}

// helpers for default glyphs
func (o Options) ExactGlyphOrDefault() string {
	if o.ExactGlyph != "" {
		return o.ExactGlyph
	}
	return DefaultOptions.ExactGlyph
}
func (o Options) PartialGlyphOrDefault() string {
	if o.PartialGlyph != "" {
		return o.PartialGlyph
	}
	return DefaultOptions.PartialGlyph
}

===== END ./internal/pretty/pretty.go =====

===== BEGIN ./internal/pretty/pretty_test.go =====
package pretty

import (
	"os"
	"path/filepath"
	"testing"

	"ipcr/internal/engine"
)

func writeIfMissingOrUpdate(path string, got string) (created bool, err error) {
	// Ensure the testdata directory exists before writing.
	if err := os.MkdirAll(filepath.Dir(path), 0o755); err != nil {
		return false, err
	}
	// Allow updating goldens explicitly.
	if os.Getenv("UPDATE_GOLDEN") == "1" {
		return true, os.WriteFile(path, []byte(got), 0644)
	}
	// First-run: create golden if missing.
	if _, e := os.Stat(path); os.IsNotExist(e) {
		return true, os.WriteFile(path, []byte(got), 0644)
	}
	return false, nil
}

func mustRead(path string, t *testing.T) string {
	t.Helper()
	b, err := os.ReadFile(path)
	if err != nil {
		t.Fatalf("read golden %s: %v", path, err)
	}
	return string(b)
}

func TestRenderProductForward_Golden(t *testing.T) {
	p := engine.Product{
		FwdPrimer: "AAA", RevPrimer: "TTT",
		FwdSite: "AAA",  RevSite: "TTT",
		Length: 22, Start: 0, End: 22, Type: "forward",
	}
	got := RenderProduct(p)
	path := filepath.Join("testdata", "forward.golden")
	if created, err := writeIfMissingOrUpdate(path, got); err != nil {
		t.Fatalf("write golden: %v", err)
	} else if created {
		t.Logf("wrote %s", path)
		return
	}
	want := mustRead(path, t)
	if got != want {
		t.Fatalf("mismatch:\n--- got ---\n%s\n--- want ---\n%s", got, want)
	}
}

func TestRenderProductRevcomp_Golden(t *testing.T) {
	p := engine.Product{
		FwdPrimer: "ACGT", RevPrimer: "ACGT",
		FwdSite: "ACGT",  RevSite: "ACGT",
		Length: 30, Start: 10, End: 40, Type: "revcomp",
	}
	got := RenderProduct(p)
	path := filepath.Join("testdata", "revcomp.golden")
	if created, err := writeIfMissingOrUpdate(path, got); err != nil {
		t.Fatalf("write golden: %v", err)
	} else if created {
		t.Logf("wrote %s", path)
		return
	}
	want := mustRead(path, t)
	if got != want {
		t.Fatalf("mismatch:\n--- got ---\n%s\n--- want ---\n%s", got, want)
	}
}

func TestRenderAnnotated_Plus_Golden(t *testing.T) {
	p := engine.Product{
		FwdPrimer: "TCAG", RevPrimer: "GATC",
		FwdSite: "TCAG",  RevSite: "GATC",
		Length: 40, Start: 0, End: 40, Type: "forward",
	}
	ann := ProbeAnnotation{
		Name: "probe", Seq: "GTACGT", Found: true, Strand: "+", Pos: 6, MM: 0, Site: "GTACGT",
	}
	got := RenderAnnotated(p, ann)
	path := filepath.Join("testdata", "probe_plus.golden")
	if created, err := writeIfMissingOrUpdate(path, got); err != nil {
		t.Fatalf("write golden: %v", err)
	} else if created {
		t.Logf("wrote %s", path)
		return
	}
	want := mustRead(path, t)
	if got != want {
		t.Fatalf("mismatch:\n--- got ---\n%s\n--- want ---\n%s", got, want)
	}
}

func TestRenderAnnotated_Minus_Golden(t *testing.T) {
	p := engine.Product{
		FwdPrimer: "TCAGGCCTTTGCTACAATGAAC",
		RevPrimer: "TCAGGCCTTTGCTACAATGAAC",
		FwdSite:   "TCAGGCCTTTGCTACAAYGAAC", // Y to make mismatches obvious if you tweak visuals
		RevSite:   "TCAGGCCTTTGCTACAATGAAC",
		Length:    112, Start: 353221, End: 353333, Type: "revcomp",
	}
	ann := ProbeAnnotation{
		Name: "probe", Seq: "AACTGCATCATATCACATACT", Found: true, Strand: "-", Pos: 52, MM: 0, Site: "AGTATGTGATATGATGCAGTT",
	}
	got := RenderAnnotated(p, ann)
	path := filepath.Join("testdata", "probe_minus.golden")
	if created, err := writeIfMissingOrUpdate(path, got); err != nil {
		t.Fatalf("write golden: %v", err)
	} else if created {
		t.Logf("wrote %s", path)
		return
	}
	want := mustRead(path, t)
	if got != want {
		t.Fatalf("mismatch:\n--- got ---\n%s\n--- want ---\n%s", got, want)
	}
}

===== END ./internal/pretty/pretty_test.go =====

===== BEGIN ./internal/primer/iupac.go =====
// internal/primer/iupac.go
package primer

/* -------------------------- IUPAC lookup table -------------------------- */

var iupacMask [256]byte // bit0=A bit1=C bit2=G bit3=T

func init() {
	set := func(c byte, bits byte) { iupacMask[c] = bits }
	set('A', 1)           // 0001
	set('C', 2)           // 0010
	set('G', 4)           // 0100
	set('T', 8)           // 1000
	set('R', 1|4)         // A/G
	set('Y', 2|8)         // C/T
	set('S', 2|4)         // C/G
	set('W', 1|8)         // A/T
	set('K', 4|8)         // G/T
	set('M', 1|2)         // A/C
	set('B', 2|4|8)       // C/G/T
	set('D', 1|4|8)       // A/G/T
	set('H', 1|2|8)       // A/C/T
	set('V', 1|2|4)       // A/C/G
	set('N', 1|2|4|8)     // any   (primer side only)
}

/* --------------------------- BaseMatch (FAST) --------------------------- */

// baseMatch returns true if primer base `p` can pair with genome base `g`
// according to the IUPAC ambiguity codes *and* g ∈ {A,C,G,T}.
//
// A genome base of 'N' (or any non‑ACGT ASCII) is treated as a HARD mismatch.
// This prevents large N‑blocks from producing thousands of spurious hits.
func BaseMatch(g, p byte) bool {
	if g != 'A' && g != 'C' && g != 'G' && g != 'T' {
		return false // genome N or unknown char ⇒ mismatch
	}
	return iupacMask[p]&iupacMask[g] != 0
}
// ===
===== END ./internal/primer/iupac.go =====

===== BEGIN ./internal/primer/iupac_test.go =====
// internal/primer/iupac_test.go
package primer

import "testing"

func TestBaseMatch(t *testing.T) {
	tests := []struct {
		g, p byte
		want bool
	}{
		{'A', 'A', true},
		{'G', 'R', true},  // R = A/G
		{'C', 'R', false},
		{'T', 'N', true},  // N = any
		{'G', 'N', true},
		{'A', 'B', false}, // B = C/G/T  (not A)
		{'C', 'B', true},
		{'T', 'X', false}, // unknown primer char
	}
	for _, tt := range tests {
		if got := BaseMatch(tt.g, tt.p); got != tt.want {
			t.Errorf("BaseMatch(%q,%q) = %v, want %v", tt.g, tt.p, got, tt.want)
		}
	}
}
// ===
===== END ./internal/primer/iupac_test.go =====

===== BEGIN ./internal/primer/loader.go =====
// internal/primer/loader.go
package primer

import (
	"bufio"
	"fmt"
	"os"
	"strings"
)

// LoadTSV reads a whitespace‑separated file with
// id forward reverse min max
// min / max are optional (0 if absent).
func LoadTSV(path string) ([]Pair, error) {
	fh, err := os.Open(path)
	if err != nil { return nil, err }
	defer fh.Close()

	var list []Pair
	sc := bufio.NewScanner(fh)
	ln := 0
	for sc.Scan() {
		ln++
		line := strings.TrimSpace(sc.Text())
		if line == "" || line[0] == '#' { continue }
		f := strings.Fields(line)
		if len(f) < 3 || len(f) == 4 || len(f) > 5 {
			return nil, fmt.Errorf("%s:%d bad field count", path, ln)
		}
		p := Pair{
			ID:      f[0],
			Forward: strings.ToUpper(f[1]),
			Reverse: strings.ToUpper(f[2]),
		}
		if len(f) >= 4 {
			fmt.Sscan(f[3], &p.MinProduct)
		}
		if len(f) == 5 {
			fmt.Sscan(f[4], &p.MaxProduct)
		}
		list = append(list, p)
	}
	if err := sc.Err(); err != nil { return nil, err }
	return list, nil
}
// ===
===== END ./internal/primer/loader.go =====

===== BEGIN ./internal/primer/loader_test.go =====
// internal/primer/loader_test.go
package primer

import (
	"os"
	"testing"
)

func TestLoadTSV(t *testing.T) {
	tmp := "tmp_primers.tsv"
	os.WriteFile(tmp, []byte("p1 ACG ACG 5 15\n#comment\n"), 0644)
	defer os.Remove(tmp)

	ps, err := LoadTSV(tmp)
	if err != nil || len(ps) != 1 || ps[0].ID != "p1" || ps[0].MinProduct != 5 {
		t.Fatalf("LoadTSV failed: %+v %v", ps, err)
	}
}
// ===
===== END ./internal/primer/loader_test.go =====

===== BEGIN ./internal/primer/match.go =====
// internal/primer/match.go
package primer

import "bytes"

/* ----------------------- types --------------------- */

type Match struct {
	Pos         int
	Mismatches  int
	Length      int
	MismatchIdx []int // 0‑based positions in primer (5'→3') that mismatched
}

/* ---------------------- helpers -------------------- */

func isUnambiguous(p []byte) bool {
	for _, c := range p {
		if c != 'A' && c != 'C' && c != 'G' && c != 'T' {
			return false
		}
	}
	return true
}

/* --------------------------- FindMatches (cap) -------------------------- */

// capHits == 0  ➜ unlimited
// terminalWindow: N bases at the primer 3' end where mismatches are disallowed (0=allow)
func FindMatches(seq, primer []byte, maxMM, capHits int, terminalWindow int) []Match {
	pl := len(primer)
	if pl == 0 || len(seq) < pl {
		return nil
	}

	// Exact‑match fast path: SIMD'd bytes.Index jump scanning.
	// Safe with any terminalWindow because mismatches=0.
	if maxMM == 0 && isUnambiguous(primer) {
		out := make([]Match, 0, 8)
		for i := 0; ; {
			j := bytes.Index(seq[i:], primer)
			if j < 0 {
				break
			}
			pos := i + j
			out = append(out, Match{Pos: pos, Mismatches: 0, Length: pl})
			if capHits > 0 && len(out) >= capHits {
				break
			}
			i = pos + 1
		}
		return out
	}

	end := len(seq) - pl
	out := make([]Match, 0, 8)

	// cutoff index: any mismatch with j >= cutoff is disallowed
	cutoff := pl - terminalWindow
	if terminalWindow <= 0 {
		cutoff = pl + 1 // effectively disable the check
	}
	if cutoff < 0 {
		cutoff = 0
	}

window:
	for pos := 0; pos <= end; pos++ {
		mm := 0
		var idx []int
		for j := 0; j < pl; j++ {
			if !BaseMatch(seq[pos+j], primer[j]) {
				// Reject if within 3' terminal window
				if j >= cutoff {
					continue window
				}
				mm++
				idx = append(idx, j)
				if mm > maxMM {
					continue window
				}
			}
		}
		out = append(out, Match{Pos: pos, Mismatches: mm, Length: pl, MismatchIdx: idx})
		if capHits > 0 && len(out) >= capHits {
			break // early stop to cap memory
		}
	}
	return out
}

===== END ./internal/primer/match.go =====

===== BEGIN ./internal/primer/match_test.go =====
// internal/primer/match_test.go
package primer

import "testing"

func TestFindMatches(t *testing.T) {
	seq := []byte("ACGTACGTACGT")

	tests := []struct {
		name         string
		primer       string
		maxMM        int
		termWin      int
		wantCount    int
		wantFirstPos int
	}{
		{
			name:         "perfect match",
			primer:       "ACG",
			maxMM:        0,
			termWin:      0,
			wantCount:    3,
			wantFirstPos: 0,
		},
		{
			name:         "one mismatch allowed",
			primer:       "AGG",
			maxMM:        1,
			termWin:      0,
			wantCount:    3,
			wantFirstPos: 0,
		},
		{
			name:         "exceed mismatch threshold",
			primer:       "AGG",
			maxMM:        0,
			termWin:      0,
			wantCount:    0,
			wantFirstPos: -1,
		},
		{
			name:         "3prime mismatch disallowed (window=1)",
			primer:       "ACA", // 3' A mismatches genome G in every window
			maxMM:        1,
			termWin:      1,
			wantCount:    0,
			wantFirstPos: -1,
		},
		{
			name:         "3prime mismatch allowed (window=0)",
			primer:       "ACG",
			maxMM:        1,
			termWin:      0,
			wantCount:    3,
			wantFirstPos: 0,
		},
		{
			name:         "IUPAC degeneracy",
			primer:       "ACN",
			maxMM:        0,
			termWin:      0,
			wantCount:    3,
			wantFirstPos: 0,
		},
	}

	for _, tc := range tests {
		hits := FindMatches(seq, []byte(tc.primer), tc.maxMM, 0, tc.termWin)
		if len(hits) != tc.wantCount {
			t.Errorf("%s: got %d hits, want %d", tc.name, len(hits), tc.wantCount)
		}
		if tc.wantCount > 0 && tc.wantFirstPos != -1 && hits[0].Pos != tc.wantFirstPos {
			t.Errorf("%s: first match pos %d, want %d", tc.name, hits[0].Pos, tc.wantFirstPos)
		}
	}
}

===== END ./internal/primer/match_test.go =====

===== BEGIN ./internal/primer/mismatch.go =====
// internal/primer/mismatch.go
package primer

func MismatchCount(g, p []byte) int {
	if len(g) != len(p) {
		panic("MismatchCount: length mismatch")
	}
	mm := 0
	for i := 0; i < len(p); i++ {
		if !BaseMatch(g[i], p[i]) {
			mm++
		}
	}
	return mm
}
// ===
===== END ./internal/primer/mismatch.go =====

===== BEGIN ./internal/primer/mismatch_test.go =====
// internal/primer/mismatch_test.go
package primer

import "testing"

func TestMismatchCount(t *testing.T) {
	//genome := []byte("ACGTACGT")
	tests := []struct {
		window string
		primer string
		want   int
	}{
		{"ACGT", "ACGT", 0},      // perfect
		{"ACGT", "NNNN", 0},      // N matches everything
		{"ACGT", "RRRR", 2},      // R=A/G  => mismatches at C,T = 2
		{"ACGT", "TTTT", 3},      // only final T matches
	}
	for _, tc := range tests {
		got := MismatchCount([]byte(tc.window), []byte(tc.primer))
		if got != tc.want {
			t.Errorf("MismatchCount(%q,%q) = %d, want %d",
				tc.window, tc.primer, got, tc.want)
		}
	}

	// Length‑mismatch panic check (optional)
	defer func() {
		if r := recover(); r == nil {
			t.Errorf("expected panic on unequal lengths")
		}
	}()
	MismatchCount([]byte("AAA"), []byte("AA"))
}
// ===
===== END ./internal/primer/mismatch_test.go =====

===== BEGIN ./internal/primer/pair.go =====
// internal/primer/pair.go
package primer

type Pair struct {
	ID                string
	Forward           string // Primer A sequence (5'→3', binds forward strand)
	Reverse           string // Primer B sequence (5'→3', binds reverse strand)
	MinProduct        int
	MaxProduct        int
}
// ===
===== END ./internal/primer/pair.go =====

===== BEGIN ./internal/primer/rc.go =====
// internal/primer/rc.go
package primer

var complement [256]byte

func init() {
    complement['A'] = 'T'; complement['C'] = 'G'; complement['G'] = 'C'; complement['T'] = 'A'
    complement['R'] = 'Y'; complement['Y'] = 'R'
    complement['S'] = 'S'; complement['W'] = 'W'
    complement['K'] = 'M'; complement['M'] = 'K'
    complement['B'] = 'V'; complement['V'] = 'B'
    complement['D'] = 'H'; complement['H'] = 'D'
    complement['N'] = 'N'
}

func RevComp(seq []byte) []byte {
	n := len(seq)
	if n == 0 {
		return nil
	}
	out := make([]byte, n)
	for i := 0; i < n; i++ {
		b := seq[n-1-i]
		c := complement[b]
		if c == 0 { c = 'N' }
	out[i] = c
	}
	return out
}
// ===
===== END ./internal/primer/rc.go =====

===== BEGIN ./internal/primer/rc_test.go =====
// internal/primer/rc_test.go
package primer

import (
	"bytes"
	"testing"
)

func TestRevCompSimple(t *testing.T) {
	got := RevComp([]byte("AGTC"))
	want := []byte("GACT")
	if !bytes.Equal(got, want) {
		t.Errorf("RevComp(AGTC) = %s, want %s", got, want)
	}
}

func TestRevCompAmbiguous(t *testing.T) {
	in  := []byte("RYSWKMBDHVN")
	want := []byte("NBDHVKMWSRY")
	got  := RevComp(in)
	if !bytes.Equal(got, want) {
		t.Errorf("RevComp(%s) = %s, want %s", in, got, want)
	}
}

func TestRevCompEmpty(t *testing.T) {
	if RevComp(nil) != nil {
		t.Errorf("RevComp(nil) should return nil")
	}
	if out := RevComp([]byte("")); len(out) != 0 {
		t.Errorf("RevComp(\"\") length = %d, want 0", len(out))
	}
}
// ===
===== END ./internal/primer/rc_test.go =====

===== BEGIN ./internal/probe/annotate.go =====
// internal/probe/annotate.go
package probe

import "ipcr/internal/oligo"

type Annotation struct {
	Found  bool
	Strand string // "+" or "-"
	Pos    int
	MM     int
	Site   string
}

func AnnotateAmplicon(amplicon string, probe string, maxMM int) Annotation {
	h := oligo.BestHit(amplicon, probe, maxMM)
	return Annotation{Found: h.Found, Strand: h.Strand, Pos: h.Pos, MM: h.MM, Site: h.Site}
}

===== END ./internal/probe/annotate.go =====

===== BEGIN ./internal/probe/annotate_test.go =====
package probe

import "testing"

func TestAnnotateAmplicon(t *testing.T) {
	amp := "ACGTACGTACGT"
	probe := "GTAC" // occurs at pos 2 and 6 and 10

	a := AnnotateAmplicon(amp, probe, 0)
	if !a.Found || a.MM != 0 || a.Pos != 2 || a.Site != "GTAC" {
		t.Fatalf("unexpected: %+v", a)
	}

	// Reverse complement should also match
	a2 := AnnotateAmplicon(amp, "GTGC", 1) // RC is GCAC; allow 1 mm
	if !a2.Found {
		t.Fatalf("expected rc match with mismatches")
	}
}

===== END ./internal/probe/annotate_test.go =====

===== BEGIN ./internal/probeapp/app.go =====
package probeapp

import (
	"bufio"
	"context"
	"errors"
	"flag"
	"fmt"
	"io"
	"strings"

	"ipcr/internal/appcore"
	"ipcr/internal/primer"
	"ipcr/internal/probecli"
	"ipcr/internal/runutil"
	"ipcr/internal/version"
	"ipcr/internal/visitors"
	"ipcr/internal/writers"
)

// RunContext is the ipcr-probe app entrypoint used by cmd/ipcr-probe.
func RunContext(parent context.Context, argv []string, stdout, stderr io.Writer) int {
	outw := bufio.NewWriter(stdout)
	defer outw.Flush()

	fs := probecli.NewFlagSet("ipcr-probe")
	fs.SetOutput(io.Discard)

	if len(argv) == 0 {
		_, _ = probecli.ParseArgs(fs, []string{"-h"})
		fs.SetOutput(outw)
		fs.Usage()
		if err := outw.Flush(); writers.IsBrokenPipe(err) {
			return 0
		} else if err != nil {
			fmt.Fprintln(stderr, err)
			return 3
		}
		return 0
	}

	opts, err := probecli.ParseArgs(fs, argv)
	if err != nil {
		if errors.Is(err, flag.ErrHelp) {
			fs.SetOutput(outw)
			fs.Usage()
			if e := outw.Flush(); writers.IsBrokenPipe(e) {
				return 0
			} else if e != nil {
				fmt.Fprintln(stderr, e)
				return 3
			}
			return 0
		}
		fmt.Fprintln(stderr, err)
		fs.SetOutput(outw)
		fs.Usage()
		if e := outw.Flush(); writers.IsBrokenPipe(e) {
			return 0
		} else if e != nil {
			fmt.Fprintln(stderr, e)
			return 3
		}
		return 2
	}

	if opts.Version {
		fmt.Fprintf(outw, "ipcr version %s (ipcr-probe)\n", version.Version)
		if e := outw.Flush(); writers.IsBrokenPipe(e) {
			return 0
		} else if e != nil {
			fmt.Fprintln(stderr, e)
			return 3
		}
		return 0
	}

	// Primer pairs
	var pairs []primer.Pair
	if opts.PrimerFile != "" {
		pairs, err = primer.LoadTSV(opts.PrimerFile)
		if err != nil {
			fmt.Fprintln(stderr, err)
			return 2
		}
	} else {
		pairs = []primer.Pair{{
			ID:         "manual",
			Forward:    opts.Fwd,
			Reverse:    opts.Rev,
			MinProduct: opts.MinLen,
			MaxProduct: opts.MaxLen,
		}}
	}

	termWin := runutil.ComputeTerminalWindow(opts.Mode, opts.TerminalWindow)
	coreOpts := appcore.Options{
		SeqFiles:        opts.SeqFiles,
		MaxMM:           opts.Mismatches,
		TerminalWindow:  termWin,
		MinLen:          opts.MinLen,
		MaxLen:          opts.MaxLen,
		HitCap:          opts.HitCap,
		SeedLength:      opts.SeedLength,
		Circular:        opts.Circular,
		Threads:         opts.Threads,
		ChunkSize:       opts.ChunkSize,
		Quiet:           opts.Quiet,
		NoMatchExitCode: opts.NoMatchExitCode,
	}

	writer := appcore.NewAnnotatedWriterFactory(opts.Output, opts.Sort, opts.Header, opts.Pretty)

	visitor := visitors.Probe{
		Name:    opts.ProbeName,
		Seq:     strings.ToUpper(opts.Probe),
		MaxMM:   opts.ProbeMaxMM,
		Require: opts.RequireProbe,
	}

	return appcore.Run(parent, stdout, stderr, coreOpts, pairs, visitor.Visit, writer)
}

// Compatibility shim for older tests and callers.
// Signature matches previous probeapp.Run(argv, stdout, stderr) style.
func Run(argv []string, stdout, stderr io.Writer) int {
	return RunContext(context.Background(), argv, stdout, stderr)
}

===== END ./internal/probeapp/app.go =====

===== BEGIN ./internal/probecli/options.go =====
// internal/probecli/options.go
package probecli

import (
	"flag"
	"fmt"
	"strings"

	"ipcr/internal/clibase"
	"ipcr/internal/cliutil"
)

const (
	ModeRealistic = "realistic"
	ModeDebug     = "debug"
)

type Options struct {
	// Shared (embed the common fields)
	PrimerFile string
	Fwd        string
	Rev        string
	SeqFiles   []string

	Mismatches     int
	MinLen         int
	MaxLen         int
	HitCap         int
	TerminalWindow int
	Mode           string

	Threads    int
	ChunkSize  int
	SeedLength int
	Circular   bool

	Output          string
	Products        bool // parity with ipcr
	Pretty          bool
	Sort            bool
	Header          bool
	NoMatchExitCode int

	Quiet   bool
	Version bool

	// Probe-specific
	Probe        string
	ProbeName    string
	ProbeMaxMM   int
	RequireProbe bool
}

func NewFlagSet(name string) *flag.FlagSet {
	fs := flag.NewFlagSet(name, flag.ContinueOnError)
	fs.Usage = func() {
		out := fs.Output()
		def := func(n string) string { if f := fs.Lookup(n); f != nil { return f.DefValue }; return "" }
		fmt.Fprintf(out, "%s – in-silico PCR + internal probe scan\n\n", name)
		fmt.Fprintln(out, "Usage:")
		fmt.Fprintf(out, "  %s [options] --forward AAA --reverse TTT --probe PROBE ref.fa\n", name)

		fmt.Fprintln(out, "\nInput:")
		fmt.Fprintln(out, "  -f, --forward string        Forward primer (5'→3')")
		fmt.Fprintln(out, "  -r, --reverse string        Reverse primer (5'→3')")
		fmt.Fprintln(out, "  -p, --primers string        Primer TSV (id fwd rev [min] [max])")
		fmt.Fprintln(out, "  -s, --sequences file        FASTA file(s) (repeatable) or '-' for STDIN")

		fmt.Fprintln(out, "\nProbe:")
		fmt.Fprintln(out, "  -P, --probe string          Internal oligo sequence (5'→3') [required]")
		fmt.Fprintf(out, "      --probe-name string     Label for the probe [%s]\n", def("probe-name"))
		fmt.Fprintf(out, "  -M, --probe-max-mm int      Max mismatches allowed in probe match [%s]\n", def("probe-max-mm"))
		fmt.Fprintf(out, "      --require-probe         Only report amplicons that contain the probe [%s]\n", def("require-probe"))

		fmt.Fprintln(out, "\nPCR / Performance / Output / Misc: (same as ipcr)")
		fmt.Fprintln(out, "      --output text | json | jsonl | fasta")
	}
	return fs
}

type stringSlice []string
func (s *stringSlice) String() string     { return strings.Join(*s, ",") }
func (s *stringSlice) Set(v string) error { *s = append(*s, v); return nil }

func ParseArgs(fs *flag.FlagSet, argv []string) (Options, error) {
	var o Options
	var help bool

	// Shared flags via clibase
	var c clibase.Common
	noHeader := clibase.Register(fs, &c)

	// Probe flags
	fs.StringVar(&o.Probe, "probe", "", "internal oligo (5'→3') [required]")
	fs.StringVar(&o.ProbeName, "probe-name", "probe", "probe label")
	fs.IntVar(&o.ProbeMaxMM, "probe-max-mm", 0, "max mismatches allowed for probe [0]")
	fs.BoolVar(&o.RequireProbe, "require-probe", true, "only report amplicons that contain the probe [true]")
	fs.IntVar(&o.ProbeMaxMM, "M", 0, "alias of --probe-max-mm")
	fs.StringVar(&o.Probe, "P", "", "alias of --probe")

	// Help
	fs.BoolVar(&help, "h", false, "show this help [false]")

	// Split & parse
	flagArgs, posArgs := cliutil.SplitFlagsAndPositionals(fs, argv)
	if err := fs.Parse(flagArgs); err != nil {
		return o, err
	}
	if help {
		return o, flag.ErrHelp
	}
	if c.Version {
		o.Version = true
		return o, nil
	}

	// Finalize header, expand pos, shared validation
	if err := clibase.AfterParse(fs, &c, noHeader, posArgs); err != nil {
		return o, err
	}
	// Probe-specific validation
	if o.Probe == "" {
		return o, fmt.Errorf("--probe is required")
	}

	// Copy shared → Options
	o.PrimerFile, o.Fwd, o.Rev, o.SeqFiles = c.PrimerFile, c.Fwd, c.Rev, c.SeqFiles
	o.Mismatches, o.MinLen, o.MaxLen, o.HitCap, o.TerminalWindow, o.Mode =
		c.Mismatches, c.MinLen, c.MaxLen, c.HitCap, c.TerminalWindow, c.Mode
	o.Threads, o.ChunkSize, o.SeedLength, o.Circular = c.Threads, c.ChunkSize, c.SeedLength, c.Circular
	o.Output, o.Products, o.Pretty, o.Sort, o.Header, o.NoMatchExitCode =
		c.Output, c.Products, c.Pretty, c.Sort, c.Header, c.NoMatchExitCode
	o.Quiet = c.Quiet
	return o, nil
}

func Parse() (Options, error) { return ParseArgs(NewFlagSet("ipcr-probe"), nil) }

===== END ./internal/probecli/options.go =====

===== BEGIN ./internal/probecli/options_test.go =====
package probecli

import (
	"flag"
	"os"
	"path/filepath"
	"testing"
)

func newFS() *flag.FlagSet { return flag.NewFlagSet("test", flag.ContinueOnError) }

func mustParse(t *testing.T, args ...string) Options {
	t.Helper()
	o, err := ParseArgs(newFS(), args)
	if err != nil {
		t.Fatalf("parse: %v", err)
	}
	return o
}

func TestProbeFlagsOK(t *testing.T) {
	o := mustParse(t,
		"--forward", "AAA", "--reverse", "TTT",
		"--probe", "ACG", "ref.fa",
	)
	if o.Probe != "ACG" || len(o.SeqFiles) != 1 || o.SeqFiles[0] != "ref.fa" {
		t.Fatalf("bad parse: %+v", o)
	}
}

func TestShortProbeAlias_P(t *testing.T) {
	o := mustParse(t,
		"--forward", "AAA", "--reverse", "TTT",
		"-P", "NNNTTT",
		"ref.fa",
	)
	if o.Probe != "NNNTTT" {
		t.Fatalf("want probe=NNNTTT via -P, got %q", o.Probe)
	}
}

func TestShortProbeMaxMMAlias_M(t *testing.T) {
	o := mustParse(t,
		"--forward", "AAA", "--reverse", "TTT",
		"--probe", "ACG",
		"-M", "2",
		"ref.fa",
	)
	if o.ProbeMaxMM != 2 {
		t.Fatalf("want ProbeMaxMM=2, got %d", o.ProbeMaxMM)
	}
}

func TestRequireProbeMissingErrors(t *testing.T) {
	_, err := ParseArgs(newFS(), []string{
		"--forward", "AAA", "--reverse", "TTT", "ref.fa",
	})
	if err == nil {
		t.Fatal("expected error when --probe missing")
	}
}

func TestPositionalGlobOK(t *testing.T) {
	dir := t.TempDir()
	a := filepath.Join(dir, "a.fa")
	b := filepath.Join(dir, "b.fa")
	_ = os.WriteFile(a, []byte(">a\nA\n"), 0644)
	_ = os.WriteFile(b, []byte(">b\nA\n"), 0644)
	pat := filepath.Join(dir, "*.fa")

	o := mustParse(t, "--forward", "AAA", "--reverse", "TTT", "--probe", "ACG", pat)
	if len(o.SeqFiles) != 2 {
		t.Fatalf("want 2 seqs, got %d", len(o.SeqFiles))
	}
}

func TestMutualExclusion(t *testing.T) {
	_, err := ParseArgs(newFS(), []string{
		"--primers", "p.tsv", "--forward", "AAA", "--reverse", "TTT", "--probe", "ACG", "ref.fa",
	})
	if err == nil {
		t.Fatal("expected mutual exclusion error")
	}
}

===== END ./internal/probecli/options_test.go =====

===== BEGIN ./internal/probeintegration/integration_test.go =====
package probeintegration

import (
	"bytes"
	"encoding/json"
	"os"
	"testing"

	"ipcr/internal/probeapp"
	"ipcr/pkg/api"
)

func write(t *testing.T, fn, data string) string {
	t.Helper()
	if err := os.WriteFile(fn, []byte(data), 0644); err != nil {
		t.Fatalf("write %s: %v", fn, err)
	}
	return fn
}

func TestProbeEndToEndJSON(t *testing.T) {
	fa := write(t, "p_itest.fa", ">s\nACGTACGTACGT\n")
	defer os.Remove(fa)

	var out, errB bytes.Buffer
	code := probeapp.Run([]string{
		"--forward", "ACG",
		"--reverse", "ACG",
		"--sequences", fa,
		"--probe", "GTAC",
		"--probe-name", "myprobe",
		"--output", "json",
		"--sort",
	}, &out, &errB)

	if code != 0 {
		t.Fatalf("exit %d err=%s", code, errB.String())
	}
	var got []api.AnnotatedProductV1
	if err := json.Unmarshal(out.Bytes(), &got); err != nil {
		t.Fatalf("json parse: %v", err)
	}
	if len(got) == 0 {
		t.Fatalf("expected ≥1 annotated amplicon")
	}
	found := false
	for _, ap := range got {
		if ap.ProbeFound && ap.ProbeMM == 0 {
			found = true
			break
		}
	}
	if !found {
		t.Fatalf("expected at least one perfect probe hit; got %v", got[0])
	}
}

func TestRequireProbeFilter(t *testing.T) {
	fa := write(t, "p_itest2.fa", ">s\nACGTACGTACGT\n")
	defer os.Remove(fa)

	var out, errB bytes.Buffer
	code := probeapp.Run([]string{
		"--forward", "ACG",
		"--reverse", "ACG",
		"--sequences", fa,
		"--probe", "AAAAA", // not present
		"--output", "json",
	}, &out, &errB)

	if code == 0 {
		t.Fatalf("expected non-zero exit when no hits under --require-probe=true")
	}
}

===== END ./internal/probeintegration/integration_test.go =====

===== BEGIN ./internal/probeoutput/fasta.go =====
package probeoutput

import (
	"fmt"
	"io"
)

// StreamFASTA streams FASTA for annotated products (uses Product.Seq).
func StreamFASTA(w io.Writer, in <-chan AnnotatedProduct) error {
	idx := 1
	for ap := range in {
		p := ap.Product
		if p.Seq == "" { continue }
		if _, err := fmt.Fprintf(
			w, ">%s_%d start=%d end=%d len=%d source_file=%s probe=%s found=%t\n%s\n",
			p.ExperimentID, idx, p.Start, p.End, p.Length, p.SourceFile, ap.ProbeName, ap.ProbeFound, p.Seq,
		); err != nil { return err }
		idx++
	}
	return nil
}

func WriteFASTA(w io.Writer, list []AnnotatedProduct) error {
	for i, ap := range list {
		p := ap.Product
		if p.Seq == "" { continue }
		if _, err := fmt.Fprintf(
			w, ">%s_%d start=%d end=%d len=%d source_file=%s probe=%s found=%t\n%s\n",
			p.ExperimentID, i+1, p.Start, p.End, p.Length, p.SourceFile, ap.ProbeName, ap.ProbeFound, p.Seq,
		); err != nil { return err }
	}
	return nil
}

===== END ./internal/probeoutput/fasta.go =====

===== BEGIN ./internal/probeoutput/json.go =====
// internal/probeoutput/json.go
package probeoutput

import (
	"encoding/json"
	"io"

	"ipcr/pkg/api"
)

func ToAPIAnnotated(ap AnnotatedProduct) api.AnnotatedProductV1 {
	p := ap.Product
	return api.AnnotatedProductV1{
		ExperimentID:   p.ExperimentID,
		SequenceID:     p.SequenceID,
		Start:          p.Start,
		End:            p.End,
		Length:         p.Length,
		Type:           p.Type,
		FwdMM:          p.FwdMM,
		RevMM:          p.RevMM,
		FwdMismatchIdx: append([]int(nil), p.FwdMismatchIdx...),
		RevMismatchIdx: append([]int(nil), p.RevMismatchIdx...),
		Seq:            p.Seq,
		SourceFile:     p.SourceFile,

		ProbeName:   ap.ProbeName,
		ProbeSeq:    ap.ProbeSeq,
		ProbeFound:  ap.ProbeFound,
		ProbeStrand: ap.ProbeStrand,
		ProbePos:    ap.ProbePos,
		ProbeMM:     ap.ProbeMM,
		ProbeSite:   ap.ProbeSite,
	}
}

func ToAPIAnnotatedSlice(list []AnnotatedProduct) []api.AnnotatedProductV1 {
	out := make([]api.AnnotatedProductV1, 0, len(list))
	for _, ap := range list {
		out = append(out, ToAPIAnnotated(ap))
	}
	return out
}

// WriteJSON encodes AnnotatedProducts using the stable wire schema (v1).
func WriteJSON(w io.Writer, list []AnnotatedProduct) error {
	enc := json.NewEncoder(w)
	enc.SetIndent("", "  ")
	return enc.Encode(ToAPIAnnotatedSlice(list))
}

===== END ./internal/probeoutput/json.go =====

===== BEGIN ./internal/probeoutput/json_text_test.go =====
package probeoutput

import (
	"bytes"
	"encoding/json"
	"ipcr/pkg/api"
	"testing"
)

func TestJSONRoundTrip(t *testing.T) {
	ap := AnnotatedProduct{}
	ap.ExperimentID = "x"
	ap.SequenceID = "s"
	ap.ProbeName = "p"
	ap.ProbeSeq  = "ACG"
	ap.ProbeFound = true

	var buf bytes.Buffer
	if err := WriteJSON(&buf, []AnnotatedProduct{ap}); err != nil {
		t.Fatalf("json write: %v", err)
	}
	var got []api.AnnotatedProductV1
	if err := json.Unmarshal(buf.Bytes(), &got); err != nil || len(got) != 1 || got[0].ProbeName != "p" {
		t.Fatalf("json roundtrip failed: %v %#v", err, got)
	}
}

===== END ./internal/probeoutput/json_text_test.go =====

===== BEGIN ./internal/probeoutput/pretty.go =====
package probeoutput

import (
	"ipcr/internal/pretty"
)

func RenderPretty(ap AnnotatedProduct) string {
	ann := pretty.ProbeAnnotation{
		Name:   ap.ProbeName,
		Seq:    ap.ProbeSeq,
		Found:  ap.ProbeFound,
		Strand: ap.ProbeStrand,
		Pos:    ap.ProbePos,
		MM:     ap.ProbeMM,
		Site:   ap.ProbeSite,
	}
	return pretty.RenderAnnotated(ap.Product, ann)
}

func RenderPrettyWithOptions(ap AnnotatedProduct, opt pretty.Options) string {
	ann := pretty.ProbeAnnotation{
		Name:   ap.ProbeName,
		Seq:    ap.ProbeSeq,
		Found:  ap.ProbeFound,
		Strand: ap.ProbeStrand,
		Pos:    ap.ProbePos,
		MM:     ap.ProbeMM,
		Site:   ap.ProbeSite,
	}
	return pretty.RenderAnnotatedWithOptions(ap.Product, ann, opt)
}

===== END ./internal/probeoutput/pretty.go =====

===== BEGIN ./internal/probeoutput/text.go =====
package probeoutput

import (
	"fmt"
	"io"
	"strconv"
	"strings"
)

// intsCSV converts []int to "1,2,3" (empty string if none).
func intsCSV(a []int) string {
	if len(a) == 0 { return "" }
	ss := make([]string, len(a))
	for i, v := range a { ss[i] = strconv.Itoa(v) }
	return strings.Join(ss, ",")
}

// WriteRowTSV emits exactly one TSV row for an AnnotatedProduct.
func WriteRowTSV(w io.Writer, ap AnnotatedProduct) error {
	p := ap.Product
	_, err := fmt.Fprintf(
		w, "%s\t%s\t%s\t%d\t%d\t%d\t%s\t%d\t%d\t%s\t%s\t%s\t%s\t%t\t%s\t%s\t%s\t%s\n",
		p.SourceFile, p.SequenceID, p.ExperimentID,
		p.Start, p.End, p.Length, p.Type,
		p.FwdMM, p.RevMM,
		intsCSV(p.FwdMismatchIdx), intsCSV(p.RevMismatchIdx),
		ap.ProbeName, ap.ProbeSeq, ap.ProbeFound,
		ap.ProbeStrand,
		// empty if not found:
		func() string { if ap.ProbeFound { return strconv.Itoa(ap.ProbePos) } else { return "" } }(),
		func() string { if ap.ProbeFound { return strconv.Itoa(ap.ProbeMM) } else { return "" } }(),
		ap.ProbeSite,
	)
	return err
}

func StreamText(w io.Writer, in <-chan AnnotatedProduct, header bool) error {
	if header {
		if _, err := fmt.Fprintln(w, TSVHeaderProbe); err != nil { return err }
	}
	for ap := range in {
		if err := WriteRowTSV(w, ap); err != nil { return err }
	}
	return nil
}

func WriteText(w io.Writer, list []AnnotatedProduct, header bool) error {
	if header {
		if _, err := fmt.Fprintln(w, TSVHeaderProbe); err != nil { return err }
	}
	for _, ap := range list {
		if err := WriteRowTSV(w, ap); err != nil { return err }
	}
	return nil
}

===== END ./internal/probeoutput/text.go =====

===== BEGIN ./internal/probeoutput/types.go =====
// internal/probeoutput/types.go
package probeoutput

import "ipcr/internal/engine"

type AnnotatedProduct struct {
	engine.Product

	ProbeName   string `json:"probe_name"`
	ProbeSeq    string `json:"probe_seq"`
	ProbeFound  bool   `json:"probe_found"`
	ProbeStrand string `json:"probe_strand,omitempty"` // "+", "-" if found
	ProbePos    int    `json:"probe_pos,omitempty"`
	ProbeMM     int    `json:"probe_mm,omitempty"`
	ProbeSite   string `json:"probe_site,omitempty"`
}

// Append probe columns to the base TSV header used by ipcr text output.
const TSVHeaderProbe = "source_file\tsequence_id\texperiment_id\tstart\tend\tlength\ttype\t" +
	"fwd_mm\trev_mm\tfwd_mm_i\trev_mm_i\t" +
	"probe_name\tprobe_seq\tprobe_found\tprobe_strand\tprobe_pos\tprobe_mm\tprobe_site"

===== END ./internal/probeoutput/types.go =====

===== BEGIN ./internal/runutil/runutil.go =====
// internal/runutil/runutil.go
package runutil

// ComputeTerminalWindow returns the effective terminal 3' window
// given the CLI mode and an override value. If terminalWindow >= 0,
// that value is used as-is. Otherwise: realistic=3, everything else=0.
func ComputeTerminalWindow(mode string, terminalWindow int) int {
	if terminalWindow >= 0 {
		return terminalWindow
	}
	if mode == "realistic" {
		return 3
	}
	return 0
}

// ComputeOverlap chooses a safe chunk overlap. If maxLen > 0, overlap must be
// at least maxLen to ensure a product straddling a boundary is seen. We also
// ensure overlap >= (maxPrimerLen - 1) so a primer site cannot be split.
func ComputeOverlap(maxLen, maxPrimerLen int) int {
	ov := 0
	if maxLen > 0 {
		ov = maxLen
	}
	if mpl := maxPrimerLen - 1; mpl > ov {
		ov = mpl
	}
	return ov
}

// ValidateChunking decides whether chunking is allowed, returns (chunkSize, overlap, warnings).
// Rules (matching current behavior):
//  • --circular disables chunking (ignore --chunk-size)
//  • If --chunk-size <= 0 → no chunking
//  • If --max-length <= 0 → disable chunking (needs max-length)
//  • If --chunk-size <= --max-length → disable chunking (must be larger)
// When enabled, overlap is ComputeOverlap(maxLen, maxPrimerLen).
func ValidateChunking(circular bool, chunkSize, maxLen, maxPrimerLen int) (int, int, []string) {
	var warns []string
	if circular {
		if chunkSize != 0 {
			warns = append(warns, "warning: --circular disables chunking; ignoring --chunk-size")
		}
		return 0, 0, warns
	}
	if chunkSize <= 0 {
		return 0, 0, nil
	}
	if maxLen <= 0 {
		warns = append(warns, "warning: --chunk-size requires --max-length; disabling")
		return 0, 0, warns
	}
	if chunkSize <= maxLen {
		warns = append(warns, "warning: --chunk-size must be > --max-length; disabling")
		return 0, 0, warns
	}
	return chunkSize, ComputeOverlap(maxLen, maxPrimerLen), nil
}

// ComputeNeedSeq tells the pipeline whether to populate Product.Seq.
// For ipcr: we need sequences for --products, for pretty text, and for FASTA.
func ComputeNeedSeq(output string, products, pretty bool) bool {
	if products {
		return true
	}
	if output == "fasta" {
		return true
	}
	if output == "text" && pretty {
		return true
	}
	return false
}

===== END ./internal/runutil/runutil.go =====

===== BEGIN ./internal/runutil/runutil_test.go =====
package runutil

import "testing"

func TestComputeTerminalWindow(t *testing.T) {
	if got := ComputeTerminalWindow("realistic", -1); got != 3 {
		t.Fatalf("realistic→3, got %d", got)
	}
	if got := ComputeTerminalWindow("debug", -1); got != 0 {
		t.Fatalf("debug→0, got %d", got)
	}
	if got := ComputeTerminalWindow("realistic", 2); got != 2 {
		t.Fatalf("override should win, got %d", got)
	}
}

func TestComputeOverlap(t *testing.T) {
	if got := ComputeOverlap(100, 21); got != 100 {
		t.Fatalf("expect 100, got %d", got)
	}
	if got := ComputeOverlap(0, 21); got != 20 {
		t.Fatalf("expect maxPrimerLen-1=20, got %d", got)
	}
}

func TestValidateChunking(t *testing.T) {
	// circular disables
	cs, ov, w := ValidateChunking(true, 1000, 500, 25)
	if cs != 0 || ov != 0 || len(w) == 0 {
		t.Fatalf("circular should disable with warning")
	}
	// no maxLen
	cs, ov, w = ValidateChunking(false, 1000, 0, 25)
	if cs != 0 || ov != 0 || len(w) == 0 {
		t.Fatalf("missing maxLen should disable with warning")
	}
	// too small chunk
	cs, ov, w = ValidateChunking(false, 500, 500, 25)
	if cs != 0 || ov != 0 || len(w) == 0 {
		t.Fatalf("chunk<=maxLen should disable with warning")
	}
	// happy path
	cs, ov, w = ValidateChunking(false, 2000, 500, 25)
	if cs != 2000 || ov != 500 || len(w) != 0 {
		t.Fatalf("enabled: cs=%d ov=%d warns=%v", cs, ov, w)
	}
}

func TestComputeNeedSeq(t *testing.T) {
	if ComputeNeedSeq("json", false, false) {
		t.Fatalf("json without products/pretty should be false")
	}
	if !ComputeNeedSeq("fasta", false, false) {
		t.Fatalf("fasta always needs sequences")
	}
	if !ComputeNeedSeq("text", false, true) {
		t.Fatalf("pretty text needs sequences")
	}
	if !ComputeNeedSeq("json", true, false) {
		t.Fatalf("--products true needs sequences")
	}
}

===== END ./internal/runutil/runutil_test.go =====

===== BEGIN ./internal/version/version.go =====
// internal/version/version.go
package version

const Version = "2.5.0"
// ===
===== END ./internal/version/version.go =====

===== BEGIN ./internal/visitors/nested.go =====
// ./internal/visitors/nested.go
package visitors

import (
	"sort"

	"ipcr/internal/engine"
	"ipcr/internal/nestedoutput"
	"ipcr/internal/primer"
)

type Nested struct {
	InnerPairs  []primer.Pair
	EngineCfg   engine.Config
	RequireInner bool
}

func (v Nested) Visit(p engine.Product) (bool, nestedoutput.NestedProduct, error) {
	amp := []byte(p.Seq)
	eng := engine.New(v.EngineCfg)
	hits := eng.SimulateBatch("amplicon", amp, v.InnerPairs)

	// Pick a deterministic “best” inner: fewest total mismatches, then longest, then leftmost.
	bestIdx := -1
	bestScore := 1<<30
	for i := range hits {
		totalMM := hits[i].FwdMM + hits[i].RevMM
		if bestIdx == -1 || totalMM < bestScore ||
			(totalMM == bestScore && (hits[i].Length > hits[bestIdx].Length ||
				(hits[i].Length == hits[bestIdx].Length && hits[i].Start < hits[bestIdx].Start))) {
			bestIdx = i
			bestScore = totalMM
		}
	}

	if bestIdx == -1 {
		if v.RequireInner {
			return false, nestedoutput.NestedProduct{}, nil
		}
		return true, nestedoutput.NestedProduct{
			Product:     p,
			InnerFound:  false,
			InnerPairID: "",
		}, nil
	}

	// Stabilize by start position if multiple equal scored remain (already handled, but keep order tidy).
	sort.SliceStable(hits, func(i, j int) bool { return hits[i].Start < hits[j].Start })

	inner := hits[bestIdx]
	np := nestedoutput.NestedProduct{
		Product:      p, // outer
		InnerFound:   true,
		InnerPairID:  inner.ExperimentID,
		InnerStart:   inner.Start,  // relative to amplicon
		InnerEnd:     inner.End,    // relative to amplicon
		InnerLength:  inner.Length,
		InnerType:    inner.Type,
		InnerFwdMM:   inner.FwdMM,
		InnerRevMM:   inner.RevMM,
	}
	return true, np, nil
}

===== END ./internal/visitors/nested.go =====

===== BEGIN ./internal/visitors/pass.go =====
package visitors

import "ipcr/internal/engine"

// PassThrough returns the product unchanged.
type PassThrough struct{}

func (PassThrough) Visit(p engine.Product) (keep bool, out engine.Product, err error) {
	return true, p, nil
}

===== END ./internal/visitors/pass.go =====

===== BEGIN ./internal/visitors/probe.go =====
package visitors

import (
	"strings"

	"ipcr/internal/engine"
	"ipcr/internal/probe"
	"ipcr/internal/probeoutput"
)

// Probe annotates with an internal oligo and returns an AnnotatedProduct.
type Probe struct {
	Name    string
	Seq     string // 5'→3'
	MaxMM   int
	Require bool
}

func (v Probe) Visit(p engine.Product) (bool, probeoutput.AnnotatedProduct, error) {
	ann := probe.AnnotateAmplicon(p.Seq, v.Seq, v.MaxMM)
	if v.Require && !ann.Found {
		return false, probeoutput.AnnotatedProduct{}, nil
	}
	return true, probeoutput.AnnotatedProduct{
		Product:     p,
		ProbeName:   v.Name,
		ProbeSeq:    strings.ToUpper(v.Seq),
		ProbeFound:  ann.Found,
		ProbeStrand: ann.Strand,
		ProbePos:    ann.Pos,
		ProbeMM:     ann.MM,
		ProbeSite:   ann.Site,
	}, nil
}

===== END ./internal/visitors/probe.go =====

===== BEGIN ./internal/writers/annotated.go =====
package writers

import (
	"fmt"
	"io"

	"ipcr/internal/common"
	"ipcr/internal/pretty"
	"ipcr/internal/probeoutput"
)

// Backward-compatible wrapper
func StartAnnotatedWriter(out io.Writer, format string, sort bool, header bool, prettyMode bool, bufSize int) (chan<- probeoutput.AnnotatedProduct, <-chan error) {
	return StartAnnotatedWriterWithPrettyOptions(out, format, sort, header, prettyMode, pretty.DefaultOptions, bufSize)
}

// Options-aware variant
func StartAnnotatedWriterWithPrettyOptions(out io.Writer, format string, sort bool, header bool, prettyMode bool, popt pretty.Options, bufSize int) (chan<- probeoutput.AnnotatedProduct, <-chan error) {
	if bufSize <= 0 { bufSize = 64 }
	in := make(chan probeoutput.AnnotatedProduct, bufSize)
	errCh := make(chan error, 1)

	go func() {
		var err error
		switch format {
		case "json":
			var buf []probeoutput.AnnotatedProduct
			for ap := range in { buf = append(buf, ap) }
			if sort { common.SortAnnotated(buf) }
			err = probeoutput.WriteJSON(out, buf)

		case "jsonl":
			jsonlIn, done := StartAnnotatedJSONLWriter(out, bufSize)
			for ap := range in { jsonlIn <- ap }
			close(jsonlIn)
			err = <-done

		case "fasta":
			if sort {
				var buf []probeoutput.AnnotatedProduct
				for ap := range in { buf = append(buf, ap) }
				common.SortAnnotated(buf)
				err = probeoutput.WriteFASTA(out, buf)
			} else {
				err = probeoutput.StreamFASTA(out, in)
			}

		case "text":
			if prettyMode {
				// Header once
				if header {
					if _, e := io.WriteString(out, probeoutput.TSVHeaderProbe+"\n"); e != nil && err == nil { err = e }
				}
				if sort {
					var buf []probeoutput.AnnotatedProduct
					for ap := range in { buf = append(buf, ap) }
					common.SortAnnotated(buf)
					for _, ap := range buf {
						if e := probeoutput.WriteRowTSV(out, ap); e != nil && err == nil { err = e }
						if _, e := io.WriteString(out, probeoutput.RenderPrettyWithOptions(ap, popt)); e != nil && err == nil { err = e }
					}
				} else {
					for ap := range in {
						if e := probeoutput.WriteRowTSV(out, ap); e != nil && err == nil { err = e }
						if _, e := io.WriteString(out, probeoutput.RenderPrettyWithOptions(ap, popt)); e != nil && err == nil { err = e }
					}
				}
			} else {
				if sort {
					var buf []probeoutput.AnnotatedProduct
					for ap := range in { buf = append(buf, ap) }
					common.SortAnnotated(buf)
					err = probeoutput.WriteText(out, buf, header)
				} else {
					err = probeoutput.StreamText(out, in, header)
				}
			}

		default:
			err = fmt.Errorf("unsupported output %q", format)
		}
		errCh <- err
	}()

	return in, errCh
}

===== END ./internal/writers/annotated.go =====

===== BEGIN ./internal/writers/annotated_writer_test.go =====
package writers

import (
	"bytes"
	"strings"
	"testing"

	"ipcr/internal/engine"
	"ipcr/internal/probeoutput"
)

func TestStartAnnotatedWriter_TextHeader(t *testing.T) {
	var buf bytes.Buffer
	in, done := StartAnnotatedWriter(&buf, "text", false, true, false, 2)
	in <- probeoutput.AnnotatedProduct{
		Product: engine.Product{
			SourceFile: "ref.fa", SequenceID: "s:0-10", ExperimentID: "x",
			Start: 0, End: 10, Length: 10, Type: "forward",
		},
		ProbeName: "p", ProbeSeq: "AAA", ProbeFound: true, ProbeStrand: "+", ProbePos: 3,
	}
	close(in)
	if err := <-done; err != nil {
		t.Fatalf("writer err: %v", err)
	}
	out := buf.String()
	if !strings.Contains(out, "probe_name") || !strings.Contains(out, "\tp\t") {
		t.Fatalf("unexpected TSV text:\n%s", out)
	}
}

===== END ./internal/writers/annotated_writer_test.go =====

===== BEGIN ./internal/writers/brokenpipe.go =====
package writers

import (
	"errors"
	"io"
	"syscall"
)

// IsBrokenPipe reports whether an error is a broken pipe / closed pipe.
// Useful when downstream consumers (like `head`) close early.
func IsBrokenPipe(err error) bool {
	return err != nil && (errors.Is(err, syscall.EPIPE) || errors.Is(err, io.ErrClosedPipe))
}

===== END ./internal/writers/brokenpipe.go =====

===== BEGIN ./internal/writers/doc.go =====
// Package writers turns domain products into serialized outputs.
//
// Design:
//   • Writers own all presentation knowledge (pretty blocks, JSON/JSONL/FASTA).
//   • Engine stays domain-only; Pipeline stays orchestration-only.
//   • JSON/JSONL go through pkg/api (v1) for a stable wire format.
package writers

===== END ./internal/writers/doc.go =====

===== BEGIN ./internal/writers/jsonl.go =====
// internal/writers/jsonl.go
package writers

import (
	"bufio"
	"encoding/json"
	"io"

	"ipcr/internal/engine"
	"ipcr/internal/output"
	"ipcr/internal/probeoutput"
	"ipcr/pkg/api"
)

// StartProductJSONLWriter streams each engine.Product as one JSON line (v1).
func StartProductJSONLWriter(out io.Writer, bufSize int) (chan<- engine.Product, <-chan error) {
	if bufSize <= 0 { bufSize = 64 }
	in := make(chan engine.Product, bufSize)
	errCh := make(chan error, 1)
	w := bufio.NewWriterSize(out, 64<<10)

	go func() {
		enc := json.NewEncoder(w)
		for p := range in {
			var v1 api.ProductV1 = output.ToAPIProduct(p)
			if err := enc.Encode(v1); err != nil { errCh <- err; return }
		}
		if err := w.Flush(); err != nil && !IsBrokenPipe(err) { errCh <- err; return }
		errCh <- nil
	}()
	return in, errCh
}

// StartAnnotatedJSONLWriter streams each AnnotatedProduct as one JSON line (v1).
func StartAnnotatedJSONLWriter(out io.Writer, bufSize int) (chan<- probeoutput.AnnotatedProduct, <-chan error) {
	if bufSize <= 0 { bufSize = 64 }
	in := make(chan probeoutput.AnnotatedProduct, bufSize)
	errCh := make(chan error, 1)
	w := bufio.NewWriterSize(out, 64<<10)

	go func() {
		enc := json.NewEncoder(w)
		for ap := range in {
			v1 := probeoutput.ToAPIAnnotated(ap)
			if err := enc.Encode(v1); err != nil { errCh <- err; return }
		}
		if err := w.Flush(); err != nil && !IsBrokenPipe(err) { errCh <- err; return }
		errCh <- nil
	}()
	return in, errCh
}

===== END ./internal/writers/jsonl.go =====

===== BEGIN ./internal/writers/jsonl_annotated_test.go =====
package writers

import (
	"bufio"
	"bytes"
	"encoding/json"
	"testing"

	"ipcr/internal/engine"
	"ipcr/internal/probeoutput"
	"ipcr/pkg/api"
)

func TestAnnotatedJSONL_StreamsValidV1(t *testing.T) {
	var buf bytes.Buffer
	in, done := StartAnnotatedJSONLWriter(&buf, 2)
	in <- probeoutput.AnnotatedProduct{
		Product: engine.Product{ExperimentID: "x", SequenceID: "s:0-4", Start: 0, End: 4, Length: 4, Type: "forward"},
		ProbeName: "p", ProbeSeq: "ACG", ProbeFound: true, ProbeStrand: "+", ProbePos: 1, ProbeMM: 0, ProbeSite: "CGT",
	}
	close(in)
	if err := <-done; err != nil {
		t.Fatalf("writer err: %v", err)
	}

	sc := bufio.NewScanner(bytes.NewReader(buf.Bytes()))
	var v api.AnnotatedProductV1
	if !sc.Scan() || json.Unmarshal(sc.Bytes(), &v) != nil || v.ProbeName != "p" {
		t.Fatalf("bad jsonl annotated: %q", sc.Text())
	}
}

===== END ./internal/writers/jsonl_annotated_test.go =====

===== BEGIN ./internal/writers/jsonl_product_test.go =====
package writers

import (
	"bufio"
	"bytes"
	"encoding/json"
	"testing"

	"ipcr/internal/engine"
	"ipcr/pkg/api"
)

func TestProductJSONL_StreamsValidV1(t *testing.T) {
	var buf bytes.Buffer
	in, done := StartProductJSONLWriter(&buf, 2)
	in <- engine.Product{ExperimentID: "x", SequenceID: "s:0-4", Start: 0, End: 4, Length: 4, Type: "forward"}
	in <- engine.Product{ExperimentID: "y", SequenceID: "s:2-6", Start: 2, End: 6, Length: 4, Type: "revcomp"}
	close(in)
	if err := <-done; err != nil {
		t.Fatalf("writer err: %v", err)
	}

	sc := bufio.NewScanner(bytes.NewReader(buf.Bytes()))
	var n int
	for sc.Scan() {
		n++
		var v api.ProductV1
		if err := json.Unmarshal(sc.Bytes(), &v); err != nil {
			t.Fatalf("bad json line %d: %v\n%s", n, err, sc.Text())
		}
	}
	if n != 2 {
		t.Fatalf("want 2 lines, got %d", n)
	}
}

===== END ./internal/writers/jsonl_product_test.go =====

===== BEGIN ./internal/writers/nested.go =====
// ./internal/writers/nested.go
package writers

import (
	"bufio"
	"encoding/json"
	"fmt"
	"io"
	"sort"

	"ipcr/internal/common"
	"ipcr/internal/nestedoutput"
)

func StartNestedWriter(out io.Writer, format string, sortOut bool, header bool, bufSize int) (chan<- nestedoutput.NestedProduct, <-chan error) {
	if bufSize <= 0 { bufSize = 64 }
	in := make(chan nestedoutput.NestedProduct, bufSize)
	errCh := make(chan error, 1)

	go func() {
		var err error
		switch format {
		case "json":
			var buf []nestedoutput.NestedProduct
			for np := range in { buf = append(buf, np) }
			if sortOut {
				sort.Slice(buf, func(i, j int) bool {
					return common.LessProduct(buf[i].Product, buf[j].Product)
				})
			}
			err = nestedoutput.WriteJSON(out, buf)

		case "jsonl":
			w := bufio.NewWriterSize(out, 64<<10)
			enc := json.NewEncoder(w)
			for np := range in {
				v1 := nestedoutput.WriteJSON // not used directly; keep identical style
				_ = v1 // silence linter
				if err = enc.Encode(apiWrap(np)); err != nil { break }
			}
			if e := w.Flush(); err == nil && e != nil && !IsBrokenPipe(e) { err = e }

		case "text":
			if sortOut {
				var buf []nestedoutput.NestedProduct
				for np := range in { buf = append(buf, np) }
				sort.Slice(buf, func(i, j int) bool {
					return common.LessProduct(buf[i].Product, buf[j].Product)
				})
				err = nestedoutput.WriteText(out, buf, header)
			} else {
				err = nestedoutput.StreamText(out, in, header)
			}

		case "fasta":
			// For nested: FASTA would just be outer sequences; reuse Product FASTA by mapping?
			// Keep it simple: advise using ipcr --products + writer if FASTA is needed.
			err = fmt.Errorf("unsupported output %q for ipcr-nested; use text|json|jsonl", format)

		default:
			err = fmt.Errorf("unsupported output %q", format)
		}
		errCh <- err
	}()
	return in, errCh
}

// Minimal inline wrapper to jsonl-encode v1 without creating a new file.
// We avoid pulling in output/probeoutput here to honor boundaries.
type apiNestedLine struct {
	ExperimentID   string `json:"experiment_id"`
	SequenceID     string `json:"sequence_id"`
	Start          int    `json:"start"`
	End            int    `json:"end"`
	Length         int    `json:"length"`
	Type           string `json:"type"`
	FwdMM          int    `json:"fwd_mm,omitempty"`
	RevMM          int    `json:"rev_mm,omitempty"`
	FwdMismatchIdx []int  `json:"fwd_mm_i,omitempty"`
	RevMismatchIdx []int  `json:"rev_mm_i,omitempty"`
	Seq            string `json:"seq,omitempty"`
	SourceFile     string `json:"source_file,omitempty"`
	InnerFound     bool   `json:"inner_found"`
	InnerPairID    string `json:"inner_experiment_id,omitempty"`
	InnerStart     int    `json:"inner_start,omitempty"`
	InnerEnd       int    `json:"inner_end,omitempty"`
	InnerLength    int    `json:"inner_length,omitempty"`
	InnerType      string `json:"inner_type,omitempty"`
	InnerFwdMM     int    `json:"inner_fwd_mm,omitempty"`
	InnerRevMM     int    `json:"inner_rev_mm,omitempty"`
}

func apiWrap(np nestedoutput.NestedProduct) apiNestedLine {
	p := np.Product
	return apiNestedLine{
		ExperimentID:   p.ExperimentID,
		SequenceID:     p.SequenceID,
		Start:          p.Start,
		End:            p.End,
		Length:         p.Length,
		Type:           p.Type,
		FwdMM:          p.FwdMM,
		RevMM:          p.RevMM,
		FwdMismatchIdx: append([]int(nil), p.FwdMismatchIdx...),
		RevMismatchIdx: append([]int(nil), p.RevMismatchIdx...),
		Seq:            p.Seq,
		SourceFile:     p.SourceFile,
		InnerFound:     np.InnerFound,
		InnerPairID:    np.InnerPairID,
		InnerStart:     np.InnerStart,
		InnerEnd:       np.InnerEnd,
		InnerLength:    np.InnerLength,
		InnerType:      np.InnerType,
		InnerFwdMM:     np.InnerFwdMM,
		InnerRevMM:     np.InnerRevMM,
	}
}

===== END ./internal/writers/nested.go =====

===== BEGIN ./internal/writers/product.go =====
package writers

import (
	"fmt"
	"io"

	"ipcr/internal/common"
	"ipcr/internal/engine"
	"ipcr/internal/output"
	"ipcr/internal/pretty"
)

// StartProductWriter spins up a writer goroutine for plain engine.Product items.
// (Backward-compatible wrapper using pretty.DefaultOptions)
func StartProductWriter(out io.Writer, format string, sort bool, header bool, prettyMode bool, bufSize int) (chan<- engine.Product, <-chan error) {
	return StartProductWriterWithPrettyOptions(out, format, sort, header, prettyMode, pretty.DefaultOptions, bufSize)
}

// StartProductWriterWithPrettyOptions allows customizing the pretty renderer.
func StartProductWriterWithPrettyOptions(out io.Writer, format string, sort bool, header bool, prettyMode bool, popt pretty.Options, bufSize int) (chan<- engine.Product, <-chan error) {
	if bufSize <= 0 {
		bufSize = 64
	}
	in := make(chan engine.Product, bufSize)
	errCh := make(chan error, 1)

	go func() {
		var err error
		switch format {
		case "json":
			var buf []engine.Product
			for p := range in {
				buf = append(buf, p)
			}
			if sort {
				common.SortProducts(buf)
			}
			err = output.WriteJSON(out, buf)

		case "jsonl":
			// Stream each object per line
			jsonlIn, done := StartProductJSONLWriter(out, bufSize)
			for p := range in {
				jsonlIn <- p
			}
			close(jsonlIn)
			err = <-done

		case "fasta":
			if sort {
				var buf []engine.Product
				for p := range in {
					buf = append(buf, p)
				}
				common.SortProducts(buf)
				err = output.WriteFASTA(out, buf)
			} else {
				err = output.StreamFASTA(out, in)
			}

		case "text":
			if sort {
				var buf []engine.Product
				for p := range in {
					buf = append(buf, p)
				}
				common.SortProducts(buf)
				// write TSV (and pretty) in a buffered manner
				err = output.WriteTextWithRenderer(out, buf, header, prettyMode,
					func(p engine.Product) string { return pretty.RenderProductWithOptions(p, popt) },
				)
			} else {
				// streaming
				err = output.StreamTextWithRenderer(out, in, header, prettyMode,
					func(p engine.Product) string { return pretty.RenderProductWithOptions(p, popt) },
				)
			}

		default:
			err = fmt.Errorf("unsupported output %q", format)
		}
		errCh <- err
	}()

	return in, errCh
}

===== END ./internal/writers/product.go =====

===== BEGIN ./internal/writers/product_writer_test.go =====
package writers

import (
	"bytes"
	"encoding/json"
	"testing"

	"ipcr/internal/engine"
)

func TestStartProductWriter_JSON(t *testing.T) {
	var buf bytes.Buffer
	in, done := StartProductWriter(&buf, "json", true, false, false, 4)
	in <- engine.Product{ExperimentID: "x", SequenceID: "s", Start: 0, End: 4, Length: 4, Type: "forward"}
	in <- engine.Product{ExperimentID: "y", SequenceID: "s", Start: 2, End: 6, Length: 4, Type: "revcomp"}
	close(in)
	if err := <-done; err != nil {
		t.Fatalf("writer err: %v", err)
	}
	var got []engine.Product
	if err := json.Unmarshal(buf.Bytes(), &got); err != nil || len(got) != 2 {
		t.Fatalf("json roundtrip: %v len=%d", err, len(got))
	}
}

===== END ./internal/writers/product_writer_test.go =====

===== BEGIN ./pkg/api/nested_v1.go =====
// ./pkg/api/nested_v1.go
package api

type NestedProductV1 struct {
	// Outer (matches ProductV1 fields)
	ExperimentID   string `json:"experiment_id"`
	SequenceID     string `json:"sequence_id"`
	Start          int    `json:"start"`
	End            int    `json:"end"`
	Length         int    `json:"length"`
	Type           string `json:"type"`
	FwdMM          int    `json:"fwd_mm,omitempty"`
	RevMM          int    `json:"rev_mm,omitempty"`
	FwdMismatchIdx []int  `json:"fwd_mm_i,omitempty"`
	RevMismatchIdx []int  `json:"rev_mm_i,omitempty"`
	Seq            string `json:"seq,omitempty"`
	SourceFile     string `json:"source_file,omitempty"`

	// Inner summary
	InnerFound   bool   `json:"inner_found"`
	InnerPairID  string `json:"inner_experiment_id,omitempty"`
	InnerStart   int    `json:"inner_start,omitempty"`
	InnerEnd     int    `json:"inner_end,omitempty"`
	InnerLength  int    `json:"inner_length,omitempty"`
	InnerType    string `json:"inner_type,omitempty"`
	InnerFwdMM   int    `json:"inner_fwd_mm,omitempty"`
	InnerRevMM   int    `json:"inner_rev_mm,omitempty"`
}

===== END ./pkg/api/nested_v1.go =====

===== BEGIN ./pkg/api/products_v1.go =====
// pkg/api/products_v1.go
package api

// ProductV1 is the stable JSON/JSONL schema for plain amplicons.
// Keep fields, names, and types stable. Add new fields only with ",omitempty".
type ProductV1 struct {
	ExperimentID   string `json:"experiment_id"`
	SequenceID     string `json:"sequence_id"`
	Start          int    `json:"start"`
	End            int    `json:"end"`
	Length         int    `json:"length"`
	Type           string `json:"type"` // "forward" | "revcomp"
	FwdMM          int    `json:"fwd_mm,omitempty"`
	RevMM          int    `json:"rev_mm,omitempty"`
	FwdMismatchIdx []int  `json:"fwd_mm_i,omitempty"`
	RevMismatchIdx []int  `json:"rev_mm_i,omitempty"`
	Seq            string `json:"seq,omitempty"`
	SourceFile     string `json:"source_file,omitempty"`
}

// AnnotatedProductV1 is the stable schema for probe-annotated outputs.
type AnnotatedProductV1 struct {
	// Base
	ExperimentID   string `json:"experiment_id"`
	SequenceID     string `json:"sequence_id"`
	Start          int    `json:"start"`
	End            int    `json:"end"`
	Length         int    `json:"length"`
	Type           string `json:"type"`
	FwdMM          int    `json:"fwd_mm,omitempty"`
	RevMM          int    `json:"rev_mm,omitempty"`
	FwdMismatchIdx []int  `json:"fwd_mm_i,omitempty"`
	RevMismatchIdx []int  `json:"rev_mm_i,omitempty"`
	Seq            string `json:"seq,omitempty"`
	SourceFile     string `json:"source_file,omitempty"`

	// Probe overlay
	ProbeName   string `json:"probe_name"`
	ProbeSeq    string `json:"probe_seq"`
	ProbeFound  bool   `json:"probe_found"`
	ProbeStrand string `json:"probe_strand,omitempty"` // "+"/"-"
	ProbePos    int    `json:"probe_pos,omitempty"`
	ProbeMM     int    `json:"probe_mm,omitempty"`
	ProbeSite   string `json:"probe_site,omitempty"`
}

===== END ./pkg/api/products_v1.go =====

